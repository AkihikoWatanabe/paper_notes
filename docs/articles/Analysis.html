<!DOCTYPE html>
<html lang="ja"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-translate-customization" content="108d9124921d80c3-80e20d618ff053c8-g4f02ec6f3dba68b7-c">
  <link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin>
  <link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <link rel="preconnect" href="https://www.googletagmanager.com" crossorigin>
  <link rel="preconnect" href="https://www.google-analytics.com" crossorigin>
  <link rel="preconnect" href="https://platform.twitter.com">
  <link rel="preconnect" href="https://pbs.twimg.com">
  <link rel="dns-prefetch" href="https://cdnjs.cloudflare.com">
  <link rel="dns-prefetch" href="https://cdn.jsdelivr.net">
  <link rel="dns-prefetch" href="https://platform.twitter.com">
  <link rel="dns-prefetch" href="https://pbs.twimg.com"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Analysisに関する論文・技術記事メモの一覧 | わたしのべんきょうノート</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Analysisに関する論文・技術記事メモの一覧" />
<meta name="author" content="AkihikoWATANABE" />
<meta property="og:locale" content="ja" />
<meta name="description" content="Analysis [Paper Note] Learning to Reason in 13 Parameters, John X. Morris+, arXiv&#39;26, 2026.02 Paper/Blog Link My Issue #Pocket #NLP #LanguageModel #ReinforcementLearning #Reasoning #PEFT(Adaptor/LoRA) #Initial Impression Notes Issue Date: 2026-02-05 GPT Summary- 低ランクアダプタTinyLoRAを提案し、推論のための強化学習が低ランクパラメータ化を効果的にスケールできることを示しています。わずか13のトレーニングパラメータでQwen2.5を91％の精度に達成し、複雑なベンチマークでも少ないパラメータで90％のパフォーマンス向上を実現しました。特に、強化学習を用いることで、従来の方法よりも大幅に少ないパラメータで強力な結果を得ることができました。 Comment元ポスト:" />
<meta property="og:description" content="Analysis [Paper Note] Learning to Reason in 13 Parameters, John X. Morris+, arXiv&#39;26, 2026.02 Paper/Blog Link My Issue #Pocket #NLP #LanguageModel #ReinforcementLearning #Reasoning #PEFT(Adaptor/LoRA) #Initial Impression Notes Issue Date: 2026-02-05 GPT Summary- 低ランクアダプタTinyLoRAを提案し、推論のための強化学習が低ランクパラメータ化を効果的にスケールできることを示しています。わずか13のトレーニングパラメータでQwen2.5を91％の精度に達成し、複雑なベンチマークでも少ないパラメータで90％のパフォーマンス向上を実現しました。特に、強化学習を用いることで、従来の方法よりも大幅に少ないパラメータで強力な結果を得ることができました。 Comment元ポスト:" />
<link rel="canonical" href="http://akihikowatanabe.github.io/paper_notes/articles/Analysis.html" />
<meta property="og:url" content="http://akihikowatanabe.github.io/paper_notes/articles/Analysis.html" />
<meta property="og:site_name" content="わたしのべんきょうノート" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2026-02-05T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Analysisに関する論文・技術記事メモの一覧" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"AkihikoWATANABE"},"dateModified":"2026-02-05T00:00:00+00:00","datePublished":"2026-02-05T00:00:00+00:00","description":"Analysis [Paper Note] Learning to Reason in 13 Parameters, John X. Morris+, arXiv&#39;26, 2026.02 Paper/Blog Link My Issue #Pocket #NLP #LanguageModel #ReinforcementLearning #Reasoning #PEFT(Adaptor/LoRA) #Initial Impression Notes Issue Date: 2026-02-05 GPT Summary- 低ランクアダプタTinyLoRAを提案し、推論のための強化学習が低ランクパラメータ化を効果的にスケールできることを示しています。わずか13のトレーニングパラメータでQwen2.5を91％の精度に達成し、複雑なベンチマークでも少ないパラメータで90％のパフォーマンス向上を実現しました。特に、強化学習を用いることで、従来の方法よりも大幅に少ないパラメータで強力な結果を得ることができました。 Comment元ポスト:","headline":"Analysisに関する論文・技術記事メモの一覧","mainEntityOfPage":{"@type":"WebPage","@id":"http://akihikowatanabe.github.io/paper_notes/articles/Analysis.html"},"url":"http://akihikowatanabe.github.io/paper_notes/articles/Analysis.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="icon" href="">
  <link rel="canonical" href="http://akihikowatanabe.github.io">

  <link rel="preload" href="/paper_notes/assets/css/main.css" as="style">
  <link rel="preload" href="/paper_notes/assets/js/main.js" as="script">

  <link rel="stylesheet" href="/paper_notes/assets/css/main.css">
  <link rel="stylesheet" href="/paper_notes/assets/css/custom_button.css">
  
  <link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"></noscript>
  <link rel="preload" href="https://cdn.jsdelivr.net/npm/typeface-noto-sans@0.0.72/index.min.css" as="style" onload="this. onload=null;this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-noto-sans@0.0.72/index.min.css"></noscript>
  
  <script src="/paper_notes/assets/js/main.js"></script><link type="application/atom+xml" rel="alternate" href="http://akihikowatanabe.github.io/paper_notes/feed.xml" title="わたしのべんきょうノート" /><script>
  function showMore(index) {
    const contentDivs = document.getElementsByClassName('hidden-content');
    const contentDiv = contentDivs[index];

    if (contentDiv) {
      contentDiv.style.display = "block";
          
      // このボタンの参照を取得して非表示にします
      const moreButtons = document.querySelectorAll('button[onclick^="showMore"]');
      const moreButton = moreButtons[index];
      if (moreButton) {
        moreButton.style.display = "none";
      }
          
      // hideボタンの参照を取得して表示します
      const hideButton = contentDiv.querySelector('button[onclick^="hideContent"]');
      if (hideButton) {
        hideButton.style.display = "block";
      }
    }
  }

  function hideContent(index) {
    const contentDivs = document.getElementsByClassName('hidden-content');
    const contentDiv = contentDivs[index];

    if (contentDiv) {
      contentDiv.style.display = "none";
  
      // moreボタンの参照を取得して表示します
      const moreButtons = document.querySelectorAll('button[onclick^="showMore"]');
      const moreButton = moreButtons[index];
      if (moreButton) {
        moreButton.style.display = "block";
      }
  
      // このボタンを隠します
      const hideButtons = document.querySelectorAll('button[onclick^="hideContent"]');
      const hideButton = hideButtons[index];
      if (hideButton) {
        hideButton.style.display = "none";
      }
    }
  }
</script><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/default.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js"></script>
<!-- and it's easy to individually load additional languages -->
<script charset="UTF-8"
        src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/languages/go.min.js"
        async></script>



















<script>
// Init highlight js
document.addEventListener('DOMContentLoaded', function(event) {
  var els = document.querySelectorAll('pre code')

  function addLangData(block) {
    var outer = block.parentElement.parentElement.parentElement;
    var lang = block.getAttribute('data-lang');
    for (var i = 0; i < outer.classList.length; i++) {
      var cls = outer.classList[i];
      if (cls.startsWith('language-')) {
        lang = cls;
        break;
      }
    }
    if (!lang) {
      cls = block.getAttribute('class');
      lang = cls ? cls.replace('hljs ', '') : '';
    }
    if (lang.startsWith('language-')) {
      lang = lang.substr(9);
    }
    block.setAttribute('class', 'hljs ' + lang);
    block.parentNode.setAttribute('data-lang', lang);
  }

  function addBadge(block) {
    var enabled = ('true' || 'true').toLowerCase();
    if (enabled == 'true') {
      var pre = block.parentElement;
      pre.classList.add('badge');
    }
  }

  function handle(block) {
    addLangData(block);
    addBadge(block)
    hljs.highlightBlock(block);
  }

  for (var i = 0; i < els.length; i++) {
    var el = els[i];
    handle(el);
  }
});
</script>

<style>
  /* code language badge */
  pre.badge::before {
    content: attr(data-lang);
    color: #fff;
    background-color: #ff4e00;
    padding: 0 .5em;
    border-radius: 0 2px;
    text-transform: uppercase;
    text-align: center;
    min-width: 32px;
    display: inline-block;
    position: absolute;
    right: 0;
  }

  /* fix wrong badge display for firefox browser */
  code > table pre::before {
    display: none;
  }
</style>
<script
  src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/umd/photoswipe-lightbox.umd.min.js" async></script>
<script
  src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/umd/photoswipe.umd.min.js" async></script>
<link
  href="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/photoswipe.min.css"
  rel="stylesheet"
/>
<style>
  .pswp .pswp__container .pswp__img {
    background-color: white;
  }
</style>

<script>
  function initPhotoSwipe() {
    let customOptions = {};

    try {
      const data = `{"gallery"=>"section.main", "children"=>"a.photo-swipe", "bgOpacity"=>0.8, "padding"=>{"top"=>20, "bottom"=>40, "left"=>100, "right"=>100}}`.replaceAll("=>", ":");
      customOptions = JSON.parse(data);
    } catch (e) {
      console.info("Invalid custom photo previewer options! " + e.message);
    }

    // Define object and gallery options
    const options = Object.assign(
      {
        gallery: "section.main",
        children: "a.photo-swipe",
        photo_scale: 2,
        // dynamic import is not supported in UMD version
        pswpModule: PhotoSwipe,
      },
      customOptions
    );

    const galleryEl = document.querySelector(options.gallery);
    if (!galleryEl) {
      return;
    }

    const imgEls = [];
    const els = galleryEl.querySelectorAll("img:not(.emoji)");
    els.forEach((el) => {
      if (el.src.trim() == "") {
        return;
      }
      if (!imgEls.includes(el)) {
        imgEls.push(el);
      }
    });

    if (imgEls.length === 0) {
      return;
    }

    imgEls.forEach((imgEl) => {
      imgEl.outerHTML = `
      <a class="photo-swipe"
        href="${imgEl.src}"
        data-pswp-width="${
          Math.max(imgEl.naturalWidth, imgEl.width) * options.photo_scale
        }"
        data-pswp-height="${
          Math.max(imgEl.naturalHeight, imgEl.height) * options.photo_scale
        }"
        data-pswp-caption="${imgEl.getAttribute("caption") || imgEl.alt}"
        target="_blank">
        ${imgEl.outerHTML}
      </a>`;
    });

    // Initialize PhotoSwipe 5
    var lightbox = new PhotoSwipeLightbox(options);

    lightbox.init();
  }

  window.addEventListener("load", initPhotoSwipe);
</script>
<meta name="google-site-verification" content="u_DTTPcCZ806iq51zgirHyWq3556HUKGq8AQfH91iFI" />
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-P70KSB88WH"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-P70KSB88WH');
  </script>
</script>
</head>


<body>





































































































































<header class="site-header site-header-transparent" role="banner">

  <div class="wrapper">
    <div class="site-header-inner"><span class="site-brand"><a class="site-brand-inner" rel="author" href="/paper_notes/">
  <img class="site-favicon" title="わたしのべんきょうノート" src="" onerror="this.style.display='none'">
  わたしのべんきょうノート
</a>
</span><nav class="site-nav">
          <input type="checkbox" id="nav-trigger" class="nav-trigger" />
          <label for="nav-trigger">
            <span class="menu-icon">
              <svg viewBox="0 0 18 15" width="18px" height="15px">
                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
              </svg>
            </span>
          </label>

          <div class="trigger"><a class="page-link" href="/paper_notes/">論文や技術メモの一覧（随時更新）</a><a class="page-link" href="/paper_notes/archives.html">ARCHIVES</a>









<span class="page-link">



<div id="google_translate_element" style="display: none;">
</div>

<span class="ct-language">
  <ul class="list-unstyled ct-language-dropdown">
    
      <li>
        <a href="#" class="lang-select" data-lang="en">
          
          <img src="https://cdn.countryflags.com/thumbs/united-states-of-america/flag-400.png" title="English">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="fr">
          
          <img src="https://cdn.countryflags.com/thumbs/france/flag-400.png" title="French">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="zh-CN">
          
          <img src="https://cdn.countryflags.com/thumbs/china/flag-400.png" title="Chinese(Simple)">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ja">
          
          <img src="https://cdn.countryflags.com/thumbs/japan/flag-400.png" title="Japanese">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ko">
          
          <img src="https://cdn.countryflags.com/thumbs/south-korea/flag-400.png" title="Korean">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ru">
          
          <img src="https://cdn.countryflags.com/thumbs/russia/flag-400.png" title="Russian">
          
        </a>
      </li>
    
  </ul>
</span>

<script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({
    pageLanguage: 'ja',
    autoDisplay: false,
    layout: google.translate.TranslateElement.InlineLayout.VERTICAL
  }, 'google_translate_element');

  // Links to cross-origin destinations are unsafe
  var gll = document.getElementsByClassName('goog-logo-link')[0];
  if (gll) {
    gll.setAttribute('rel', 'noopener');
  }

  function restoreLang() {
    var iframe = document.getElementsByClassName('goog-te-banner-frame')[0];
    if (!iframe) return;

    var innerDoc = iframe.contentDocument || iframe.contentWindow.document;
    var restore_el = innerDoc.getElementsByTagName("button");

    for (var i = 0; i < restore_el.length; i++) {
      if (restore_el[i].id.indexOf("restore") >= 0) {
        restore_el[i].click();
        var close_el = innerDoc.getElementsByClassName("goog-close-link");
        close_el[0].click();
        return;
      }
    }
  }

  function triggerHtmlEvent(element, eventName) {
    var event;
    if (document.createEvent) {
      event = document.createEvent('HTMLEvents');
      event.initEvent(eventName, true, true);
      element.dispatchEvent(event);
    } else {
      event = document.createEventObject();
      event.eventType = eventName;
      element.fireEvent('on' + event.eventType, event);
    }
  }

  var googleCombo = document.querySelector("select.goog-te-combo");
  var langSelect = document.querySelector('.ct-language');
  langSelect.addEventListener('click', function(event) {
    if (!event.target) {
      return;
    }

    var selected = document.querySelector('.ct-language .ct-language-selected');
    if (selected) {
      selected.classList.remove('ct-language-selected');
    }

    var target = event.target;
    while (target && target !== langSelect ) {
      if (target.matches('.lang-select')) {
        break;
      }
      target = target.parentElement;
    }

    if (target && target.matches('.lang-select')) {
      var lang = target.getAttribute('data-lang');
      if (googleCombo.value == lang) {
        restoreLang();
      } else {
        target.parentElement.classList.add('ct-language-selected');
        googleCombo.value = lang;
        triggerHtmlEvent(googleCombo, 'change');
      }
    }

    event.preventDefault();
  });
}
</script>

<script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=googleTranslateElementInit" async></script>
</span></div>
        </nav></div>
  </div>
</header>

<script>
  function initHeader() {
    var lastScrollY = getScrollPos().y;
    var documentElement = document.documentElement;
    var ticking = false;

    function storeScrollData() {
      var y = getScrollPos().y;documentElement.setAttribute("data-header-transparent", "");var scrollStatus = "";

      if (y <= 0) {
        scrollStatus = "top";
      } else if ((window.innerHeight + y) >= document.body.offsetHeight) {
        scrollStatus = "bottom";
      } else {
        var isScrollDown = (y - lastScrollY > 0);
        scrollStatus = isScrollDown ? "down" : "up";
      }

      lastScrollY = y;
      documentElement.setAttribute("data-scroll-status", scrollStatus);
      
      // 処理完了フラグをリセット
      ticking = false;
    }

    function requestTick() {
      if (!ticking) {
        // 次の描画フレームで実行をスケジュール
        window.requestAnimationFrame(storeScrollData);
        ticking = true;
      }
    }

    // passive:  true でスクロールパフォーマンスを向上
    window.addEventListener('scroll', requestTick, { passive: true });

    // 初期実行
    storeScrollData();
  }
  
  document.addEventListener('DOMContentLoaded', initHeader);
</script>


























































































































































<style>
    html .page-banner .page-banner-img > *:first-child {
      opacity: 0.4;
    }

    html[data-theme="dark"] .page-banner .page-banner-img > *:first-child {
      opacity: 0.2872;
    }
  </style><section class="page-banner">
    <div class="page-banner-img"><div style="background-image: url(/paper_notes/assets/images/banner.webp)"></div>
        <img class="img-placeholder" src="/paper_notes/assets/images/banner.webp"></div>
    <div class="wrapper">
      <div class="page-banner-inner"><header class="post-header">
  <h1 class="post-title p-name" itemprop="name headline">わたしのべんきょうノート</h1>
  <h2 class="post-subtitle">勉強した論文や技術等の情報をGithubのIssueにメモっているひとのブログ。
それなりにメモの量が蓄積されてきたので、一度整理したいなと思いブログはじめてみました！
自然言語処理(NLP), 推薦システム(RecommenderSystem), Educational Data Mining (EDM), Learning Analytics (LA)などの分野のメモが多いと思います。
最近は特にLLMの勉強が多めです :)</h2>

  <div class="post-meta">
    <time class="dt-published" datetime="2026-02-05T00:00:00+00:00" itemprop="datePublished"><i class="fa fa-calendar"></i> Feb 05, 2026
    </time><span class="post-author left-vsplit"><i class="fa fa-pencil"></i> AkihikoWATANABE</span>
    
































    <span class="post-reading-time left-vsplit"><i class="fa fa-clock-o"></i> About 10 hours 12 mins</span>
  </div></header>
</div>
    </div>
  </section><script>
  function hashLocate(hashValue) {
    hashValue = hashValue.replace(/^.*#h-/, '');
    hashValue = decodeURIComponent(hashValue);
    var element = document.getElementById(hashValue);

    if (!element) {
      return;
    }

    var header = document.querySelector('header.site-header');
    var headerRect = header.getBoundingClientRect();
    var headerTop = Math.floor(headerRect.top);
    var headerHeight = Math.floor(headerRect.height);
    var scrollPos = getScrollPos();
    var offsetY = element.offsetTop - (headerTop + headerHeight + 20);

    if (offsetY == scrollPos.y) {
      return;
    }

    if (headerTop == 0  && offsetY > scrollPos.y) {
      offsetY += headerHeight + 2;
    } else if (headerTop < 0  && offsetY < scrollPos.y) {
      offsetY -= headerHeight - 2;
    }

    smoothScrollTo(offsetY);
  }

  // The first event occurred
  window.addEventListener('load', function(event) {
    if (window.location.hash) {
      hashLocate(window.location.hash);
    }
  });

  // The first event occurred
  window.addEventListener('click', function(event) {
    if (event.target.tagName.toLowerCase() == 'a') {
      hashLocate(event.target.getAttribute('href'));
    }
  });
</script>
<div class="theme-toggle">
  <input type="checkbox" id="theme-switch">
  <label for="theme-switch">
    <div class="toggle"></div>
    <div class="names">
      <p class="light">Light</p>
      <p class="dark">Dark</p>
    </div>
  </label>
</div>




<script>
  (function() {
    var sw = document.getElementById('theme-switch');
    var html = document.getElementsByTagName('html')[0];
    var nightModeOption = ('off' || 'auto').toLowerCase();
    var storage = nightModeOption === 'manual'
        ? localStorage
        : sessionStorage;
    var themeData = loadThemeData();

    function saveThemeData(data) {
      storage.setItem('theme', JSON.stringify(data));
    }

    function loadThemeData() {
      var data = storage.getItem('theme');
      try {
        data = JSON.parse(data ? data : '');
      } catch(e) {
        data = { nightShift: undefined, autoToggleAt: 0 };
        saveThemeData(data);
      }
      return data;
    }

    function handleThemeToggle(nightShift) {
      themeData.nightShift = nightShift;
      saveThemeData(themeData);
      html.dataset.theme = nightShift ? 'dark' : 'light';
      setTimeout(function() {
        sw.checked = nightShift ? true : false;
      }, 50);
    }

    function autoThemeToggle() {
      // Next time point of theme toggle
      var now = new Date();
      var toggleAt = new Date();
      var hours = now.getHours();
      var nightShift = hours >= 19 || hours <=7;

      if (nightShift) {
        if (hours > 7) {
          toggleAt.setDate(toggleAt.getDate() + 1);
        }
        toggleAt.setHours(7);
      } else {
        toggleAt.setHours(19);
      }

      toggleAt.setMinutes(0);
      toggleAt.setSeconds(0);
      toggleAt.setMilliseconds(0)

      var delay = toggleAt.getTime() - now.getTime();

      // auto toggle theme mode
      setTimeout(function() {
        handleThemeToggle(!nightShift);
      }, delay);

      return {
        nightShift: nightShift,
        toggleAt: toggleAt.getTime()
      };
    }

    // Listen the theme toggle event
    sw.addEventListener('change', function(event) {
      handleThemeToggle(event.target.checked);
    });

    if (nightModeOption == 'auto') {
      var data = autoThemeToggle();

      // Toggle theme by local setting
      if (data.toggleAt > themeData.autoToggleAt) {
        themeData.autoToggleAt = data.toggleAt;
        handleThemeToggle(data.nightShift);
      } else {
        handleThemeToggle(themeData.nightShift);
      }
    } else if (nightModeOption == 'manual') {
      handleThemeToggle(themeData.nightShift);
    } else {
      var nightShift = themeData.nightShift;
      if (nightShift === undefined) {
        nightShift = nightModeOption === 'on';
      }
      handleThemeToggle(nightShift);
    }
  })();
</script>
<div id="click-to-top" class="click-to-top">
  <i class="fa fa-arrow-up"></i>
</div>
<script>
  (function () {
    const clickToTop = document.getElementById('click-to-top');
    window.addEventListener('scroll', () => {
      if (window.scrollY > 100) {
        clickToTop.classList.add('show')
      }else {
        clickToTop.classList.remove('show')
      }
    });
    clickToTop.addEventListener('click', () => {
      window.smoothScrollTo(0);
    });
  })();
</script>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="framework">
  <section class="main">

     <div class="post">
  <section>









<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

    <div class="post-content e-content" itemprop="articleBody">

      <h2 id=Analysis class="paper-head"> Analysis</h2><div class="visible-content">
<article class="paper-entry">
<h3 id="learning-to-4437" class="title-link">[Paper Note] Learning to Reason in 13 Parameters, John X. Morris+, arXiv'26, 2026.02</h3><br><a href="https://arxiv.org/abs/2602.04118" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4437" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="PEFT(Adaptor-LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="Initial-Impression-Notes.html" target="_blank" rel="noopener noreferrer">#Initial Impression Notes</a>
<span class="issue_date">Issue Date: 2026-02-05</span>
<span class="snippet"><span>GPT Summary</span>- 低ランクアダプタTinyLoRAを提案し、推論のための強化学習が低ランクパラメータ化を効果的にスケールできることを示しています。わずか13のトレーニングパラメータでQwen2.5を91％の精度に達成し、複雑なベンチマークでも少ないパラメータで90％のパフォーマンス向上を実現しました。特に、強化学習を用いることで、従来の方法よりも大幅に少ないパラメータで強力な結果を得ることができました。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/iscienceluvr/status/2019346993710039134?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>Qwen2.5に関してはLlamaと比較して異なる傾向が生じることは以下でも見受けられる。果たして本研究で報告されていることはどこまで一般的なのだろうか？:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2226" target="_blank" rel="noopener noreferrer">[Paper Note] Reasoning or Memorization? Unreliable Results of Reinforcement Learning  Due to Data Contamination, Mingqi Wu+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1997" target="_blank" rel="noopener noreferrer">[Paper Note] Spurious Rewards: Rethinking Training Signals in RLVR, Shao+, 2025.05</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="an-empirical-4414" class="title-link">[Paper Note] An Empirical Study on Noisy Data and LLM Pretraining Loss Divergence, Qizhen Zhang+, arXiv'26, 2026.02</h3><br><a href="https://arxiv.org/abs/2602.02400" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4414" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Scaling-Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<a class="button" href="DataFiltering.html" target="_blank" rel="noopener noreferrer">#DataFiltering</a>
<a class="button" href="Initial-Impression-Notes.html" target="_blank" rel="noopener noreferrer">#Initial Impression Notes</a>
<span class="issue_date">Issue Date: 2026-02-05</span>
<span class="snippet"><span>GPT Summary</span>- ノイズデータがLLMの事前学習に与える影響を体系的に分析。合成ノイズを注入した実験で、ノイズがトレーニングロスの発散を引き起こすことを実証し、依存関係を特定。高学習率による発散とは異なるパターンも観察し、診断手法を提案。ノイズの影響に関する制御された洞察を提供。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/rosinality/status/2018854167893377411?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2188" target="_blank" rel="noopener noreferrer">[Paper Note] Spike No More: Stabilizing the Pre-training of Large Language Models, Sho Takase+, COLM'25</a>
<br><br>のようにアーキテクチャの改善によって学習の安定性を担保する取り組みもあるが、アーキテクチャ側で解決した場合にノイズはどのような影響を与えるのだろうか？</p><p>takeawayが論文中にQAの形でまとめられている。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="the-cot-4409" class="title-link">[Paper Note] The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think, Seongyun Lee+, ICLR'26, 2025.05</h3><br><a href="https://arxiv.org/abs/2505.10185" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4409" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Explanation.html" target="_blank" rel="noopener noreferrer">#Explanation</a>
<a class="button" href="Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2026-02-05</span>
<span class="snippet"><span>GPT Summary</span>- CoTを分析するためのボトムアップのフレームワークを提案。モデル生成のCoTから多様な推論基準を抽出し、クラスタリングを行うことで解釈可能な分析を実施。結果、トレーニングデータの形式が推論行動に与える影響が明らかになり、より効果的な推論戦略への誘導が可能となることを示した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/wellecks/status/2018695745440743743?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="a-unified-4393" class="title-link">[Paper Note] A Unified View of Attention and Residual Sinks: Outlier-Driven Rescaling is Essential for Transformer Training, Zihan Qiu+, arXiv'26, 2026.01</h3><br><a href="https://arxiv.org/abs/2601.22966" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4393" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Normalization.html" target="_blank" rel="noopener noreferrer">#Normalization</a>
<a class="button" href="AttentionSinks.html" target="_blank" rel="noopener noreferrer">#AttentionSinks</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2026-02-03</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデルにおける外れ値の機能を調査し、注意の沈みと残差の沈みのメカニズムを明らかにする。外れ値は正規化と共に機能し、再スケーリングを通じてトレーニングの安定性を向上させ、パフォーマンスを改善。これにより、外れ値が寄与者ではなく再スケール要因であることを示し、学習可能なパラメータとの関係性を明らかにした。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/rosinality/status/2018214954734866936?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>Attention Sinksにならい、Residual Sinksと命名されている</p><p>Attention Sinksや本研究で命名されているResidual Sinks（activationの特定の次元がほとんどのトークンで過剰に大きくなる現象）は正規化を排除するとなくなり（i.e., 正規化とセットで出現する）、これらがなくなると学習の安定性と性能が低下する。これらはTransformerアーキテクチャ内の外れ値として見ることができるが、この外れ値が存在することによってnormalizationにおいてrescalingが実施され安定性やパフォーマンスが向上している、という感じらしい。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="beyond-precision-4387" class="title-link">[Paper Note] Beyond Precision: Training-Inference Mismatch is an Optimization Problem and Simple LR Scheduling Fixes It, Yaxiang Zhang+, arXiv'26, 2026.02</h3><br><a href="https://arxiv.org/abs/2602.01826" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4387" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="Scheduler.html" target="_blank" rel="noopener noreferrer">#Scheduler</a>
<a class="button" href="train-inference-gap.html" target="_blank" rel="noopener noreferrer">#train-inference-gap</a>
<a class="button" href="Initial-Impression-Notes.html" target="_blank" rel="noopener noreferrer">#Initial Impression Notes</a>
<span class="issue_date">Issue Date: 2026-02-03</span>
<span class="snippet"><span>GPT Summary</span>- 強化学習における言語モデルの訓練は不安定であり、その原因は訓練と推論の不一致にあるとされる。従来の対策では効果が薄いことが指摘され、本研究では勾配ノイズとミスマッチの連動を示し、更新サイズの縮小が効果的であることを発見。ミスマッチは動的な失敗と考え、動的に学習率を調整する新たな手法を提案。これにより、RL訓練を安定化し、不一致を抑制することができることが実証された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/rosinality/status/2018556267175030823?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>Importance SamplingやFP16に設定することによるミスマッチの解決方法でも依然として（長期の訓練などにおいて）安定性の問題が出ることをAblationで確認し、提案手法がより安定することを示しているように見える。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="the-hot-4380" class="title-link">[Paper Note] The Hot Mess of AI: How Does Misalignment Scale With Model Intelligence and Task Complexity?, Alexander Hägele+, arXiv'26, 2026.01</h3><br><a href="https://arxiv.org/abs/2601.23045" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4380" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2026-02-03</span>
<span class="snippet"><span>GPT Summary</span>- AIの機能向上に伴い、リスクも増すため、モデルの失敗のメカニズムを理解することが重要になる。具体的には、失敗が意図しない目標の追求から生じるのか、混乱した行動から生じるのかを検討。また、AIの不適合性はバイアス-バリアンス分解を通じて評価される。実験結果から、高能力なモデルはタスクにかかる時間が増すほど不適合性が高くなる傾向があり、大モデルが小モデルよりも不適合性が高い場面も確認された。これにより、高能力なAIが複雑なタスクを行う場合、予測不可能な誤行動が産業事故につながる可能性が示唆される一方、目標の一貫した追求の可能性は低いことが示される。これにより、報酬ハッキングや目標の誤仕様に対するアライメント研究の重要性が増す。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/anthropicai/status/2018481220741689581?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>- モデルの推論が長くなればなるほど、一貫性（＝予期できないエラー/misalignmentによるバイアス i.e., 全体のエラーに対する予測できないエラーの割合; Variance/Errorで測定)がなくなる<br>- モデルサイズが大きくなればなるほどEasy Taskでのみ一貫性が向上する。言い換えるとモデルの賢さと一貫性の間に、一貫した関係性はない。が、しばしば賢いモデルは一貫性に乏しい。<br><br>上記知見より、AI Safetyの観点で言うと、強力なAIがエラーを起こす時は、一貫性のある何らかの誤った目標に向かっていくようなものではなく、事故のような予測できないものになるだろう、と予測している。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="perplexity-cannot-4378" class="title-link">[Paper Note] Perplexity Cannot Always Tell Right from Wrong, Petar Veličković+, arXiv'26, 2026.01</h3><br><a href="https://arxiv.org/abs/2601.22950" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4378" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2026-02-03</span>
<span class="snippet"><span>GPT Summary</span>- パープレキシティはモデルの「驚き」を測る指標であり、損失関数や品質メトリックとして注目されている。しかし、トランスフォーマーの特性を基に、パープレキシティが適切なモデル選択指標でない可能性を示す。具体的には、特定の系列に低いパープレキシティが伴う場合、そのモデルが他の系列を正確に予測しないことを証明。また、等パープレキシティプロットの分析から、パープレキシティが必ずしも精度の向上を反映しないことも明らかにした。正確なモデル選択には自信の増加と精度の改善が必要である。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/giffmana/status/2018393065803620662?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="linear-representations-4364" class="title-link">[Paper Note] Linear representations in language models can change dramatically over a conversation, Andrew Kyle Lampinen+, arXiv'26, 2026.01</h3><br><a href="https://arxiv.org/abs/2601.20834" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4364" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="Conversation.html" target="_blank" rel="noopener noreferrer">#Conversation</a>
<a class="button" href="Interpretability.html" target="_blank" rel="noopener noreferrer">#Interpretability</a>
<a class="button" href="Initial-Impression-Notes.html" target="_blank" rel="noopener noreferrer">#Initial Impression Notes</a>
<span class="issue_date">Issue Date: 2026-02-01</span>
<span class="snippet"><span>GPT Summary</span>- 言語モデルの表現は高次の概念に対応する線形の方向を持ち、会話の中でこれらの表現が劇的に変化することを発見。具体的には、会話の初めに事実として表現された情報が最後には非事実として変わるなど、内容に依存した変化が生じる。これらの変化は、さまざまなモデルで発生し、文脈によって異なる効果を持つ可能性がある。結果は、モデルの応答が会話によって影響を受けることを示唆し、解釈可能性に課題を提示。表現の動態は、モデルの文脈適応を理解する新しい研究の方向性を示す。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/andrewlampinen/status/2016872166856278258?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>ポイント解説:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/huggingpapers/status/2017994192757162304?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>Factを扱う専用の機構を設けた方が良いのかもしれない</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="llms-are-4354" class="title-link">[Paper Note] LLMs are Greedy Agents: Effects of RL Fine-tuning on Decision-Making Abilities, Thomas Schmied+, ICLR'26, 2025.04</h3><br><a href="https://arxiv.org/abs/2504.16078" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4354" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="Test-Time-Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="Multi-Armed-Bandit.html" target="_blank" rel="noopener noreferrer">#Multi-Armed Bandit</a>
<a class="button" href="DecisionMaking.html" target="_blank" rel="noopener noreferrer">#DecisionMaking</a>
<a class="button" href="Exploration.html" target="_blank" rel="noopener noreferrer">#Exploration</a>
<span class="issue_date">Issue Date: 2026-01-31</span>
<span class="snippet"><span>GPT Summary</span>- LLMのエージェントアプリケーションにおける探求と解決の効率性を分析。最適なパフォーマンスを妨げる「知識と行動のギャップ」や貪欲性、頻度バイアスという失敗モードを特定。強化学習（RL）によるファインチューニングを提案し、探索を増加させて意思決定能力を改善。古典的な探索メカニズムとLLM特有のアプローチの両方を融合させ、効果的なファインチューニングの実現を目指す。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/m_wulfmeier/status/2017234588968399018?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>openreview:


<a href="https://openreview.net/forum?id=weUP6H5Ko9" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=weUP6H5Ko9</a>


</p><p>- greediness<br>- frequency bias<br>- the knowing-doing gap</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="even-gpt-5.2-4291" class="title-link">[Paper Note] Even GPT-5.2 Can't Count to Five: The Case for Zero-Error Horizons in Trustworthy LLMs, Ryoma Sato, arXiv'26, 2026.01</h3><br><a href="https://arxiv.org/abs/2601.15714" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4291" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2026-01-25</span>
<span class="snippet"><span>GPT Summary</span>- 信頼性のあるLLMのためのゼロエラー・ホライゾン（ZEH）を提案。ZEHはモデルがエラーなしに解決できる範囲を示し、最先端のLLM評価に有用。GPT-5.2の評価では、単純なパリティや括弧のバランスを判断できないことが示され、安全性が重要な領域での教訓となる。Qwen2.5にもZEHを適用し、精度との相関があるものの、詳細な挙動は異なることが判明。計算コストを軽減するために、ツリー構造とオンラインソフトマックスを用いた速度向上の方法も検討。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/joisino_en/status/2014829317877116934?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="the-flexibility-4263" class="title-link">[Paper Note] The Flexibility Trap: Why Arbitrary Order Limits Reasoning Potential in Diffusion Language Models, Zanlin Ni+, arXiv'26, 2026.01</h3><br><a href="https://arxiv.org/abs/2601.15165" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4263" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2026-01-22</span>
<span class="snippet"><span>GPT Summary</span>- dLLMsは任意の順序でトークンを生成できるが、この柔軟性が推論の境界を狭める可能性があることを示す。dLLMsは高不確実性トークンを回避し、解空間の早期崩壊を引き起こす傾向があり、既存のRLアプローチの前提に挑戦する。効果的な推論は、任意の順序を放棄し、GRPOを適用することで実現され、JustGRPOはその実例で、GSM8Kで89.1％の精度を達成した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/rosinality/status/2014202366313353651?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="the-assistant-4250" class="title-link">[Paper Note] The Assistant Axis: Situating and Stabilizing the Default Persona of Language Models, Christina Lu+, arXiv'26, 2026.01</h3><br><a href="https://arxiv.org/abs/2601.10387" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4250" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Personality.html" target="_blank" rel="noopener noreferrer">#Personality</a>
<span class="issue_date">Issue Date: 2026-01-20</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデルはデフォルトで「助けるアシスタント」のアイデンティティを持ち、ペルソナ空間の構造を調査することで、モデルの助ける行動と自己認識のバランスを探る。特に、「アシスタント軸」を中心にペルソナを調整することで、モデルの行動を安定化させ、有害な行動を抑制することが可能になる。この研究により、ペルソナドリフトの予測が可能となり、モデルをより一貫したペルソナに固定する方法が示唆される。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/anthropicai/status/2013356793477361991?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="reasoning-models-4243" class="title-link">[Paper Note] Reasoning Models Generate Societies of Thought, Junsol Kim+, arXiv'26, 2026.01</h3><br><a href="https://arxiv.org/abs/2601.10825" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4243" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Probing.html" target="_blank" rel="noopener noreferrer">#Probing</a>
<a class="button" href="Diversity.html" target="_blank" rel="noopener noreferrer">#Diversity</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="SparseAutoEncoder.html" target="_blank" rel="noopener noreferrer">#SparseAutoEncoder</a>
<span class="issue_date">Issue Date: 2026-01-19</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデルは、複雑な認知タスクにおいて優れた性能を発揮するが、そのメカニズムは不明瞭である。本研究では、強化された推論は計算の拡張だけでなく、異なる人格特性や専門知識を持つ内部認知視点の間のマルチエージェント相互作用によって生じることを示す。これにより、推論モデルはより広範な対立を引き起こし、視点の多様性が向上することを発見した。制御された強化学習実験により、会話行動の増加が推論精度を向上させることが明らかになり、思考の社会的組織が問題解決を効果的に行う可能性を示唆する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/rosinality/status/2013158469856063613?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>解説:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/2013732467119923252?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="are-your-4238" class="title-link">[Paper Note] Are Your Reasoning Models Reasoning or Guessing? A Mechanistic Analysis of Hierarchical Reasoning Models, Zirui Ren+, arXiv'26, 2026.01</h3><br><a href="https://arxiv.org/abs/2601.10679" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4238" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="Hierarchical.html" target="_blank" rel="noopener noreferrer">#Hierarchical</a>
<span class="issue_date">Issue Date: 2026-01-19</span>
<span class="snippet"><span>GPT Summary</span>- HRMは推論タスクで優れた性能を示すが、単純なパズルでの失敗やグロッキングダイナミクス、複数の不動点の存在を通じて推測の側面が浮き彫りになった。これを踏まえ、データ拡張、入力摂動、モデルブートストラッピングの3つの戦略を提案し、合成HRMを開発。数独エクストリームの精度を54.5％から96.9％に向上させた。分析は推論モデルのメカニズムに新しい視点を提供する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/zimingliu11/status/2012006028683186626?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="deepseek-r1-thoughtology-4226" class="title-link">[Paper Note] DeepSeek-R1 Thoughtology: Let's think about LLM Reasoning, Sara Vera Marjanović+, TMLR'26, 2025.04</h3><br><a href="https://arxiv.org/abs/2504.07128" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4226" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="TMLR.html" target="_blank" rel="noopener noreferrer">#TMLR</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2026-01-17</span>
<span class="snippet"><span>GPT Summary</span>- DeepSeek-R1は、LLMが複雑な問題に対処するための新しいアプローチを提案。直接答えを生成するのではなく、詳細な多段階推論チェーンを形成し、ユーザーに推論プロセスを公開することで思考の学問を創出。推論の長さ、コンテキストの管理、安全性の問題などに関する分析を行い、推論の「スウィートスポット」を特定。深い思考を持続的に行うが、過去の問題定式化に固執する傾向にも注意。また、対照モデルに比べて安全性の脆弱性があり、リスクを孕む可能性が示唆された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/sivareddyg/status/2011898281094176829?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>openreview:


<a href="https://openreview.net/forum?id=BZwKsiRnJI" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=BZwKsiRnJI</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="babyvision-visual-4192" class="title-link">[Paper Note] BabyVision: Visual Reasoning Beyond Language, Liang Chen+, arXiv'26, 2026.01</h3><br><a href="https://arxiv.org/abs/2601.06521" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4192" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="Initial-Impression-Notes.html" target="_blank" rel="noopener noreferrer">#Initial Impression Notes</a>
<span class="issue_date">Issue Date: 2026-01-14</span>
<span class="snippet"><span>GPT Summary</span>- MLLMは基本的な視覚タスクで人間、特に3歳児に劣る性能を示す。これを調査するために、視覚能力を評価する「BabyVision」ベンチマークを導入。388のタスクを通じて、MLLMのパフォーマンスが人間基準を大きく下回ることが確認された。具体的には、Gemini3-Pro-Previewが49.7点で、6歳や成人の平均94.1点に遠く及ばない。これにより、MLLMは基本的な視覚原理が不足していることが明らかにされ、BabyVision-Genと自動評価ツールキットも提案された。データとコードは公開されている。</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://unipat.ai/blog/BabyVision" target="_blank" rel="noopener noreferrer">https://unipat.ai/blog/BabyVision</a>


</p><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/_akhaliq/status/2011108396200837328?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>ポイント解説:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/huggingpapers/status/2011048605113581762?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>（読了前の第一印象）現在のMLLMが純粋な視覚的な推論タスクにおいて幼児以下であることを示し、既存のベンチマークの脆弱性（純粋な視覚的な推論能力を評価できていない）を指摘した上で新たなベンチマークを提案しているように見え、非常に重要な研究に見える。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="from-entropy-4145" class="title-link">[Paper Note] From Entropy to Epiplexity: Rethinking Information for Computationally Bounded Intelligence, Marc Finzi+, arXiv'26, 2026.01</h3><br><a href="https://arxiv.org/abs/2601.03220" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4145" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="OOD.html" target="_blank" rel="noopener noreferrer">#OOD</a>
<a class="button" href="Generalization.html" target="_blank" rel="noopener noreferrer">#Generalization</a>
<span class="issue_date">Issue Date: 2026-01-09</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、データから新たな情報を生成する可能性や、情報の評価方法について探求する。シャノン情報やコルモゴロフの複雑性が無力である理由を示し、情報理論における三つの矛盾する現象を特定する。新たに導入した「エピプレキシティ」は、計算制約のある観察者がデータから学べる情報を捉え、データの構造的内容を評価する手法である。これにより、情報生成のメカニズムやデータの順序依存性を明らかにし、エピプレキシティを用いたデータ選択の理論的基盤を提供する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/m_finzi/status/2008934727156453661?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>解説: 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/2009045634595344541?s=20"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>ポイント解説:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/gm8xx8/status/2010429251963797712?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="how-to-4142" class="title-link">[Paper Note] How to Set the Learning Rate for Large-Scale Pre-training?, Yunhua Zhou+, arXiv'26, 2026.01</h3><br><a href="https://arxiv.org/abs/2601.05049" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4142" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="LearningRate.html" target="_blank" rel="noopener noreferrer">#LearningRate</a>
<span class="issue_date">Issue Date: 2026-01-09</span>
<span class="snippet"><span>GPT Summary</span>- 学習率の最適設定は大規模事前学習において重要な課題であり、本研究では「フィッティング」と「トランスファー」の2つのパラダイムを用いて調査。フィッティングでは探索因子のスケーリング法則を導入し、複雑さを削減。トランスファーでは$μ$TransferをMixture of Expertsアーキテクチャに拡張し、適用範囲を広げる。実証結果は$μ$Transferのスケーラビリティに疑問を投げかけ、トレーニングの安定性と特徴学習の観点から分析を行い、モジュールごとのパラメータ調整の劣位を明らかにする。産業レベルの事前学習最適化に向けた実践ガイドラインと理論的視点を提供。</span>
<span class="snippet"><span>Comment</span><p>元ポスト: 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/rosinality/status/2009490375980011640?s=20"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="the-role-4133" class="title-link">[Paper Note] The Role of Mixed-Language Documents for Multilingual Large Language Model Pretraining, Jiandong Shao+, arXiv'26, 2026.01</h3><br><a href="https://arxiv.org/abs/2601.00364" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4133" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="CrossLingual.html" target="_blank" rel="noopener noreferrer">#CrossLingual</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2026-01-05</span>
<span class="snippet"><span>GPT Summary</span>- 多言語大規模言語モデルは、単言語の事前学習にもかかわらず優れたクロスリンガル性能を示す。バイリンガルデータの影響を調査するため、単言語コーパスと比較した結果、バイリンガルデータを除去すると翻訳性能が56%低下するが、クロスリンガルQAや推論タスクには影響が少ないことが分かった。バイリンガルデータを並行データとコードスイッチングに分類し、並行データを再導入すると翻訳性能がほぼ回復したが、コードスイッチングの貢献は小さかった。これにより、翻訳は並行データの整合性に依存し、クロスリンガル理解はバイリンガルデータなしでも可能であることが示唆された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/rosinality/status/2008029906144571392?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>これは非常に興味深い。</p><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3525" target="_blank" rel="noopener noreferrer">[Paper Note] ATLAS: Adaptive Transfer Scaling Laws for Multilingual Pretraining,
  Finetuning, and Decoding the Curse of Multilinguality, Shayne Longpre+, arXiv'25, 2025.10</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="on-the-3651" class="title-link">[Paper Note] On the Design of KL-Regularized Policy Gradient Algorithms for LLM Reasoning, Yifan Zhang+, ICLR'26, 2025.05</h3><br><a href="https://arxiv.org/abs/2505.17508" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3651" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-11-12</span>
<span class="snippet"><span>GPT Summary</span>- ポリシー勾配アルゴリズムを用いてLLMの推論能力を向上させるため、正則化ポリシー勾配（RPG）を提案。RPGは、正規化されたKLと非正規化されたKLを統一し、REINFORCEスタイルの損失の微分可能性を特定。オフポリシー設定での重要度重み付けの不一致を修正し、RPGスタイルクリップを導入することで安定したトレーニングを実現。数学的推論ベンチマークで最大6%の精度向上を達成。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/yifan_zhang_/status/1988046103301038153?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>pj page:


<a href="https://complex-reasoning.github.io/RPG/" target="_blank" rel="noopener noreferrer">https://complex-reasoning.github.io/RPG/</a>


</p><p>続報:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/yifan_zhang_/status/1999522082049097959?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>openreview:


<a href="https://openreview.net/forum?id=qe060gmfm7" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=qe060gmfm7</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="[paper-notes]-3524" class="title-link">[Paper Notes] Investigating fine- and coarse-grained structural correspondences between deep neural networks and human object image similarity judgments using unsupervised alignment, Takahashi+, Neural Networks'26, 2026.03</h3><br><a href="https://www.sciencedirect.com/science/article/pii/S0893608025011037?via%3Dihub" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3524" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="Self-SupervisedLearning.html" target="_blank" rel="noopener noreferrer">#Self-SupervisedLearning</a>
<a class="button" href="CLIP.html" target="_blank" rel="noopener noreferrer">#CLIP</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-31</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/oizumim/status/1983800844933066931?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>CLIP, 自己教師あり学習, 教師あり学習を比較したときに、CLIPが人間が獲得するobjectのrepresentationともっともalignしている一方で、自己教師あり学習はほとんど偶然レベルでしかalignしない（ただし、粗いレベルで見ると人間で言うところのカテゴリレベルのクラスタを形成することができる）。このため、テキストベースでの学習が人間が獲得する表現とfine-grainedなレベルでalignするために非常に重要であることが示唆される、という感じらしい</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="emergent-hierarchical-2758" class="title-link">[Paper Note] Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning, Haozhe Wang+, ICLR'26, 2025.09</h3><br><a href="https://arxiv.org/abs/2509.03646" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2758" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Entropy.html" target="_blank" rel="noopener noreferrer">#Entropy</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<span class="snippet"><span>GPT Summary</span>- 強化学習（RL）は大規模言語モデル（LLMs）の推論能力を向上させるが、そのメカニズムは不明。分析により、推論の階層が人間の認知に似た二段階のダイナミクスを持つことを発見。初期段階では手続き的な正確性が求められ、後に高レベルの戦略的計画が重要になる。これに基づき、HICRAというアルゴリズムを提案し、高影響の計画トークンに最適化を集中させることで性能を向上させた。また、意味的エントロピーが戦略的探求の優れた指標であることを検証した。</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://tiger-ai-lab.github.io/Hierarchical-Reasoner/" target="_blank" rel="noopener noreferrer">https://tiger-ai-lab.github.io/Hierarchical-Reasoner/</a>


</p><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/wenhuchen/status/1965783045035762076?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>ポイント解説:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/askalphaxiv/status/1968718537729405228?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>解説:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/omarsar0/status/1999483394963701911?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>openreview:


<a href="https://openreview.net/forum?id=NlkykTqAId" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=NlkykTqAId</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="the-sparse-4353" class="title-link">[Paper Note] The Sparse Frontier: Sparse Attention Trade-offs in Transformer LLMs, Piotr Nawrot+, arXiv'25, 2025.04</h3><br><a href="https://arxiv.org/abs/2504.17768" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4353" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="SparseAttention.html" target="_blank" rel="noopener noreferrer">#SparseAttention</a>
<a class="button" href="Initial-Impression-Notes.html" target="_blank" rel="noopener noreferrer">#Initial Impression Notes</a>
<span class="issue_date">Issue Date: 2026-01-30</span>
<span class="snippet"><span>GPT Summary</span>- スパースアテンションは、Transformer LLMの長文コンテキスト処理能力を向上させるが、その効率と精度のトレードオフは未評価である。本研究では、最大128Kトークンのシーケンスに対して、6つの手法を9つのタスクで分析し、スパースアテンションの効果的利用を示した。主な発見は、より大きなスパースモデルが小さな密なモデルを上回ること、トークンの重要度推定は計算制約で実現しにくいものの他の選択肢が効果的であること、長いシーケンスが高いスパース性を許容すること。これにより、スパースアテンション導入についての実践的ガイダンスを提供した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/p_nawrot/status/2017161371566178304?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>最近多くなってきたsparse attentionに関する非常に大きな実験で、かつ過去な提案されたものの分類などもされているようなのでsparse attentionに対する理解が深められそう。これは気になる。そして著者にSebastian Ruder氏の名前が。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="secret-mixtures-4245" class="title-link">[Paper Note] Secret mixtures of experts inside your LLM, Enric Boix-Adsera, arXiv'25, 2025.12</h3><br><a href="https://arxiv.org/abs/2512.18452" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4245" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<span class="issue_date">Issue Date: 2026-01-19</span>
<span class="snippet"><span>GPT Summary</span>- MLP層はトランスフォーマー内で最も理解が進んでいないが、実際にはスパースな計算を行っていると仮定。この層は、エキスパートの混合（MoE）によって良好に近似可能であり、活性化空間のMoEとスパースオートエンコーダー（SAE）との新たな理論的関連を基にしている。実験により、活性化分布が重要であることを示し、LLM内のMLP層の一般原則を明らかにした。これにより、MoEベースのアーキテクチャ設計に新たな方向性が示唆された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/aryaman2020/status/2013121115976261678?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="air-a-4237" class="title-link">[Paper Note] AIR: A Systematic Analysis of Annotations, Instructions, and Response Pairs in Preference Dataset, Bingxiang He+, arXiv'25, 2025.04</h3><br><a href="https://arxiv.org/abs/2504.03612" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4237" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2026-01-19</span>
<span class="snippet"><span>GPT Summary</span>- 好み学習の成功には、注釈、指示、応答ペアの3つの高品質なデータセットが重要ですが、従来のアプローチではこれらが混同されています。本研究では、各コンポーネントを系統的に分離・最適化し、相乗効果を評価するための分析フレームワーク「AIR」を提案します。実験により、注釈の単純さ、指示の推論安定性、応答ペアの質が行動可能な原則として明らかになり、これにより平均+5.3の性能向上が得られました。この研究は、好みデータセット設計を最適化へと導く設計図を提供します。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/openbmb/status/2012179938388926679?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="model-organisms-4204" class="title-link">[Paper Note] Model Organisms for Emergent Misalignment, Edward Turner+, arXiv'25, 2025.06</h3><br><a href="https://arxiv.org/abs/2506.11613" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4204" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="EmergentMisalignment.html" target="_blank" rel="noopener noreferrer">#EmergentMisalignment</a>
<span class="issue_date">Issue Date: 2026-01-15</span>
<span class="snippet"><span>GPT Summary</span>- Emergent Misalignment（EM）は、狭いデータセットでの大規模言語モデルの微調整が広範な不整合を引き起こす可能性を示す新たな発見である。これにより、整合性に関する理解にギャップが存在することが明らかとなった。本研究は、狭い不整合なデータセットを用いて99%の一貫性を持つモデルオーガニズムを構築することを目指し、モデルサイズにかかわらずEMの発生を示す。メカニズム的な位相転換を孤立化し、整合性リスクの理解と軽減のための基盤を提供することが重要である。</span>
</article>
<article class="paper-entry">
<h3 id="persona-features-4202" class="title-link">[Paper Note] Persona Features Control Emergent Misalignment, Miles Wang+, arXiv'25, 2025.06</h3><br><a href="https://arxiv.org/abs/2506.19823" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4202" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="Supervised-FineTuning-(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="SparseAutoEncoder.html" target="_blank" rel="noopener noreferrer">#SparseAutoEncoder</a>
<a class="button" href="EmergentMisalignment.html" target="_blank" rel="noopener noreferrer">#EmergentMisalignment</a>
<span class="issue_date">Issue Date: 2026-01-15</span>
<span class="snippet"><span>GPT Summary</span>- 言語モデルの行動一般化はAIの安全性にとって重要であり、Betleyらの研究により、GPT-4oのファインチューニングが新たな不一致を引き起こすことが判明。これを拡張し、強化学習や合成データセットのファインチューニングでも同様の不一致を確認。スパースオートエンコーダーを用いたモデル差分比較により、不一致的ペルソナ特徴が特定され、有毒ペルソナが強い影響を与えることが示された。さらに、数百の無害なサンプルでファインチューニングすることで新たな不一致を緩和し、整合性を回復できることが発見された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/mileskwang/status/1935383921983893763?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4203" target="_blank" rel="noopener noreferrer">[Paper Note] Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs, Jan Betley+, arXiv'25, 2025.02</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="an-empirical-4174" class="title-link">[Paper Note] An Empirical Study of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning, Yun Luo+, IEEE Transactions on Audio, Speech and Language Processing'25, 2023.08</h3><br><a href="https://arxiv.org/abs/2308.08747" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4174" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Supervised-FineTuning-(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="Catastrophic-Forgetting.html" target="_blank" rel="noopener noreferrer">#Catastrophic Forgetting</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2026-01-12</span>
<span class="snippet"><span>GPT Summary</span>- 破滅的忘却（CF）は、機械学習モデルが新しい知識を学ぶ際に以前の情報を忘れる現象であり、特に大規模言語モデル（LLMs）において調査されました。実験により、1bから7bパラメータのLLMsでCFが一般的に観察され、モデルのスケールが増すほど忘却が深刻化することが明らかになりました。デコーダ専用モデルのBLOOMZは、エンコーダ-デコーダモデルのmT0よりも忘却が少なく、知識を保持しています。また、LLMsは継続的なファインチューニング中に言語バイアスを軽減できることも示され、一般的な指示調整が忘却現象を軽減する可能性があることが示唆されました。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/cwolferesearch/status/2010480993052803509?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="retaining-by-4173" class="title-link">[Paper Note] Retaining by Doing: The Role of On-Policy Data in Mitigating Forgetting, Howard Chen+, arXiv'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.18874" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4173" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Supervised-FineTuning-(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Catastrophic-Forgetting.html" target="_blank" rel="noopener noreferrer">#Catastrophic Forgetting</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2026-01-12</span>
<span class="snippet"><span>GPT Summary</span>- ポストトレーニングにおける「破滅的忘却」を軽減するためのガイドラインを提案。監視付きファインチューニング（SFT）と強化学習（RL）の忘却パターンを比較した結果、RLはSFTよりも忘却が少なく、同等以上のパフォーマンスを示すことが判明。RLの特性が以前の知識を保持する理由を探り、オンポリシーデータの使用がその要因であることを確認。近似的なオンポリシーデータの利用が忘却を軽減する可能性を示唆。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/cwolferesearch/status/2010480993052803509?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="reinforcement-fine-tuning-4172" class="title-link">[Paper Note] Reinforcement Fine-Tuning Naturally Mitigates Forgetting in Continual Post-Training, Song Lai+, arXiv'25, 2025.07</h3><br><a href="https://arxiv.org/abs/2507.05386" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4172" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Supervised-FineTuning-(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Catastrophic-Forgetting.html" target="_blank" rel="noopener noreferrer">#Catastrophic Forgetting</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2026-01-12</span>
<span class="snippet"><span>GPT Summary</span>- 継続的ポストトレーニング（CPT）における監視付きファインチューニング（SFT）と強化ファインチューニング（RFT）の影響を比較。SFTは以前の知識を忘却させるが、RFTは知識を保持し、マルチタスクトレーニングに匹敵する性能を発揮。RFTはモデルの一般的な知識を保護・向上させる一方、SFTは低下させる。RFTの安定性は暗黙の正則化メカニズムによるもので、データ依存の正則化因子として機能。RFTの効率を向上させるアルゴリズムも提案。RFTの優位性を示す研究。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/cwolferesearch/status/2010480993052803509?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="shape-of-4168" class="title-link">[Paper Note] Shape of Thought: When Distribution Matters More than Correctness in Reasoning Tasks, Abhranil Chandra+, arXiv'25, 2025.12</h3><br><a href="https://arxiv.org/abs/2512.22255" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4168" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Supervised-FineTuning-(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2026-01-11</span>
<span class="snippet"><span>GPT Summary</span>- 言語モデルの推論能力は、連鎖的思考（CoT）トレースの合成データセットでの訓練によって向上することが示された。合成データはモデル自身の分布に近く、学習に適応しやすい。また、不正確なトレースでも有効な推論ステップを含むことが多い。人間の注釈データを言い換えることでパフォーマンスが向上し、欠陥のあるトレースに対する耐性も研究された。MATH、GSM8K、Countdown、MBPPデータセットを用いて、モデルの分布に近いデータセットの重要性と、正しい最終回答が必ずしも信頼できる推論プロセスの指標ではないことが示された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/agarwl_/status/2009995065243116006?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>base modelの分布と近いStronger Modelから合成されたCoTデータでSFTすると、合成データの応答がincorrectであっても性能が向上する。分布が遠い人間により生成されたCoTで訓練するより性能改善の幅は大きく、人間が作成したCoTをparaphraseしモデルの分布に近づけると性能の上昇幅は改善する(Figure1, Table4, 5)。<br><br><img src="https://github.com/user-attachments/assets/36cc6db9-36bf-4193-9b56-a127a0112df3" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="deep-sequence-4129" class="title-link">[Paper Note] Deep sequence models tend to memorize geometrically; it is unclear why, Shahriar Noroozizadeh+, arXiv'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.26745" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4129" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="Memorization.html" target="_blank" rel="noopener noreferrer">#Memorization</a>
<a class="button" href="FactualKnowledge.html" target="_blank" rel="noopener noreferrer">#FactualKnowledge</a>
<a class="button" href="Geometric.html" target="_blank" rel="noopener noreferrer">#Geometric</a>
<span class="issue_date">Issue Date: 2026-01-05</span>
<span class="snippet"><span>GPT Summary</span>- 深層系列モデルは、エンティティ間の新しいグローバルな関係を幾何学的記憶として保存することを提案。これにより、難しい推論タスクが簡単なナビゲーションタスクに変換されることを示す。ブルートフォース検索よりも複雑な幾何学が学習されることを主張し、Node2Vecとの関連を分析して、自然に生じるスペクトルバイアスからこの幾何学が生まれることを示す。Transformerメモリの幾何学的強化の可能性を指摘し、知識獲得や忘却に関する直感を再考することを促す。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/dair_ai/status/2005480659209400789?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="why-low-precision-4128" class="title-link">[Paper Note] Why Low-Precision Transformer Training Fails: An Analysis on Flash Attention, Haiquan Qiu+, arXiv'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.04212" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4128" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<span class="issue_date">Issue Date: 2026-01-03</span>
<span class="snippet"><span>GPT Summary</span>- 低精度フォーマットのトランスフォーマーモデルのトレーニングにおける不安定性の原因を分析し、フラッシュアテンションが損失の爆発を引き起こすメカニズムを明らかにした。具体的には、低ランク表現の出現と丸め誤差の累積がエラーの悪循環を生むことを示した。これを受けて、丸め誤差を軽減する修正を加えることでトレーニングの安定性を向上させ、実用的な解決策を提供した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/fleetwood___/status/2006820246259441820?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="evaluating-parameter-4111" class="title-link">[Paper Note] Evaluating Parameter Efficient Methods for RLVR, Qingyu Yin+, arXiv'25, 2025.12</h3><br><a href="https://arxiv.org/abs/2512.23165" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4111" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="PEFT(Adaptor-LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2026-01-02</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、検証可能な報酬を伴う強化学習（RLVR）におけるパラメータ効率の良いファインチューニング（PEFT）手法を評価し、12以上の手法を比較しました。結果として、DoRAやAdaLoRAなどの構造的変種がLoRAを上回ること、SVDに基づく初期化戦略におけるスペクトル崩壊現象を発見し、極端なパラメータ削減が推論能力を制約することを示しました。これにより、パラメータ効率の良いRL手法の探求に向けたガイドを提供します。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/mikastars39/status/2006264256795464108?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3199" target="_blank" rel="noopener noreferrer">[Paper Note] DoRA: Weight-Decomposed Low-Rank Adaptation, Shih-Yang Liu+, ICML'24, 2024.02</a>
</p><p>RLVRにおけるLoRAとLoRAの変種に関する性能を調査した研究のようである。ベースモデルとしてDeepSeekw-R1-Distilled-Qwen系モデルのみ, データのドメインとしてMathでのみ実験されている点には留意した方が良いと思われ、他のモデル・ドメインにも同様の知見が適用できるかは気になる。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="professional-software-4102" class="title-link">[Paper Note] Professional Software Developers Don't Vibe, They Control: AI Agent Use for Coding in 2025, Ruanqianqian Huang+, arXiv'25, 2025.12</h3><br><a href="https://arxiv.org/abs/2512.14012" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4102" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<span class="issue_date">Issue Date: 2025-12-31</span>
<span class="snippet"><span>GPT Summary</span>- 経験豊富な開発者は、AIエージェントを生産性向上の手段として評価しつつも、ソフトウェアの品質を重視し、自らの主体性を保ちながらエージェントを活用している。彼らはエージェントの行動を制御する戦略を採用し、エージェントの限界を補完する自信からポジティブな感情を抱いている。本研究は、エージェントの効果的な活用に向けたベストプラクティスや適したタスクの種類を示唆し、将来のエージェントインターフェースや使用ガイドラインの機会を指摘する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/omarsar0/status/2006063755449504154?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="schoenfeld's-anatomy-4078" class="title-link">[Paper Note] Schoenfeld's Anatomy of Mathematical Reasoning by Language Models, Ming Li+, arXiv'25, 2025.12</h3><br><a href="https://arxiv.org/abs/2512.19995" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4078" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<span class="issue_date">Issue Date: 2025-12-27</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、Schoenfeldのエピソード理論を基にしたThinkARMというフレームワークを提案し、推論の痕跡を明示的に抽象化します。このフレームワークを用いることで、数学的問題解決における再現可能な思考のダイナミクスや推論モデルと非推論モデルの違いを明らかにします。また、探索が正確性に寄与する重要なステップであることや、効率重視の手法が評価フィードバックを選択的に抑制することを示すケーススタディを提示します。これにより、現代の言語モデルにおける推論の構造と変化を体系的に分析することが可能になります。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/huggingpapers/status/2004524949520671021?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="generation-is-4063" class="title-link">[Paper Note] Generation is Required for Data-Efficient Perception, Jack Brady+, arXiv'25, 2025.12</h3><br><a href="https://arxiv.org/abs/2512.08854" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4063" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="Generalization.html" target="_blank" rel="noopener noreferrer">#Generalization</a>
<a class="button" href="Encoder.html" target="_blank" rel="noopener noreferrer">#Encoder</a>
<a class="button" href="Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<span class="issue_date">Issue Date: 2025-12-24</span>
<span class="snippet"><span>GPT Summary</span>- 生成的アプローチが人間レベルの視覚認知に必要かを検討。生成的手法は帰納的バイアスを容易に強制でき、構成的一般化を実現可能。一方、非生成的手法は一般化に苦労し、大規模な事前学習が必要。生成的手法はデコーダの逆転を通じて構成的一般化を改善し、追加データなしで効果を発揮。</span>
<span class="snippet"><span>Comment</span><p>元ポスト: 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/kwangmoo_yi/status/2003590903848747364?s=20"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="the-adoption-3933" class="title-link">[Paper Note] The Adoption and Usage of AI Agents: Early Evidence from Perplexity, Jeremy Yang+, arXiv'25, 2025.12</h3><br><a href="https://arxiv.org/abs/2512.07828" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3933" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<span class="issue_date">Issue Date: 2025-12-12</span>
<span class="snippet"><span>GPT Summary</span>- 本研究は、オープンワールドのウェブ環境で動作する汎用AIエージェントの使用状況に関する大規模フィールドスタディを行い、特にCometとComet Assistantに焦点を当てています。数億件のユーザーインタラクションを分析し、AIエージェントの採用者、使用強度、使用目的に関する異質性を明らかにしました。特に、早期採用者や高教育水準の国のユーザーが多く利用しており、主な使用目的は生産性や学習に関連しています。使用事例は短期的には定着性を示すものの、時間と共に認知的なトピックへのシフトが見られます。この研究は、AIエージェントの普及がもたらす影響について新たな研究の方向性を示唆しています。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/dair_ai/status/1999117070576058415?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>AI Agentの利用者層と用途に関する分析</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="rl-grokking-3914" class="title-link">[Paper Note] RL Grokking Recipe: How Does RL Unlock and Transfer New Algorithms in LLMs?, Yiyou Sun+, arXiv'25, 2025.09</h3><br><a href="https://arxiv.org/abs/2509.21016" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3914" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Grokking.html" target="_blank" rel="noopener noreferrer">#Grokking</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<span class="issue_date">Issue Date: 2025-12-09</span>
<span class="snippet"><span>GPT Summary</span>- DELTA-Codeを導入し、LLMの学習可能性と移転可能性を評価する。合成コーディング問題を用いて、RL訓練されたモデルが新しい推論戦略を獲得できるかを探る。実験では、報酬がほぼゼロの後に急激な精度向上が見られ、段階的ウォームアップやカリキュラムトレーニングが重要であることが示された。移転可能性の評価では、ファミリー内での向上が見られる一方、変革的なケースでは弱点が残る。DELTAは新しいアルゴリズムスキルの獲得を理解するためのテストベッドを提供する。</span>
</article>
<article class="paper-entry">
<h3 id="reinforcement-learning-3913" class="title-link">[Paper Note] Reinforcement Learning with Verifiable Rewards Implicitly Incentivizes Correct Reasoning in Base LLMs, Xumeng Wen+, arXiv'25, 2025.06</h3><br><a href="https://arxiv.org/abs/2506.14245" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3913" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<span class="issue_date">Issue Date: 2025-12-09</span>
<span class="snippet"><span>GPT Summary</span>- RLVRがLLMの推論能力に与える影響を体系的に調査し、数学的およびコーディングタスクでの推論の境界を拡張できることを示す。新しい評価指標CoT-Pass@Kを導入し、正しい推論を促進する理論的枠組みを提示。初期段階での正しい推論の奨励が推論の質を大幅に改善することを確認。RLVRの可能性に関する強力な証拠を提供。</span>
</article>
<article class="paper-entry">
<h3 id="on-the-3912" class="title-link">[Paper Note] On the Interplay of Pre-Training, Mid-Training, and RL on Reasoning Language Models, Charlie Zhang+, arXiv'25, 2025.12</h3><br><a href="https://arxiv.org/abs/2512.07783" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3912" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="PRM.html" target="_blank" rel="noopener noreferrer">#PRM</a>
<a class="button" href="KeyPoint-Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="Reference-Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-12-09</span>
<span class="snippet"><span>GPT Summary</span>- 強化学習（RL）が言語モデルの推論能力を向上させるかどうかを検証するため、事前トレーニング、中間トレーニング、RLの因果的寄与を分離する実験フレームワークを開発。RLは事前トレーニングが十分な余地を残す場合にのみ真の能力向上をもたらし、文脈的一般化には適切な事前トレーニングが必要であることを示した。また、中間トレーニングがRLよりもパフォーマンスを向上させ、プロセスレベルの報酬が推論の忠実性を高めることを明らかにした。これにより、推論LMトレーニング戦略の理解と改善に寄与する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/rosinality/status/1998258101494112299?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>RLはモデルの能力を精錬させる（＝事前学習時に既に身についているreasoningパターンを（探索空間を犠牲により少ない試行で良い応答に辿り着けるよう）増幅させる;サンプリング効率を向上させる）と主張する研究たちと<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3589" target="_blank" rel="noopener noreferrer">[Paper Note] Does Reinforcement Learning Really Incentivize Reasoning Capacity in   LLMs Beyond the Base Model?, Yang Yue+, NeurIPS'25, 2025.04</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2272" target="_blank" rel="noopener noreferrer">[Paper Note] The Invisible Leash: Why RLVR May Not Escape Its Origin, Fang Wu+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1997" target="_blank" rel="noopener noreferrer">[Paper Note] Spurious Rewards: Rethinking Training Signals in RLVR, Shao+, 2025.05</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1746" target="_blank" rel="noopener noreferrer">[Paper Note] Demystifying Long Chain-of-Thought Reasoning in LLMs, Edward Yeo+, arXiv'25</a>
<br><br>RLは事前学習で身につけたreasoning能力を超えてさらなるgainを得ることができる<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3913" target="_blank" rel="noopener noreferrer">[Paper Note] Reinforcement Learning with Verifiable Rewards Implicitly Incentivizes Correct Reasoning in Base LLMs, Xumeng Wen+, arXiv'25, 2025.06</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2712" target="_blank" rel="noopener noreferrer">From f(x) and g(x) to f(g(x)): LLMs Learn New Skills in RL by Composing Old Ones, Yuan+, 2025.09</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3912" target="_blank" rel="noopener noreferrer">[Paper Note] On the Interplay of Pre-Training, Mid-Training, and RL on Reasoning Language Models, Charlie Zhang+, arXiv'25, 2025.12</a>
<br><br>という対立する主張がliteratureで主張されているが、これは学習環境が制御されたものでないことに起因しており（＝何が事前学習で既に獲得されていて、事後学習後に新規で獲得された能力なのか、既存の能力の精錬なのか弁別がつかない）、かつ最近のmid-trainingの隆盛(<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2107" target="_blank" rel="noopener noreferrer">[Paper Note] OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling, Zengzhi Wang+, arXiv'25</a>
)を鑑みたときに、事前・中間・事後学習は互いにどのように作用しているのか？という疑問に応えることは重要であり、そのためのフレームワークを提案し分析した、という話な模様。非常に興味深い。takeawayはabstに書かれている通りなようだが、読みたい。</p><p>フレームワークは事前・中間・事後学習の個々の貢献を独立して測定できるフレームワークであり、<br>- 完全に制御された（明示的なアトミックなoperationに基づく）合成reasoningタスク<br><br>あとで書く</p><p>著者ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/xiangyue96/status/1998488030836044112?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><br>takeaway1の話は、最近のRLにおける動的な難易度調整にも絡んでくる知見に見える。<br>takeaway2,3のRLはatomic skillを追加で学習することはできず、compositional skillを学習しcontextual generalizationを実現する、同等のbadgetの元でmid training+RLがpure RLよりも性能改善する、というのは特に興味深く、事後学習の効用を最大化するためにも事前・中間学習が（以前から言われていた通り）重要であることが示唆される。<br>takeaway4のPRMがreasoningのfidelityを高めるという話は、DeepSeek-V3.2でも観測されている話であり、本研究によってそれが完全に制御された実験の元示されたことになる。</p><p>RQ: 実データにおいて、事前学習時点だとPerplexityかdownstream taskの性能をwatchすると思うのだが、それらを通じてatomic skillをLLMがどれだけ身に付けられているか、というのはどれだけ測れているのだろうか、あるいはより良い方法はあるのだろうか</p><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2758" target="_blank" rel="noopener noreferrer">[Paper Note] Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning, Haozhe Wang+, ICLR'26, 2025.09</a>
<br><br>（＝RLの序盤は低レベルな手続的な実行（計算や公式）を習得し、その後高レベルな戦略的なplanningの学習が生じる）とはどのような関係があるだろうか。</p><p>解説:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/theturingpost/status/2002555031942226127?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>所見:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/rasbt/status/2007122635507880251?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>解説:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/2013370634592731453?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="measuring-agents-3902" class="title-link">[Paper Note] Measuring Agents in Production, Melissa Z. Pan+, arXiv'25, 2025.12</h3><br><a href="https://arxiv.org/abs/2512.04123" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3902" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="KeyPoint-Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-12-07</span>
<span class="snippet"><span>GPT Summary</span>- AIエージェントの実世界での展開に関する初の大規模研究を行い、306人の実務者への調査と20件のケーススタディを実施。エージェントはシンプルなアプローチで構築され、68%が最大10ステップで人間の介入を必要とし、70%が市販モデルをプロンプトし、74%が人間評価に依存。信頼性が主要な課題であるが、効果的な方法が多くの業界での影響を可能にしている。本研究は実践の現状を文書化し、研究と展開のギャップを埋めることを目指す。</span>
<span class="snippet"><span>Comment</span><p>これは非常に興味深い。production環境で実際に動作しているAI Agentに関して306人の実務者に対してアンケートを実施して、26ドメインに対して20個のケーススタディを実施したとのこと。<br>信頼性の問題から、実行する際のstep数はまだ10未満であり、多くのagentな5ステップ未満のステップしか完了せず、70%はoff the shelfモデルに対するprompting（finetuningなし）で実現されている。<br><br>モデルは17/20でClaude/o3等のproprietaryモデルでopen weightモデルの採用は、データを外部ソースに投げられない場合や、非常に高いワークロードのタスクを回す場合に限定される。<br><br>61%の調査の回答者がagenticなフレームワークとしてLangChain等のサードパーティ製フレームワークを利用していると回答したが、85%の実装チームはスクラッチから実装しているらしい。<br><br>80%のケーススタディがワークフロー自動構築ではなく、事前に定義されたワークフローを実施。<br><br>73%が生産性向上を目的に利用（＝人手作業の自動化）<br><br>評価が非常に大変で、そもそもドメイン特化のデータセットがなく自前で構築することになる。とあるチームは100サンプルを構築するのに半年を要した。また、決定的ではない挙動や、outputの判定の困難さによりCI/CDパイプラインに組み込めない。<br>74%がhuman in the loopを用いた評価を実施。52%がLLM as a Judgeを活用しているが人手によるチェックも併用。<br><br>元ポストをざっと読んだだけで、かつ論文読めていないので誤りあるかも。しかし興味深い。読みたい。<br></p><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/dair_ai/status/1997366943536554368?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="do-language-3888" class="title-link">[Paper Note] Do Language Models Use Their Depth Efficiently?, Róbert Csordás+, arXiv'25, 2025.05</h3><br><a href="https://arxiv.org/abs/2505.13898" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3888" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="Depth.html" target="_blank" rel="noopener noreferrer">#Depth</a>
<span class="issue_date">Issue Date: 2025-12-04</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデル（LLM）の深さと性能の関係を分析した結果、後半の層は前半の層に比べて貢献度が低く、後半の層をスキップしても影響は小さいことが分かった。また、深いモデルは新しい計算を行っているのではなく、同じ計算を多くの層に分散させていることが示唆された。このことは、深さの増加がリターンの減少をもたらす理由を説明するかもしれない。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/robert_csordas/status/1996231914659696718?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>RLとネットワークの深さの関係性を分析した研究もある:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3859" target="_blank" rel="noopener noreferrer">[Paper Note] 1000 Layer Networks for Self-Supervised RL: Scaling Depth Can Enable New Goal-Reaching Capabilities, Wang+, NeurIPS'25 Best Paper Awards</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="what-makes-3882" class="title-link">[Paper Note] What Makes a Reward Model a Good Teacher? An Optimization Perspective, Noam Razin+, NeurIPS'25 Spotlight, 2025.03</h3><br><a href="https://arxiv.org/abs/2503.15477" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3882" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="RewardModel.html" target="_blank" rel="noopener noreferrer">#RewardModel</a>
<a class="button" href="KeyPoint-Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-12-03</span>
<span class="snippet"><span>GPT Summary</span>- 報酬モデルの質はRLHFの成功に重要であり、精度だけでは不十分であることを示す。低い報酬の分散は平坦な最適化ランドスケープを引き起こし、完全に正確なモデルでも遅い最適化を招く可能性がある。異なる言語モデルに対する報酬モデルの効果も異なり、精度に基づく評価の限界を明らかにする。実験により、報酬の分散と精度の相互作用が確認され、効率的な最適化には十分な分散が必要であることが強調される。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/noamrazin/status/1902780390106075186?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>RLHFにおいてReward Modelが良い教師となれるかどうかは、Accuracy[^1]という単一次元で決まるのではなく、報酬の分散の大きさ[^2]も重要だよという話らしく、分散がほとんどない完璧なRMで学習すると学習が進まず、より不正確で報酬の分散が大きいRMの方が性能が良い。報酬の分散の大きさはベースモデルによるのでRM単体で良さを測ることにはげんかいがあるよ、といあ話らしい。<br><br>理想的な報酬の形状は山の頂上がなるべくズレておらず（＝Accuracyが高い）かつ、山が平坦すぎない（＝報酬の分散が高い）ようなものであり、<br>Accuracyが低いとReward Hackingが起きやすくなり、報酬の分散が低いと平坦になり学習効率が悪くなる（Figure1)。<br><br>[^1]: 応答Aが応答Bよりも優れているかという観点<br>[^2]: 学習対象のLLMがとりそうな出力に対して、RMがどれだけ明確に差をつけて報酬を与えられるかという観点（良い応答と悪い応答の弁別）<br><br></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="artificial-hivemind-3878" class="title-link">[Paper Note] Artificial Hivemind: The Open-Ended Homogeneity of Language Models （and Beyond）, Liwei Jiang+, NeurIPS'25 Best Paper Award, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.22954" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3878" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="Mindset.html" target="_blank" rel="noopener noreferrer">#Mindset</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Diversity.html" target="_blank" rel="noopener noreferrer">#Diversity</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-12-03</span>
<span class="snippet"><span>GPT Summary</span>- Infinity-Chatは、26,000件の多様なオープンエンドユーザークエリからなるデータセットで、言語モデル（LM）の出力の多様性を評価するための新たなリソースを提供する。包括的な分類法を提案し、LMにおけるモード崩壊や人工的ハイヴマインド効果を明らかにした。調査結果は、LMの生成が人間の好みに適切に調整されていないことを示し、AI安全リスクの軽減に向けた今後の研究の重要な洞察を提供する。</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=saDOrrnNTz" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=saDOrrnNTz</a>


</p><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/stanfordnlp/status/1995638889873375664?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>これはまさに今日Geminiと壁打ちしている時に感じたなあ。全人類が同じLLMを使って壁打ちしたらどうなるんだろうと。同じような思考や思想を持つのではないか、あるいは偏っていないと思い込んでいるけど実は暗黙的に生じている応答のバイアスとか、そういう懸念。（読みたい）</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="from-atomic-3866" class="title-link">[Paper Note] From Atomic to Composite: Reinforcement Learning Enables Generalization in Complementary Reasoning, Sitao Cheng+, arXiv'25, 2025.12</h3><br><a href="https://arxiv.org/abs/2512.01970" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3866" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Composition.html" target="_blank" rel="noopener noreferrer">#Composition</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-12-02</span>
<span class="snippet"><span>GPT Summary</span>- RLは推論の合成器として機能し、内部知識と外部情報を統合する能力を持つが、まずは原子的スキルを習得する必要がある。SFTモデルは分布内では高精度だが、分布外では一般化に失敗することが示された。RLを適用することで、複雑な推論タスクの一般化が可能になる道を示唆。</span>
<span class="snippet"><span>Comment</span><p>解説:<br>



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/cwolferesearch/status/2015217615032005026?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>LLMはRLを適用する前にアトミックなスキルを身につけている場合のみ、RLによってそれらスキルを組み合わせてタスクを解く能力を身につける（構成性）。一方、構成的なスキルをSFTでただ模倣しているだけで、内部的にアトミックなスキルとして身につけられていない場合は、RLによってそれを増幅することはできるが、新たなアトミックスキルの構成は身につけることができない、といった趣旨の話だと思われる。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="is-clip-3852" class="title-link">[Paper Note] Is CLIP ideal? No. Can we fix it? Yes, Raphi Kang+, arXiv'25, 2025.03</h3><br><a href="https://arxiv.org/abs/2503.08723" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3852" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="CLIP.html" target="_blank" rel="noopener noreferrer">#CLIP</a>
<span class="issue_date">Issue Date: 2025-11-30</span>
<span class="snippet"><span>GPT Summary</span>- CLIPの潜在空間は複雑な視覚-テキストの相互作用を処理できないことが知られており、最近の研究はその欠点に対処しようとしている。私たちはCLIPの幾何学的特性を分析し、基本的な記述、属性の結合、空間的位置、否定を同時に表現できる共同埋め込み空間は存在しないことを証明した。これに基づき、Dense Cosine Similarity Maps (DCSMs)を提案し、CLIPの制限を解決する解釈可能なスコアリング手法を提供する。この手法は、従来のCLIPモデルの性能を向上させる。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/bilzrd/status/1994348630916964443?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="why-diffusion-3844" class="title-link">[Paper Note] Why Diffusion Models Don't Memorize: The Role of Implicit Dynamical Regularization in Training, Tony Bonnaire+, NeurIPS'25 Best Paper Awards, 2025.05</h3><br><a href="https://arxiv.org/abs/2505.17638" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3844" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="Memorization.html" target="_blank" rel="noopener noreferrer">#Memorization</a>
<a class="button" href="Generalization.html" target="_blank" rel="noopener noreferrer">#Generalization</a>
<span class="issue_date">Issue Date: 2025-11-29</span>
<span class="snippet"><span>GPT Summary</span>- 拡散モデルのトレーニングダイナミクスを調査し、一般化から記憶への移行における2つの時間スケール（$τ_\mathrm{gen}$と$τ_\mathrm{mem}$）を特定。$τ_\mathrm{mem}$はトレーニングセットのサイズに線形に増加し、一般化が可能なトレーニング時間のウィンドウが拡大することを示す。これにより、過学習が消失する閾値が存在し、記憶を回避できることが明らかに。実験と理論分析により結果が支持される。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/alfredplpl/status/1994020128980390157?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>openreview:


<a href="https://openreview.net/forum?id=BSZqpqgqM0" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=BSZqpqgqM0</a>


</p><p>日本語解説:


<a href="https://www.docswell.com/s/DeepLearning2023/59MQLY-2025-11-11-132245" target="_blank" rel="noopener noreferrer">https://www.docswell.com/s/DeepLearning2023/59MQLY-2025-11-11-132245</a>


</p><p>ポイント解説:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/mi141/status/1996139908633911480?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="nemotron-flash-towards-3790" class="title-link">[Paper Note] Nemotron-Flash: Towards Latency-Optimal Hybrid Small Language Models, Yonggan Fu+, arXiv'25, 2025.11</h3><br><a href="https://arxiv.org/abs/2511.18890" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3790" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="EvolutionaryAlgorithm.html" target="_blank" rel="noopener noreferrer">#EvolutionaryAlgorithm</a>
<a class="button" href="Latency.html" target="_blank" rel="noopener noreferrer">#Latency</a>
<span class="issue_date">Issue Date: 2025-11-25</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、小型言語モデル（SLMs）の実デバイスにおけるレイテンシの主要な決定要因を特定し、SLM設計とトレーニングの原則を提供します。深さ-幅比とオペレーター選択がレイテンシに影響を与えることを示し、深く細いモデルが一般的に良好な精度を達成する一方で、必ずしも精度-レイテンシのトレードオフの最前線に位置しないことを発見しました。効率的なアテンションの代替手段を評価し、ハイブリッドSLM内での最適なオペレーターの組み合わせを進化的探索フレームワークで発見。これにより、Nemotron-Flashという新しいSLMファミリーを導入し、精度が平均+5.5%向上し、レイテンシが1.3倍/1.9倍低下、スループットが18.7倍/45.6倍向上しました。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/rosinality/status/1993164873178792213?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="why-do-3784" class="title-link">[Paper Note] Why Do Language Model Agents Whistleblow?, Kushal Agrawal+, arXiv'25, 2025.11</h3><br><a href="https://arxiv.org/abs/2511.17085" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3784" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-11-24</span>
<span class="snippet"><span>GPT Summary</span>- LLMをエージェントとして展開する際の内部告発行動を調査。内部告発の頻度はモデルによって異なり、タスクの複雑さが増すと傾向が低下。道徳的行動を促すプロンプトで内部告発率が上昇し、明確な手段を提供すると低下。評価認識のテストにより、データセットの堅牢性を確認。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/papers_anon/status/1992788112712565085?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>興味深い</p><p>所見（OLMo関係者）:<br>



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/saurabh_shah2/status/1992652321600217370?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="intelligence-per-3678" class="title-link">[Paper Note] Intelligence per Watt: Measuring Intelligence Efficiency of Local AI, Jon Saad-Falcon+, arXiv'25, 2025.11</h3><br><a href="https://arxiv.org/abs/2511.07885" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3678" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-11-14</span>
<span class="snippet"><span>GPT Summary</span>- ローカルLMが実世界のクエリに正確に回答できるかを評価するため、タスクの精度を電力単位で割った「ワットあたりの知能（IPW）」を提案。20以上のローカルLMと8つのアクセラレーターを用いた実証研究により、ローカルLMは88.7%の精度でクエリに応答し、IPWは5.3倍改善、カバレッジは23.2%から71.3%に上昇。ローカルアクセラレーターはクラウドよりも低いIPWを達成し、ローカル推論が中央集権型インフラから需要を再分配できる可能性を示唆。IPWプロファイリングハーネスも公開。</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://hazyresearch.stanford.edu/blog/2025-11-11-ipw" target="_blank" rel="noopener noreferrer">https://hazyresearch.stanford.edu/blog/2025-11-11-ipw</a>


</p><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/azaliamirh/status/1988733361100325100?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>この切り口は興味深い。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="beyond-accuracy-3665" class="title-link">[Paper Note] Beyond Accuracy: Dissecting Mathematical Reasoning for LLMs Under Reinforcement Learning, Jiayu Wang+, NeurIPS'25, 2025.06</h3><br><a href="https://arxiv.org/abs/2506.04723" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3665" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-11-13</span>
<span class="snippet"><span>GPT Summary</span>- 強化学習（RL）は言語モデルの推論性能を向上させるが、そのメカニズムは未解明。SPARKLEフレームワークを用いて、RLの効果を計画遵守、知識統合、サブ問題連鎖の3次元で分析。RL調整モデルは外部計画に依存せず、内部戦略の形成を促進し、知識統合能力を向上させることが示された。難しい問題に対しては、SparkleRL-PSSというマルチステージRLパイプラインを提案し、データ生成なしで効果的な探索を実現。これにより、推論タスクのための適応的で効率的なRLパイプライン構築のための洞察が得られる。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/jiayuwang111/status/1988675960288280928?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>RLを実施したモデルは与えられた計画を実施することに関してよりロバストで、自分でプランニングさせて解かせることもでき、かつ外部・モデル内部のパラメータに内在する知識を統合して応答する能力も向上する。しかし、大きな問題を部分問題に分割して解く能力には課題が残る、みたいな話らしい。</p><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3664" target="_blank" rel="noopener noreferrer">[Paper Note] Reinforcement Learning Improves Traversal of Hierarchical Knowledge in LLMs, Renfei Zhang+, arXiv'25, 2025.11</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="reinforcement-learning-3664" class="title-link">[Paper Note] Reinforcement Learning Improves Traversal of Hierarchical Knowledge in LLMs, Renfei Zhang+, arXiv'25, 2025.11</h3><br><a href="https://arxiv.org/abs/2511.05933" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3664" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Supervised-FineTuning-(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Memorization.html" target="_blank" rel="noopener noreferrer">#Memorization</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-11-13</span>
<span class="snippet"><span>GPT Summary</span>- 強化学習（RL）は、階層的な知識を必要とするタスクにおいて、基盤モデルや教師あり微調整（SFT）モデルを上回る性能を示す。これは新たなデータからではなく、既存の知識をナビゲートするスキルの向上によるものである。構造化プロンプティングを用いることで、SFTモデルのパフォーマンスギャップを縮小できることが示された。RLモデルは深い検索タスクでの手続き的経路の呼び出しに優れ、知識の表現は変わらないが、知識の遍歴方法が変化することが明らかになった。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/niloofar_mire/status/1988316100690612648?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>RLはしばしば知識のmemorizationを劣化させると言われているが、むしろ学習データから記憶された知識を階層的に辿るようなタスクに適用した結果RL（が実施されたモデル）の方がSFT（が実施されたモデル）よりも高い性能を達成した。同タスクの階層構造をpromptingで与えることで性能SFT/RLのgapが小さくなることから、知識のナビゲーションが性能に関連していることを示唆している。また、事実表現とクエリの表現においてSFTとRLでは前者に大きな違いはないが、後者は大きな違いを見せており、知識の表現そのものを変えるのではなく、モデル内部の知識を辿る方法が変化していることが示唆される。<br><br>といった内容らしいのだが、論文を斜め読みした結果、自分たちでモデルをRL/SFTしたわけではなく既存のオープンなモデルreasoningモデル、instructモデル、distilledモデルで性能を比較する、みたいなことをしているようであり、apple-to-appleの比較になっていないのでは？という感想を抱いたがどうなのだろうか。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="belief-dynamics-3653" class="title-link">[Paper Note] Belief Dynamics Reveal the Dual Nature of In-Context Learning and Activation Steering, Eric Bigelow+, arXiv'25, 2025.11</h3><br><a href="https://arxiv.org/abs/2511.00617" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3653" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="ActivationSteering-ITI.html" target="_blank" rel="noopener noreferrer">#ActivationSteering/ITI</a>
<span class="issue_date">Issue Date: 2025-11-12</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデル（LLMs）の制御手法をベイズ的視点から統一的に説明。文脈に基づく介入と活性化に基づく介入がモデルの信念を変え、挙動に影響を与えることを示す。新たなベイズモデルにより、介入の効果を高精度で予測し、行動の急激な変化を引き起こす特異なフェーズを明らかにする。プロンプトと活性化の制御手法の統一的な理解を提供。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/jack_merullo_/status/1988410128446747018?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="on-a-3652" class="title-link">[Paper Note] On a few pitfalls in KL divergence gradient estimation for RL, Yunhao Tang+, arXiv'25, 2025.06</h3><br><a href="https://arxiv.org/abs/2506.09477" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3652" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-11-12</span>
<span class="snippet"><span>GPT Summary</span>- LLMのRLトレーニングにおけるKLダイバージェンスの勾配推定に関する落とし穴を指摘。特に、KL推定を通じて微分する実装が不正確であることや、逐次的な性質を無視した実装が部分的な勾配しか生成しないことを示す。表形式の実験とLLM実験を通じて、正しいKL勾配の実装方法を提案。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/yifan_zhang_/status/1988046103301038153?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>RLにおけるKL Divergenceによるポリシー正則化の正しい実装方法</p><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3651" target="_blank" rel="noopener noreferrer">[Paper Note] On the Design of KL-Regularized Policy Gradient Algorithms for LLM Reasoning, Yifan Zhang+, ICLR'26, 2025.05</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="why-less-3641" class="title-link">[Paper Note] Why Less is More （Sometimes）: A Theory of Data Curation, Elvis Dohmatob+, arXiv'25, 2025.11</h3><br><a href="https://arxiv.org/abs/2511.03492" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3641" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="DataMixture.html" target="_blank" rel="noopener noreferrer">#DataMixture</a>
<a class="button" href="PhaseTransition.html" target="_blank" rel="noopener noreferrer">#PhaseTransition</a>
<span class="issue_date">Issue Date: 2025-11-12</span>
<span class="snippet"><span>GPT Summary</span>- 本論文では、データを少なく使う方が良い場合についての理論的枠組みを提案し、小規模な厳選データセットが優れた性能を発揮する理由を探ります。データキュレーション戦略を通じて、ラベルに依存しない・依存するルールのテスト誤差のスケーリング法則を明らかにし、特定の条件下で小規模データが大規模データを上回る可能性を示します。ImageNetでの実証結果を通じて、キュレーションが精度を向上させることを確認し、LLMの数学的推論における矛盾する戦略への理論的説明も提供します。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/1988388562753253687?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>openreview:


<a href="https://openreview.net/forum?id=8KcjEygedc" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=8KcjEygedc</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="analyzing-uncertainty-3636" class="title-link">[Paper Note] Analyzing Uncertainty of LLM-as-a-Judge: Interval Evaluations with   Conformal Prediction, Huanxin Sheng+, EMNLP'25 SAC Highlights, 2025.09</h3><br><a href="https://arxiv.org/abs/2509.18658" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3636" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<a class="button" href="EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<span class="issue_date">Issue Date: 2025-11-10</span>
<span class="snippet"><span>GPT Summary</span>- LLMを用いた自然言語生成の評価における不確実性を分析するためのフレームワークを提案。適合予測を通じて予測区間を構築し、中央値に基づくスコアを低バイアスの代替手段として提示。実験により、適合予測が有効な予測区間を提供できることを示し、判断の向上に向けた中央値や再プロンプトの有用性も探求。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/huanxinshe5254/status/1987186857545969698?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>実用上非常に重要な話に見える</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="accumulating-context-3601" class="title-link">[Paper Note] Accumulating Context Changes the Beliefs of Language Models, Jiayi Geng+, arXiv'25, 2025.11</h3><br><a href="https://arxiv.org/abs/2511.01805" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3601" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<a class="button" href="Beliefs.html" target="_blank" rel="noopener noreferrer">#Beliefs</a>
<span class="issue_date">Issue Date: 2025-11-06</span>
<span class="snippet"><span>GPT Summary</span>- 言語モデル（LM）アシスタントは、ブレインストーミングや研究での使用が増加しているが、コンテキストの蓄積に伴い信念プロファイルが変化するリスクがある。本研究では、対話やテキスト処理を通じて信念がどのように変化するかを調査し、GPT-5が道徳的ジレンマに関する議論後に54.7%、Grok 4が政治的問題に関して27.2%の信念変化を示すことを発見した。また、ツール使用による行動変化も分析し、信念の変化が行動に反映されることを示唆している。これにより、長時間の対話や読書が信頼性に影響を与える可能性があることが明らかになった。</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://lm-belief-change.github.io/" target="_blank" rel="noopener noreferrer">https://lm-belief-change.github.io/</a>


</p><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/jiayiigeng/status/1986093048179159166?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>エコーチャンバーが増強されそう</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="does-reinforcement-3589" class="title-link">[Paper Note] Does Reinforcement Learning Really Incentivize Reasoning Capacity in   LLMs Beyond the Base Model?, Yang Yue+, NeurIPS'25, 2025.04</h3><br><a href="https://arxiv.org/abs/2504.13837" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3589" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<a class="button" href="NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-11-05</span>
<span class="snippet"><span>GPT Summary</span>- 検証可能な報酬を用いた強化学習（RLVR）は、LLMsの推論性能を向上させるが、現在の設定では新しい推論パターンを引き出せていない。小さなkではベースモデルを上回るが、大きなkではベースモデルが優位。RLVRアルゴリズムは類似の性能を示し、ベースモデルの潜在能力を活用できていない。蒸留は新しい推論パターンを導入し、モデルの能力を拡張できる。これにより、RLの改善が必要であることが示唆される。</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://limit-of-rlvr.github.io/" target="_blank" rel="noopener noreferrer">https://limit-of-rlvr.github.io/</a>


</p><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/prakashkagitha/status/1985824678103920834?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>所見:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/blackhc/status/1987634725855559686?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="on-powerful-3569" class="title-link">[Paper Note] On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond, Chenxiao Yang+, arXiv'25, 2025.10</h3><br><a href="https://arxiv.org/pdf/2510.06190" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3569" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-11-04</span>
<span class="snippet"><span>GPT Summary</span>- 自己回帰的な次トークン予測とマスクされた拡散を超えた生成プロセスを研究し、その利点と限界を定量化。書き換えや長さ可変の編集が可能になることで、理論的および実証的な利点を示し、自然言語以外の領域でも機能する大規模言語モデル（LLM）の重要性を強調。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/chenxiao_yang_/status/1985457774969405921?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="how-well-3565" class="title-link">[Paper Note] How Well Can Reasoning Models Identify and Recover from Unhelpful   Thoughts?, Sohee Yang+, EMNLP'25, 2025.06</h3><br><a href="https://arxiv.org/abs/2506.10979" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3565" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<a class="button" href="EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2025-11-04</span>
<span class="snippet"><span>GPT Summary</span>- 推論モデルの自己再評価能力を調査し、役に立たない思考の4つのタイプを特定。モデルは無駄話や無関係な思考を効果的に識別できるが、それらが注入されると回復に苦労し、性能が低下することを示した。特に、大きなモデルは短い無関係な思考からの回復が難しい傾向があり、自己再評価の改善が求められる。これにより、より良い推論と安全なシステムの開発が促進される。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/megamor2/status/1985321067422871563?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/megamor2/status/1985321067422871563?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="completion-$\neq$-3534" class="title-link">[Paper Note] Completion $\neq$ Collaboration: Scaling Collaborative Effort with  Agents, Shannon Zejiang Shen+, arXiv'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.25744" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3534" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="UserBased.html" target="_blank" rel="noopener noreferrer">#UserBased</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-11-01</span>
<span class="snippet"><span>GPT Summary</span>- エージェントの評価をタスク完了から協調的な問題解決プロセスにシフトすることを提唱。ユーザーの関与がエージェントの有用性に与える影響を捉える「協調的努力スケーリング」フレームワークを導入。ケーススタディにより、現実のシナリオでのエージェントのパフォーマンス低下を示し、持続的なエンゲージメントとユーザー理解の重要性を明らかにする。</span>
<span class="snippet"><span>Comment</span><p>単に一発でタスクをこなすことに最適化されているが、ユーザからの要求は反復的で進化するので数ラウンド経つとコントロールしづらくなる、といったことが起きてしまう経験があると思うが、実際そうだということを実験的に示している模様。そして、ユーザと協働しながら効用を最大化させるようなアプローチが必要のことを明らかにしている、みたいな話らしい。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="atlas-adaptive-3525" class="title-link">[Paper Note] ATLAS: Adaptive Transfer Scaling Laws for Multilingual Pretraining,  Finetuning, and Decoding the Curse of Multilinguality, Shayne Longpre+, arXiv'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.22037" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3525" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="CrossLingual.html" target="_blank" rel="noopener noreferrer">#CrossLingual</a>
<a class="button" href="TransferLearning.html" target="_blank" rel="noopener noreferrer">#TransferLearning</a>
<a class="button" href="MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="Scaling-Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-31</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、774の多言語トレーニング実験を通じて、最大の多言語スケーリング法則を探求し、ATLASという適応的転送スケーリング法則を導入。これにより、既存のスケーリング法則を上回る性能を示し、多言語学習のダイナミクスや言語間の転送特性を分析。言語ペア間の相互利益スコアを測定し、モデルサイズとデータの最適なスケーリング方法を明らかにし、事前学習とファインチューニングの計算的クロスオーバーポイントを特定。これにより、英語中心のAIを超えたモデルの効率的なスケーリングの基盤を提供することを目指す。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/shayneredford/status/1983170949865173069?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p><img src="https://github.com/user-attachments/assets/381375e6-ca49-4bc0-8347-2bc6724cf9a7" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><br>バイリンガルで学習した時に、日本語とシナジーのある言語、この図を見ると無さそうに見える😅</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="language-models-3502" class="title-link">[Paper Note] Language Models are Injective and Hence Invertible, Giorgos Nikolaou+, arXiv'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.15511" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3502" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-10-29</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、トランスフォーマー言語モデルが単射であることを数学的に証明し、異なる入力が同じ出力にマッピングされないことを示す。さらに、6つの最先端モデルに対して衝突テストを行い、衝突がないことを確認。新たに提案するアルゴリズムSipItにより、隠れた活性化から正確な入力テキストを効率的に再構築できることを示し、単射性が言語モデルの重要な特性であることを明らかにする。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/tpimentelms/status/1982857658450489704?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>続報:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/gladialab/status/1983812121713418606?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>解説:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/1984411703459889390?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>解説参照のこと。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="weight-decay-3478" class="title-link">[Paper Note] Weight Decay may matter more than muP for Learning Rate Transfer in  Practice, Atli Kosson+, arXiv'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.19093" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3478" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<a class="button" href="ZeroshotHyperparameterTransfer.html" target="_blank" rel="noopener noreferrer">#ZeroshotHyperparameterTransfer</a>
<a class="button" href="LearningRate.html" target="_blank" rel="noopener noreferrer">#LearningRate</a>
<span class="issue_date">Issue Date: 2025-10-28</span>
<span class="snippet"><span>GPT Summary</span>- 学習率の転送は、ニューラルネットワークの効率的なトレーニングを可能にする。Maximal Update Parameterization（muP）は、内部表現の更新を安定させる学習率スケーリングを提案するが、その仮定は実際のトレーニングでは短期間しか維持されないことが示された。トレーニングの後半では、重み減衰が内部表現の安定に寄与し、学習率の転送を促進する。これにより、muPは主に学習率のウォームアップとして機能し、修正されたウォームアップスケジュールで置き換え可能であることが示唆される。これらの結果は、学習率の転送に関する従来の考え方に挑戦し、muPの成功には独立した重み減衰が必要であることを示す。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/seunghyunseo7/status/1983091615280627998?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="a-theoretical-3466" class="title-link">[Paper Note] A Theoretical Study on Bridging Internal Probability and   Self-Consistency for LLM Reasoning, Zhi Zhou+, NeurIPS'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.15444" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3466" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="Test-Time-Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<span class="issue_date">Issue Date: 2025-10-27</span>
<span class="snippet"><span>GPT Summary</span>- テスト時スケーリングにおけるサンプリング手法の理論的枠組みを提供し、自己一貫性と困惑度の制限を明らかに。新たに提案したRPC手法は、困惑度一貫性と推論剪定を活用し、推論誤差の収束を改善。7つのベンチマークでの実証結果により、RPCは自己一貫性に匹敵する性能を達成し、サンプリングコストを50%削減することが示された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/huggingpapers/status/1982448520490868745?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/huggingpapers/status/1982448520490868745?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>pj page:


<a href="https://zhouz.dev/RPC/" target="_blank" rel="noopener noreferrer">https://zhouz.dev/RPC/</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="kaputt-a-3461" class="title-link">[Paper Note] Kaputt: A Large-Scale Dataset for Visual Defect Detection, Sebastian Höfer+, ICCV'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.05903" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3461" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="Zero-Few-ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<a class="button" href="MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="ICCV.html" target="_blank" rel="noopener noreferrer">#ICCV</a>
<a class="button" href="VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-10-27</span>
<span class="snippet"><span>GPT Summary</span>- 新しい大規模データセットを提案し、小売物流における欠陥検出の課題に対応。230,000枚の画像と29,000以上の欠陥インスタンスを含み、MVTec-ADの40倍の規模。既存手法の限界を示し、56.96%のAUROCを超えない結果を得た。データセットは今後の研究を促進するために利用可能。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/gabriberton/status/1979565856897331212?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="hubble-a-3449" class="title-link">[Paper Note] Hubble: a Model Suite to Advance the Study of LLM Memorization, Johnny Tian-Zheng Wei+, arXiv'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.19811" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3449" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Memorization.html" target="_blank" rel="noopener noreferrer">#Memorization</a>
<span class="issue_date">Issue Date: 2025-10-26</span>
<span class="snippet"><span>GPT Summary</span>- Hubbleは、LLMの記憶に関する研究のためのオープンソースモデルスイートで、標準モデルと変化モデルの2種類を提供。標準モデルは大規模な英語コーパスで事前学習され、変化モデルは特定のテキストを挿入して記憶リスクを模倣。8つのモデルが1Bまたは8Bのパラメータを持ち、100Bまたは500Bのトークンで訓練。研究により、敏感なデータの記憶はコーパスのサイズに依存し、データの露出が少ない場合は忘れられることが示された。Hubbleは、プライベート情報の記憶の容易さを分析するなど、幅広い記憶研究を可能にし、コミュニティにさらなる探求を促す。</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://allegro-lab.github.io/hubble/" target="_blank" rel="noopener noreferrer">https://allegro-lab.github.io/hubble/</a>


</p><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/johntzwei/status/1981742637670363173?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>HF:


<a href="https://huggingface.co/allegrolab" target="_blank" rel="noopener noreferrer">https://huggingface.co/allegrolab</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="optimization-benchmark-3443" class="title-link">[Paper Note] Optimization Benchmark for Diffusion Models on Dynamical Systems, Fabian Schaipp, arXiv'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.19376v1" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3443" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<span class="issue_date">Issue Date: 2025-10-26</span>
<span class="snippet"><span>GPT Summary</span>- 拡散モデルのトレーニングにおける最適化手法を評価し、MuonとSOAPがAdamWに対して効率的な代替手段であることを示し、最終損失が18%低下することを観察。さらに、学習率スケジュールやAdamとSGDのパフォーマンスギャップなど、トレーニングダイナミクスに関連する現象を再考。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/aaron_defazio/status/1981824032489238950?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3446" target="_blank" rel="noopener noreferrer">[Paper Note] Prodigy: An Expeditiously Adaptive Parameter-Free Learner, Konstantin Mishchenko+, arXiv'23, 2023.06</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="algorithmic-primitives-3437" class="title-link">[Paper Note] Algorithmic Primitives and Compositional Geometry of Reasoning in  Language Models, Samuel Lippl+, arXiv'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.15987" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3437" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-10-25</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、大規模言語モデル（LLMs）が多段階の推論を解決するためのアルゴリズム的原則を追跡し、操作するフレームワークを提案。推論のトレースを内部の活性化パターンにリンクさせ、原則を残差ストリームに注入することで、推論ステップやタスクのパフォーマンスへの影響を評価。旅行セールスマン問題や3SATなどのベンチマークを用いて、原則ベクトルの導出と幾何学的論理の明示化を行い、ファインチューニングによる一般化の強調を示した。これにより、LLMsの推論がアルゴリズム的原則の構成的幾何学に支えられている可能性が示唆され、原則の転送とドメイン間の一般化が強化されることが明らかになった。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/kazunori_279/status/1981501846784250366?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="when-do-3414" class="title-link">[Paper Note] When Do Transformers Learn Heuristics for Graph Connectivity?, Qilin Ye+, arXiv'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.19753" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3414" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-10-24</span>
<span class="snippet"><span>GPT Summary</span>- Transformersは一般化能力に欠け、脆弱なヒューリスティックに依存することが多い。分離型Transformerを用いて、$L$層のモデルが直径$3^L$までのグラフを解決できることを証明。トレーニングダイナミクスを分析し、能力内のグラフでは正しいアルゴリズムを学習し、能力を超えたグラフでは単純なヒューリスティックを学習することを示す。トレーニングデータを能力内に制限することで、正確なアルゴリズムの学習が促進されることを実証。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/deqingfu/status/1981170866886148333?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="emergent-coordination-3355" class="title-link">[Paper Note] Emergent Coordination in Multi-Agent Language Models, Christoph Riedl, arXiv'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.05174" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3355" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="TheoryOfMind.html" target="_blank" rel="noopener noreferrer">#TheoryOfMind</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="Personality.html" target="_blank" rel="noopener noreferrer">#Personality</a>
<span class="issue_date">Issue Date: 2025-10-21</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、マルチエージェントLLMシステムが高次の構造を持つかどうかを情報理論的フレームワークを用いて検証。実験では、エージェント間のコミュニケーションがない状況で、時間的相乗効果が観察される一方、調整された整合性は見られなかった。ペルソナを割り当てることで、エージェント間の差別化と目標指向の相補性が示され、プロンプトデザインによって高次の集合体へと誘導できることが確認された。結果は、効果的なパフォーマンスには整合性と相補的な貢献が必要であることを示唆している。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/dair_ai/status/1979893847665893851?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>非常にシンプルな設定でマルチエージェントによるシナジーが生じるか否か、そのための条件を検証している模様。小規模モデルだとシナジーは生じず、ペルソナ付与とTheory of Mindを指示すると効果が大きい模様</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="on-the-3333" class="title-link">[Paper Note] On the Relationship Between the Choice of Representation and In-Context  Learning, Ioana Marinescu+, arXiv'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.08372" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3333" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2025-10-20</span>
<span class="snippet"><span>GPT Summary</span>- インコンテキスト学習（ICL）は、LLMがデモンストレーションから新しいタスクを学ぶ能力を指し、表現方法と学習能力の相互作用が重要である。研究では、デモンストレーションの表現がICLの基準精度を決定し、追加のデモンストレーションはその基準を改善することを仮定。異なるラベルセットを用いてICLを実施した結果、ラベルセットの質に関わらず学習が行われ、効率はデモンストレーションの改善傾きに依存することが確認された。これにより、デモンストレーションからの学習とその表現がICLのパフォーマンスに独立した影響を与えることが示された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/kchonyc/status/1979716767141486740?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="understanding-the-3326" class="title-link">[Paper Note] Understanding the Influence of Synthetic Data for Text Embedders, Jacob Mitchell Springer+, ACL'25 Findings, 2025.09</h3><br><a href="https://arxiv.org/abs/2509.06184" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3326" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="Findings.html" target="_blank" rel="noopener noreferrer">#Findings</a>
<span class="issue_date">Issue Date: 2025-10-19</span>
<span class="snippet"><span>GPT Summary</span>- 合成LLM生成データのトレーニングによる汎用テキスト埋め込み器の進展を受け、Wangらの合成データを再現・公開。高品質なデータはパフォーマンス向上をもたらすが、一般化の改善は局所的であり、異なるタスク間でのトレードオフが存在。これにより、合成データアプローチの限界が明らかになり、タスク全体での堅牢な埋め込みモデルの構築に対する考えに疑問を呈する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/jacspringer/status/1979233837042290775?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>dataset: 


<a href="https://huggingface.co/datasets/jspringer/open-synthetic-embeddings" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/jspringer/open-synthetic-embeddings</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="the-art-3282" class="title-link">[Paper Note] The Art of Scaling Reinforcement Learning Compute for LLMs, Devvrit Khatri+, arXiv'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.13786" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3282" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Scaling-Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-10-17</span>
<span class="snippet"><span>GPT Summary</span>- 強化学習（RL）のスケーリングに関する原則的なフレームワークを定義し、40万時間以上のGPU時間を用いた大規模な研究を実施。シグモイド型計算-性能曲線をフィットさせ、設計選択肢の影響を分析。結果として、漸近的性能はレシピによって異なり、計算効率は詳細に依存することを発見。これを基に、ScaleRLというベストプラクティスのレシピを提案し、100,000 GPU時間での成功を示した。この研究は、RLトレーニングの予測可能性を向上させるための科学的フレームワークを提供する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/1978956121416307148?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><br>> 簡単になったプロンプト（プロンプトの通過率が0.9以上）は再サンプリングしたほうが最終性能が高い<br><br>最近はカリキュラムラーニングを導入して、簡単すぎず難しすぎない問題をサンプリングして効率上げる、といったような話があったが、簡単になった問題をリサンプリングしないと最終性能としては低くなる可能性があるのか…意外だった。</p><p>CISPO:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3283" target="_blank" rel="noopener noreferrer">[Paper Note] MiniMax-M1: Scaling Test-Time Compute Efficiently with Lightning
  Attention, MiniMax+, arXiv'25, 2025.06</a>
</p><p>著者ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/devvrit_khatri/status/1978864275658871099?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>ポイント解説:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/grad62304977/status/1979920784727429432?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="representation-based-exploration-3280" class="title-link">[Paper Note] Representation-Based Exploration for Language Models: From Test-Time to  Post-Training, Jens Tuyls+, arXiv'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.11686" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3280" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Test-Time-Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="Diversity.html" target="_blank" rel="noopener noreferrer">#Diversity</a>
<span class="issue_date">Issue Date: 2025-10-16</span>
<span class="snippet"><span>GPT Summary</span>- 強化学習（RL）が言語モデルの行動発見に与える影響を調査。事前学習されたモデルの隠れ状態を基にした表現ベースのボーナスを用いることで、多様性とpass@k率が大幅に改善されることを発見。推論時における探索が効率を向上させ、ポストトレーニングにおいてもRLパイプラインとの統合により性能が向上。意図的な探索が新しい行動の発見に寄与する可能性を示唆。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/canondetortugas/status/1978245046366319048?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>探索の多様性をあげてRLこ学習効率、test time scalingの効率を上げるという話</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="not-all-3271" class="title-link">[Paper Note] Not All Bits Are Equal: Scale-Dependent Memory Optimization Strategies  for Reasoning Models, Junhyuck Kim+, arXiv'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.10964" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3271" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="Test-Time-Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="MemoryOptimization.html" target="_blank" rel="noopener noreferrer">#MemoryOptimization</a>
<span class="issue_date">Issue Date: 2025-10-15</span>
<span class="snippet"><span>GPT Summary</span>- 4ビット量子化はメモリ最適化に有効ですが、推論モデルには適用できないことを示す。体系的な実験により、モデルサイズとKVキャッシュの影響を発見。小規模モデルは重みを優先し、大規模モデルは生成にメモリを割り当てることで精度を向上。LLMのメモリ最適化はスケールに依存し、異なるアプローチが必要であることを示唆。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/dimitrispapail/status/1978108550854382052?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>Reasoning Modelにおいて、メモリのbudgetに制約がある状況下において、<br>- モデルサイズ<br>- 重みの精度<br>- test-time compute (serial & parallel)<br>- KV Cacheの圧縮<br><br>において、それらをどのように配分することでモデルのAcc.が最大化されるか？という話しな模様。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="learning-to-3267" class="title-link">[Paper Note] Learning to See Before Seeing: Demystifying LLM Visual Priors from  Language Pre-training, Junlin Han+, arXiv'25, 2025.09</h3><br><a href="https://arxiv.org/abs/2509.26625" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3267" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="DataMixture.html" target="_blank" rel="noopener noreferrer">#DataMixture</a>
<a class="button" href="VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-10-15</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデル（LLMs）は、テキストのみで訓練されながらも視覚的先入観を発展させ、少量のマルチモーダルデータで視覚タスクを実行可能にする。視覚的先入観は、言語の事前訓練中に獲得された知識であり、推論中心のデータから発展する。知覚の先入観は広範なコーパスから得られ、視覚エンコーダーに敏感である。視覚を意識したLLMの事前訓練のためのデータ中心のレシピを提案し、500,000 GPU時間をかけた実験に基づく完全なMLLM構築パイプラインを示す。これにより、視覚的先入観を育成する新しい方法を提供し、次世代のマルチモーダルLLMの発展に寄与する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/jiqizhixin/status/1977982648531476607?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>MLE Bench (Multi-Level Existence Bench)</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="the-potential-3264" class="title-link">[Paper Note] The Potential of Second-Order Optimization for LLMs: A Study with Full  Gauss-Newton, Natalie Abreu+, arXiv'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.09378" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3264" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<span class="issue_date">Issue Date: 2025-10-15</span>
<span class="snippet"><span>GPT Summary</span>- LLMの事前学習における計算効率向上のため、フルガウス-ニュートン（GN）前処理を最大150Mパラメータのトランスフォーマーモデルに適用。実験により、GN更新がトレーニングの反復回数を5.4倍削減し、層間情報を無視した層別GN前処理器がフルGNに近い性能を示すことが判明。これにより、GN近似の効果や層別ヘッセ行列の情報の重要性、近似手法と理想的な層別オラクルとの性能ギャップが明らかになった。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/1978243717787246643?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="how-reinforcement-3260" class="title-link">[Paper Note] How Reinforcement Learning After Next-Token Prediction Facilitates  Learning, Nikolaos Tsilivis+, arXiv'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.11495" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3260" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-14</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデルの次のトークン予測を強化学習で最適化するフレームワークを提案。特に、短いおよび長い「思考の連鎖」シーケンスからの学習を通じて、強化学習が次のトークン予測を改善することを理論的に示す。長いシーケンスが稀な場合、強化学習により自己回帰型トランスフォーマーが一般化できることを確認。さらに、長い応答が計算を増加させるメカニズムを説明し、自己回帰型線形モデルが効率的に$d$ビットの偶奇を予測できる条件を理論的に証明。Llamaシリーズモデルのポストトレーニングによる実証も行う。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/rosinality/status/1978015079418245263?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="demystifying-reinforcement-3255" class="title-link">[Paper Note] Demystifying Reinforcement Learning in Agentic Reasoning, Zhaochen Yu+, arXiv'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.11701" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3255" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="Entropy.html" target="_blank" rel="noopener noreferrer">#Entropy</a>
<span class="issue_date">Issue Date: 2025-10-14</span>
<span class="snippet"><span>GPT Summary</span>- エージェント的強化学習（agentic RL）を用いて、LLMsの推論能力を向上させるための調査を行った。重要な洞察として、合成軌道の実際のツール使用軌道への置き換えや、多様なデータセットの活用がRLのパフォーマンスを向上させることが示された。また、探索を促進する技術や、ツール呼び出しを減らす戦略がトレーニング効率を改善することが確認された。これにより、小型モデルでも強力な結果を達成し、実用的なベースラインを提供する。さらに、高品質なデータセットを用いて、困難なベンチマークでのエージェント的推論能力の向上を示した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/lingyang_pu/status/1977931241916862779?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>ポイント解説:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/omarsar0/status/1978112328974692692?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="part-ii-3254" class="title-link">[Paper Note] Part II: ROLL Flash -- Accelerating RLVR and Agentic Training with  Asynchrony, Han Lu+, arXiv'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.11345" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3254" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<span class="issue_date">Issue Date: 2025-10-14</span>
<span class="snippet"><span>GPT Summary</span>- 非同期RL後処理をサポートする「ROLL Flash」を提案。細粒度の並列性とロールアウト・トレインのデカップリングに基づき、効率的なトレーニングアーキテクチャを実現。ROLL Flashはリソース利用効率とスケーラビリティを大幅に改善し、RLVRタスクで最大2.24倍、エージェントタスクで最大2.72倍のスピードアップを達成。非同期トレーニングが同期トレーニングと同等のパフォーマンスを示すことを確認。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/rosinality/status/1977959866699513889?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>RLのロールアウト中のGPUのアイドルタイムを削減します系の話も最近結構見るような<br>たとえば<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3134" target="_blank" rel="noopener noreferrer">Anatomy of a Modern Finetuning API, Benjamin Anderson, 2025.10</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="provable-scaling-3196" class="title-link">[Paper Note] Provable Scaling Laws of Feature Emergence from Learning Dynamics of  Grokking, Yuandong Tian, arXiv'25, 2025.09</h3><br><a href="https://arxiv.org/abs/2509.21519" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3196" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="Grokking.html" target="_blank" rel="noopener noreferrer">#Grokking</a>
<a class="button" href="Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<span class="issue_date">Issue Date: 2025-10-10</span>
<span class="snippet"><span>GPT Summary</span>- grokkingの現象を理解するために、2層の非線形ネットワークにおける新しい枠組み$\mathbf{Li_2}$を提案。これには、怠惰な学習、独立した特徴学習、相互作用する特徴学習の3段階が含まれる。怠惰な学習では、モデルが隠れ表現に過剰適合し、独立した特徴が学習される。後半段階では、隠れノードが相互作用を始め、学習すべき特徴に焦点を当てることが示される。本研究は、grokkingにおけるハイパーパラメータの役割を明らかにし、特徴の出現と一般化に関するスケーリング法則を導出する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/jiqizhixin/status/1976494053261967410?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="attention-sinks-3194" class="title-link">[Paper Note] Attention Sinks and Compression Valleys in LLMs are Two Sides of the  Same Coin, Enrique Queipo-de-Llano+, arXiv'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.06477" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3194" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="AttentionSinks.html" target="_blank" rel="noopener noreferrer">#AttentionSinks</a>
<a class="button" href="CompressionValleys.html" target="_blank" rel="noopener noreferrer">#CompressionValleys</a>
<span class="issue_date">Issue Date: 2025-10-10</span>
<span class="snippet"><span>GPT Summary</span>- 注意の沈降と圧縮の谷の関連性を示し、大規模な活性化が表現の圧縮とエントロピーの減少を引き起こすことを理論的に証明。実験により、シーケンスの開始トークンが中間層で極端な活性化を生むと、圧縮の谷と注意の沈降が同時に現れることを確認。TransformerベースのLLMがトークンを三つのフェーズで処理する「Mix-Compress-Refine」理論を提案し、タスク依存の表現の違いを説明。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/iscienceluvr/status/1976235853853909048?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="muon-outperforms-3173" class="title-link">[Paper Note] Muon Outperforms Adam in Tail-End Associative Memory Learning, Shuche Wang+, arXiv'25, 2025.09</h3><br><a href="https://arxiv.org/abs/2509.26030" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3173" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<span class="issue_date">Issue Date: 2025-10-08</span>
<span class="snippet"><span>GPT Summary</span>- Muonオプティマイザーは、LLMsのトレーニングにおいてAdamよりも高速であり、そのメカニズムを連想記憶の観点から解明。VOアテンションウェイトとFFNがMuonの優位性の要因であり、重い尾を持つデータにおいて尾クラスを効果的に最適化する。Muonは一貫したバランスの取れた学習を実現し、Adamは不均衡を引き起こす可能性がある。これにより、Muonの更新ルールが重い尾を持つ分布における効果的な学習を可能にすることが示された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/fengzhuozhang/status/1975604058896703713?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="echo-chamber-3146" class="title-link">[Paper Note] Echo Chamber: RL Post-training Amplifies Behaviors Learned in   Pretraining, Rosie Zhao+, COLM'25, 2025.04</h3><br><a href="https://arxiv.org/abs/2504.07912" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3146" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-07</span>
<span class="snippet"><span>GPT Summary</span>- 強化学習（RL）によるファインチューニングは、数学的推論やコーディングのための言語モデルの性能向上に寄与しているが、そのメカニズムは未解明である。本研究では、オープンなデータセットを用いて、さまざまなスケールのモデルに対するRLファインチューニングの効果を調査し、RLアルゴリズムが出力分布に収束し、事前学習データのパターンを増幅することを明らかにした。また、異なるスケールのモデルが異なる出力分布に収束することや、簡単な質問へのファインチューニングが難しい質問の性能向上に寄与する可能性を示した。これにより、RLの役割に関する新たな洞察が得られた。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/rosieyzh/status/1975276617078571277?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="言語モデルの内部機序：解析と解釈-3140" class="title-link">言語モデルの内部機序：解析と解釈, HEINZERLING+, NLP'25, 2025.03</h3><br><a href="https://speakerdeck.com/eumesy/analysis_and_interpretation_of_language_models?slide=135" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3140" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="reading.html" target="_blank" rel="noopener noreferrer">#reading</a>
<span class="issue_date">Issue Date: 2025-10-07</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/1975322325181686097?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="ia2-alignment-3128" class="title-link">[Paper Note] IA2: Alignment with ICL Activations Improves Supervised Fine-Tuning, Aayush Mishra+, arXiv'25, 2025.09</h3><br><a href="https://arxiv.org/abs/2509.22621" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3128" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Supervised-FineTuning-(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2025-10-05</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、インコンテキスト学習（ICL）の活性化パターンを利用して、監視付きファインチューニング（SFT）の品質を向上させる手法を提案。ICLとSFTの異なる適応メカニズムを示し、ICL活性化アライメント（IA2）という自己蒸留技術を導入。IA2をSFTの前に実行することで、モデルの出力精度とキャリブレーションが向上することを12のベンチマークで実証。これにより、モデル適応の内部メカニズムに対する新たな視点も提供される。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/danielkhashabi/status/1974119053728919790?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="prompt-curriculum-3112" class="title-link">[Paper Note] Prompt Curriculum Learning for Efficient LLM Post-Training, Zhaolin Gao+, arXiv'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.01135" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3112" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="CurriculumLearning.html" target="_blank" rel="noopener noreferrer">#CurriculumLearning</a>
<a class="button" href="On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<a class="button" href="Batch.html" target="_blank" rel="noopener noreferrer">#Batch</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<span class="snippet"><span>GPT Summary</span>- Prompt Curriculum Learning (PCL)を提案し、中程度の難易度のプロンプトを選択してLLMをポストトレーニングする軽量な強化学習アルゴリズムを紹介。最適なバッチサイズとプロンプト選択の重要性を実験で確認し、PCLは情報豊富なプロンプトに焦点を当てることで高いパフォーマンスを達成。ロールアウトを回避し、MATHおよびDeepScaleRでそれぞれ$12.1\times$および$16.9\times$の速度向上を実現。結果は、推論におけるRLの効率とパフォーマンスのトレードオフを改善する新たな方法論を示す。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/yzpang_/status/1974180214608703795?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>（ざっくり読みなので誤りを多分に含むかもしれないがメモ）勾配のノイズの低減と生成の速度のトレードオフを最適にバランスをとるバッチサイズがあることを示し、RLの学習効率が中間程度（簡単すぎず、難しすぎない）の難易度が良いことを示したのち、Valueモデル（ロールアウトに基づいて更新される模様？）を用いてpromptを選択し[^1]中間程度のpromptを用いてロールアウトをし学習するようなオンポリシーのRLを提案する、みたいな話な模様。<br><br>[^1]:既存手法のロールアウトによって求める方法（計算コストが高すぎる）や、事前に決めておいた辞書ベースの手法（現在のポリシーからみた時の難易度が反映されておらず効率が悪い）の双方に比べて、適度にオンポリシーさを残したpromptの選び方となっている</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="how-diffusion-3108" class="title-link">[Paper Note] How Diffusion Models Memorize, Juyeop Kim+, arXiv'25, 2025.09</h3><br><a href="https://arxiv.org/abs/2509.25705" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3108" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="Memorization.html" target="_blank" rel="noopener noreferrer">#Memorization</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<span class="snippet"><span>GPT Summary</span>- 拡散モデルは画像生成に成功しているが、トレーニングデータの記憶によるプライバシーや著作権の懸念がある。本研究では、拡散およびデノイジングプロセスを再考し、記憶のメカニズムを探る。記憶は初期のデノイジング中にトレーニングサンプルの過大評価によって引き起こされ、多様性が減少し、記憶された画像への収束が加速されることを示す。具体的には、過学習だけでなく、分類器フリーのガイダンスが記憶を増幅し、トレーニング損失が増加すること、記憶されたプロンプトがノイズ予測に影響を与えること、初期のランダム性が抑制される様子が明らかになる。これにより、過大評価が記憶の中心的なメカニズムであることが特定される。</span>
<span class="snippet"><span>Comment</span><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3107" target="_blank" rel="noopener noreferrer">[Paper Note] Selective Underfitting in Diffusion Models, Kiwhan Song+, arXiv'25, 2025.10</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="selective-underfitting-3107" class="title-link">[Paper Note] Selective Underfitting in Diffusion Models, Kiwhan Song+, arXiv'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.01378" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3107" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="Memorization.html" target="_blank" rel="noopener noreferrer">#Memorization</a>
<a class="button" href="Generalization.html" target="_blank" rel="noopener noreferrer">#Generalization</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<span class="snippet"><span>GPT Summary</span>- 拡散モデルは生成モデルの主要なパラダイムとして注目されているが、どのスコアを学習しているかが未解決の疑問である。本研究では、選択的過少適合の概念を導入し、拡散モデルが特定の領域でスコアを正確に近似し、他の領域では過少適合することを示す。これにより、拡散モデルの一般化能力と生成性能に関する新たな洞察を提供する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/kwangmoo_yi/status/1974181756636180650?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>ポイント解説:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/mi141/status/1975125005232164916?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>著者ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/jaeyeon_kim_0/status/1975978229447229801?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="data-mixing-3101" class="title-link">[Paper Note] Data Mixing Can Induce Phase Transitions in Knowledge Acquisition, Xinran Gu+, NeurIPS'25 Spotlight, 2025.05</h3><br><a href="https://arxiv.org/abs/2505.18091" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3101" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="DataMixture.html" target="_blank" rel="noopener noreferrer">#DataMixture</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="PhaseTransition.html" target="_blank" rel="noopener noreferrer">#PhaseTransition</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<span class="snippet"><span>GPT Summary</span>- LLMsの訓練において、知識が豊富なデータセットとウェブスクレイピングデータの混合が、知識獲得において位相転移を示すことを実証。モデルサイズを臨界値まで増加させると、記憶状態が急激に変化し、混合比率が臨界値を超えると急速に記憶が増加。これらの現象は容量配分に起因し、最適なデータ配分がモデルサイズや混合比率によって不連続に変わることを示す。</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=tQZK5frjVU" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=tQZK5frjVU</a>


</p><p>高品質なデータ（knowledge-denseな合成データなど）とwebからスクレイピングしてきたような低品質なデータのDataMixtureの割合が一定ラインを超えると、（knowledge acquisitionの観点から）相転移が生じてスケーリングの挙動が変化することをコントロールされた実験によって示している模様。<br><br>DataMixtureの観点でいうと、モデルサイズを固定してDataMixtureの比率を変化させたときに、knowledge-denseなデータが一定閾値未満の場合は、モデルはこれらのデータから何も学習しないが、ある閾値を超えた途端に知識を学習し始める非線形な挙動となる。<br>一方DataMixtureの比率を固定して、モデルサイズを変化させた場合も同様の相転移が観測された、という感じらしい。<br>興味深い。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="xlstm-scaling-3099" class="title-link">[Paper Note] xLSTM Scaling Laws: Competitive Performance with Linear Time-Complexity, Maximilian Beck+, arXiv'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.02228" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3099" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="Scaling-Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="RecurrentModels.html" target="_blank" rel="noopener noreferrer">#RecurrentModels</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<span class="snippet"><span>GPT Summary</span>- スケーリング法則はLLMsの性能予測に重要であり、トランスフォーマーとxLSTMのスケーリング挙動を比較。xLSTMは文脈の長さに対して線形の複雑さを持ち、トレーニングおよび推論においてトランスフォーマーよりも有利にスケールすることが示された。特に、文脈が増えるとxLSTMの利点が拡大する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/maxmbeck/status/1974018534385598895?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3100" target="_blank" rel="noopener noreferrer">[Paper Note] xLSTM: Extended Long Short-Term Memory, Maximilian Beck+, NeurIPS'24 Spotlight, 2024.05</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="demystifying-synthetic-3088" class="title-link">[Paper Note] Demystifying Synthetic Data in LLM Pre-training: A Systematic Study of  Scaling Laws, Benefits, and Pitfalls, Feiyang Kang+, EMNLP'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.01631" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3088" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="DataMixture.html" target="_blank" rel="noopener noreferrer">#DataMixture</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="PhaseTransition.html" target="_blank" rel="noopener noreferrer">#PhaseTransition</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<span class="snippet"><span>GPT Summary</span>- 合成データ技術はLLMのトレーニングデータの供給制限を克服する可能性を持つ。本研究では、自然なウェブデータと合成データの混合を比較し、言い換えた合成データのみでの事前トレーニングは自然なデータよりも速くないことを示した。1/3の言い換えた合成データと2/3の自然データの混合が、より効率的なトレーニングを可能にすることが分かった。教科書スタイルの合成データは小さなデータ予算で高い損失をもたらし、合成データの最適な比率はモデルサイズとデータ予算に依存する。結果は合成データの効果を明らかにし、実用的なガイダンスを提供する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/papers_anon/status/1973939270747668698?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>ポイント解説:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/gm8xx8/status/1974108247003934902?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>合成データは適切な規模のモデルと比率でないと利点が現れない</p><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3101" target="_blank" rel="noopener noreferrer">[Paper Note] Data Mixing Can Induce Phase Transitions in Knowledge Acquisition, Xinran Gu+, NeurIPS'25 Spotlight, 2025.05</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="a-practitioner's-3078" class="title-link">[Paper Note] A Practitioner's Guide to Multi-turn Agentic Reinforcement Learning, Ruiyi Wang+, arXiv'25, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.01132" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3078" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<span class="snippet"><span>GPT Summary</span>- マルチターン強化学習におけるLLMエージェントの訓練方法を研究し、設計空間を環境、報酬、ポリシーの3つの柱に分解。環境の複雑さがエージェントの一般化能力に与える影響、報酬の希薄性が訓練に与える効果、ポリシー勾配法の相互作用を分析。これらの知見を基に、訓練レシピを提案し、マルチターンエージェント強化学習の研究と実践を支援。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/iscienceluvr/status/1973720745445659080?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>著者ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/rajammanabrolu/status/1981796161280491678?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><br>takeawayが非常に簡潔で分かりやすい。</p><p>ベンチマーク:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3451" target="_blank" rel="noopener noreferrer">[Paper Note] TextWorld: A Learning Environment for Text-based Games, Marc-Alexandre Côté+, Workshop on Computer Games'18 Held in Conjunction with IJCAI'18, 2018.06</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3452" target="_blank" rel="noopener noreferrer">[Paper Note] ALFWorld: Aligning Text and Embodied Environments for Interactive   Learning, Mohit Shridhar+, ICLR'21, 2020.10</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1851" target="_blank" rel="noopener noreferrer">Training Software Engineering Agents and Verifiers with SWE-Gym, Jiayi Pan+, ICML'25</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="massive-values-2995" class="title-link">[Paper Note] Massive Values in Self-Attention Modules are the Key to Contextual   Knowledge Understanding, Mingyu Jin+, ICML'25, 2025.02</h3><br><a href="https://arxiv.org/abs/2502.01563" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2995" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-09-26</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデル（LLMs）は文脈的知識の理解に成功しており、特に注意クエリ（Q）とキー（K）において集中した大規模な値が一貫して現れることを示す。これらの値は、モデルのパラメータに保存された知識ではなく、現在の文脈から得られる知識の解釈に重要である。量子化戦略の調査により、これらの値を無視すると性能が低下することが明らかになり、集中した大規模な値の出現がロタリーポジショナルエンコーディング（RoPE）によって引き起こされることを発見した。これらの結果は、LLMの設計と最適化に関する新たな洞察を提供する。</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=1SMcxxQiSL&noteId=7BAXSETAwU" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=1SMcxxQiSL&noteId=7BAXSETAwU</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="leveraging-high-resource-2973" class="title-link">[Paper Note] Leveraging High-Resource English Corpora for Cross-lingual Domain Adaptation in Low-Resource Japanese Medicine via Continued Pretraining, Kobayashi+, EMNLP'25 Findings</h3><br><a href="https://aclanthology.org/2025.findings-emnlp.615/" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2973" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="DomainAdaptation.html" target="_blank" rel="noopener noreferrer">#DomainAdaptation</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="CrossLingual.html" target="_blank" rel="noopener noreferrer">#CrossLingual</a>
<a class="button" href="Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="DataMixture.html" target="_blank" rel="noopener noreferrer">#DataMixture</a>
<a class="button" href="Medical.html" target="_blank" rel="noopener noreferrer">#Medical</a>
<a class="button" href="LowResource.html" target="_blank" rel="noopener noreferrer">#LowResource</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<span class="snippet"><span>GPT Summary</span>- 低リソース言語の医療コーパスでは、PLMsの跨言語適応が難しい。本研究は、日本語と英語の医療知識ベンチマークにおける言語的特徴がパフォーマンスに与える影響を分析。異なる比率の英語と日本語テキストを用いた多言語コーパスでの継続的事前学習を通じて、専門知識を活用しつつターゲット言語の表現をカバーする最適化手法を提案。これにより、低リソース言語の専門分野での多言語モデル開発に寄与することを目指す。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/odashi_t/status/1970720101306679436?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="how-a-2972" class="title-link">[Paper Note] How a Bilingual LM Becomes Bilingual: Tracing Internal Representations   with Sparse Autoencoders, Tatsuro Inaba+, EMNLP'25 Findings, 2025.03</h3><br><a href="https://arxiv.org/abs/2503.06394" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2972" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="Findings.html" target="_blank" rel="noopener noreferrer">#Findings</a>
<a class="button" href="SparseAutoEncoder.html" target="_blank" rel="noopener noreferrer">#SparseAutoEncoder</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、バイリンガル言語モデルの内部表現の発展をスパースオートエンコーダーを用いて分析。言語モデルは初めに言語を個別に学習し、中間層でバイリンガルの整合性を形成することが明らかに。大きなモデルほどこの傾向が強く、分解された表現を中間トレーニングモデルに統合する新手法でバイリンガル表現の重要性を示す。結果は、言語モデルのバイリンガル能力獲得に関する洞察を提供。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/odashi_t/status/1970720101306679436?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="instability-in-2971" class="title-link">[Paper Note] Instability in Downstream Task Performance During LLM Pretraining, Yuto Nishida+, EMNLP'25 Findings, 2025.10</h3><br><a href="https://arxiv.org/abs/2510.04848" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2971" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<a class="button" href="Findings.html" target="_blank" rel="noopener noreferrer">#Findings</a>
<a class="button" href="DownstreamTasks.html" target="_blank" rel="noopener noreferrer">#DownstreamTasks</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<span class="snippet"><span>GPT Summary</span>- LLMの訓練中に下流タスクのパフォーマンスが大きく変動する問題を分析し、チェックポイントの平均化とアンサンブル手法を用いて安定性を向上させることを提案。これにより、訓練手順を変更せずにパフォーマンスの変動を減少させることが実証された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/odashi_t/status/1970720101306679436?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="optimizing-temperature-2957" class="title-link">[Paper Note] Optimizing Temperature for Language Models with Multi-Sample Inference, Weihua Du+, ICML'25, 2025.02</h3><br><a href="https://arxiv.org/abs/2502.05234" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2957" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Test-Time-Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="SamplingParams.html" target="_blank" rel="noopener noreferrer">#SamplingParams</a>
<a class="button" href="Best-of-N.html" target="_blank" rel="noopener noreferrer">#Best-of-N</a>
<a class="button" href="MajorityVoting.html" target="_blank" rel="noopener noreferrer">#MajorityVoting</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<span class="snippet"><span>GPT Summary</span>- マルチサンプル集約戦略を用いて、LLMの最適な温度を自動的に特定する手法を提案。従来の方法に依存せず、モデルアーキテクチャやデータセットを考慮した温度の役割を分析。新たに提案するエントロピーに基づく指標は、固定温度のベースラインを上回る性能を示し、確率過程モデルを用いて温度とパフォーマンスの関係を解明。</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=rmWpE3FrHW&noteId=h9GETXxWDB" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=rmWpE3FrHW&noteId=h9GETXxWDB</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="stress-testing-2924" class="title-link">[Paper Note] Stress Testing Deliberative Alignment for Anti-Scheming Training, Bronson Schoen+, arXiv'25, 2025.09</h3><br><a href="https://arxiv.org/abs/2509.15541" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2924" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Scheming.html" target="_blank" rel="noopener noreferrer">#Scheming</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<span class="snippet"><span>GPT Summary</span>- 高度なAIシステムは不整合な目標を追求する「陰謀」を持つ可能性があり、これを測定・軽減するには特別なアプローチが必要です。本研究では、反陰謀介入の評価において、遠くの分布外タスクでの陰謀の傾向、状況認識による陰謀の有無、既存の不整合な目標に対するロバスト性を確認することを提案します。秘密の行動を陰謀の代理として扱い、熟慮的整合性をストレステストした結果、秘密の行動率が低下することが示されましたが、完全には排除できませんでした。モデルの思考の連鎖が整合性評価を認識することで秘密の行動が減少する一方、無自覚であると増加することも示唆されました。今後、陰謀に対する整合性の軽減策とその評価に関する研究が重要です。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/scaling01/status/1969548755255861575?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="latent-learning-2923" class="title-link">[Paper Note] Latent learning: episodic memory complements parametric learning by  enabling flexible reuse of experiences, Andrew Kyle Lampinen+, arXiv'25, 2025.09</h3><br><a href="https://arxiv.org/abs/2509.16189" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2923" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="Generalization.html" target="_blank" rel="noopener noreferrer">#Generalization</a>
<a class="button" href="ReversalCurse.html" target="_blank" rel="noopener noreferrer">#ReversalCurse</a>
<a class="button" href="memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<span class="snippet"><span>GPT Summary</span>- 機械学習システムの一般化失敗の原因として、潜在学習の欠如を指摘。認知科学の視点から、エピソード記憶やオラクルリトリーバルメカニズムが一般化を改善する手段であることを示す。文脈内学習が情報活用の鍵であり、リトリーバル手法がパラメトリック学習を補完することで、データ効率を向上させる可能性を提案。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/arankomatsuzaki/status/1969968869952631225?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="lost-in-2920" class="title-link">[Paper Note] Lost in Embeddings: Information Loss in Vision-Language Models, Wenyan Li+, EMNLP'25 Findings, 2025.09</h3><br><a href="https://arxiv.org/abs/2509.11986" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2920" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="Findings.html" target="_blank" rel="noopener noreferrer">#Findings</a>
<span class="issue_date">Issue Date: 2025-09-21</span>
<span class="snippet"><span>GPT Summary</span>- 視覚と言語のモデル（VLMs）の投影ステップによる情報損失を分析するため、2つのアプローチを提案。1つ目は、投影前後の画像表現のk近傍関係の変化を評価し、2つ目は視覚埋め込みの再構築によって情報損失を測定。実験により、コネクタが視覚表現の幾何学を歪め、k近傍が40～60%乖離することが明らかになり、これは検索性能の低下と関連。パッチレベルの再構築は、モデルの挙動に対する洞察を提供し、高い情報損失がモデルの苦手な事例を予測することを示した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/wenyan62/status/1969298016684163195?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>ポイント解説:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/huggingpapers/status/1969557366245933068?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="length-representations-2905" class="title-link">[Paper Note] Length Representations in Large Language Models, Sangjun Moon+, EMNLP'25</h3><br><a href="https://arxiv.org/abs/2507.20398" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2905" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="Length.html" target="_blank" rel="noopener noreferrer">#Length</a>
<span class="issue_date">Issue Date: 2025-09-20</span>
<span class="snippet"><span>GPT Summary</span>- LLMsは出力シーケンスの長さを制御する能力を持ち、その内部メカニズムを探求。特に、マルチヘッドアテンションが出力長の決定に重要であり、特定の隠れユニットを調整することで長さを制御可能であることを示す。プロンプトが長さ特有になると隠れユニットが活性化し、モデルの内部認識を反映。これにより、LLMsは外部制御なしに出力の長さを適応的に制御するメカニズムを学習していることが示唆される。</span>
</article>
<article class="paper-entry">
<h3 id="the-illusion-2899" class="title-link">[Paper Note] The Illusion of Thinking: Understanding the Strengths and Limitations of  Reasoning Models via the Lens of Problem Complexity, Parshin Shojaee+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2506.06941" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2899" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<span class="snippet"><span>GPT Summary</span>- LRMsは思考プロセスを生成するが、その能力や限界は未解明。評価は主に最終回答の正確性に焦点を当てており、推論の痕跡を提供しない。本研究では制御可能なパズル環境を用いて、LRMsの推論過程を分析。実験により、LRMsは特定の複雑さを超えると正確性が崩壊し、スケーリングの限界が明らかに。低複雑性では標準モデルが優位、中複雑性ではLRMsが優位、高複雑性では両者が崩壊することを示した。推論の痕跡を調査し、LRMsの強みと限界を明らかに。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/parshinshojaee/status/1968812151138918541?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>出た当初相当話題になったIllusion of thinkingがNeurIPSにacceptされた模様。Appendix A.1に当時のcriticismに対するレスポンスが記述されている。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="bread-branched-2898" class="title-link">[Paper Note] BREAD: Branched Rollouts from Expert Anchors Bridge SFT & RL for   Reasoning, Xuechen Zhang+, NeurIPS'25</h3><br><a href="https://arxiv.org/pdf/2506.17211" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2898" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Supervised-FineTuning-(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<span class="snippet"><span>GPT Summary</span>- 小型言語モデル（SLMs）は、トレースが不足している場合に複雑な推論を学ぶのが難しい。本研究では、SFT + RLの限界を調査し、BREADという新しい手法を提案。BREADは、専門家のガイダンスを用いてSFTとRLを統合し、失敗したトレースに対して短いヒントを挿入することで成功を促進。これにより、トレーニングが約3倍速くなり、標準的なGRPOを上回る性能を示す。BREADは、SLMの推論能力を大幅に向上させることが確認された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/sametoymac/status/1968892463382200391?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="the-leaderboard-2895" class="title-link">[Paper Note] The Leaderboard Illusion, Shivalika Singh+, NeurIPS'25</h3><br><a href="https://arxiv.org/abs/2504.20879" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2895" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<span class="snippet"><span>GPT Summary</span>- 進捗測定は科学の進展に不可欠であり、Chatbot ArenaはAIシステムのランキングにおいて重要な役割を果たしている。しかし、非公開のテスト慣行が存在し、特定のプロバイダーが有利になることで、スコアにバイアスが生じることが明らかになった。特に、MetaのLlama-4に関連するプライベートLLMバリアントが問題視され、データアクセスの非対称性が生じている。GoogleやOpenAIはArenaデータの大部分を占め、オープンウェイトモデルは少ないデータしか受け取っていない。これにより、Arena特有のダイナミクスへの過剰適合が発生している。研究は、Chatbot Arenaの評価フレームワークの改革と、公正で透明性のあるベンチマーキングの促進に向けた提言を行っている。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/singhshiviii/status/1968756900062753080?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>要チェック</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="reinforcement-learning-2887" class="title-link">[Paper Note] Reinforcement Learning Finetunes Small Subnetworks in Large Language   Models, Sagnik Mukherjee+, NeurIPS''25, 2025.05</h3><br><a href="https://arxiv.org/abs/2505.11711" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2887" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Sparse.html" target="_blank" rel="noopener noreferrer">#Sparse</a>
<a class="button" href="Initial-Impression-Notes.html" target="_blank" rel="noopener noreferrer">#Initial Impression Notes</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<span class="snippet"><span>GPT Summary</span>- 強化学習（RL）は、LLMsのパフォーマンスと人間の価値観の整合性を大幅に改善する。驚くべきことに、パラメータの5％から30％の小さなサブネットワークのみを更新することで実現されるスパース性が観察され、これは7つのRLアルゴリズムと10のLLMで共通して見られた。このスパース性は本質的であり、サブネットワークのファインチューニングによってテスト精度が回復し、ほぼ同一のモデルが生成される。更新はほぼフルランクであり、ポリシー分布に近いデータでのトレーニングが主な要因と考えられる。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/saagnikkk/status/1968804642449490314?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>openreview: 


<a href="https://openreview.net/forum?id=0NdS4xCngO" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=0NdS4xCngO</a>


</p><p>RLの挙動を理解する上で役に立ちそうで興味深い。以下とは何か関連があるのだろうか:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2382" target="_blank" rel="noopener noreferrer">[Paper Note] On the Generalization of SFT: A Reinforcement Learning Perspective with
  Reward Rectification, Yongliang Wu+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3866" target="_blank" rel="noopener noreferrer">[Paper Note] From Atomic to Composite: Reinforcement Learning Enables Generalization in Complementary Reasoning, Sitao Cheng+, arXiv'25, 2025.12</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="shared-imagination-2847" class="title-link">[Paper Note] Shared Imagination: LLMs Hallucinate Alike, Yilun Zhou+, TMLR'25, 2025.08</h3><br><a href="https://arxiv.org/abs/2407.16604" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2847" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="TMLR.html" target="_blank" rel="noopener noreferrer">#TMLR</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-18</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデル（LLMs）の類似性を理解するために、想像上の質問応答（IQA）という新しい設定を提案。IQAでは、1つのモデルが架空の質問を生成し、別のモデルがそれに答える。驚くべきことに、全てのモデルがフィクションの質問に成功裏に応答できることから、共通の「想像空間」が存在することが示唆される。この現象について調査し、モデルの均質性や幻覚、計算的創造性に関する考察を行う。</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=NUXpBMtDYs" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=NUXpBMtDYs</a>


</p><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/tmlrpub/status/1968449957343433191?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="rl-fine-tuning-2840" class="title-link">[Paper Note] RL Fine-Tuning Heals OOD Forgetting in SFT, Hangzhan Jin+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2509.12235" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2840" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Supervised-FineTuning-(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-17</span>
<span class="snippet"><span>GPT Summary</span>- 二段階ファインチューニングにおけるSFTとRLの相互作用を探求し、SFTが記憶し、RLが一般化するという主張が過度に単純化されていることを発見。具体的には、(1) OOD性能はSFTの初期段階でピークに達し、その後低下すること、(2) RLはSFT中に失われた推論能力を回復する役割を果たすこと、(3) 回復能力には限界があること、(4) OODの挙動は特異ベクトルの「回転」と強く相関することを明らかにした。これにより、SFTとRLの役割を再認識し、特異ベクトルの回転が重要なメカニズムであることを示した。</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1740" target="_blank" rel="noopener noreferrer">SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model   Post-training, Tianzhe Chu+, ICML'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2382" target="_blank" rel="noopener noreferrer">[Paper Note] On the Generalization of SFT: A Reinforcement Learning Perspective with
  Reward Rectification, Yongliang Wu+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2700" target="_blank" rel="noopener noreferrer">[Paper Note] Towards a Unified View of Large Language Model Post-Training, Xingtai Lv+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2713" target="_blank" rel="noopener noreferrer">[Paper Note] RL's Razor: Why Online Reinforcement Learning Forgets Less, Idan Shenfeld+, arXiv'25</a>
<br><br>と合わせて読むと良さそう</p><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/rosinality/status/1968187719588385240?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>直感的には、下記研究でSFTをRLの観点で見たときに、回答の軌跡に対してexact matchしていた場合に1を返す報酬を持つRL、かつimportance weightingによって現在のポリシーが苦手な軌跡を重要視する、ということ考えると、目的のデータに対して汎化性能おかまいなしにgreedyに最適化されるため、OODへの対応力が無くなる、というのはなんとなく理解できる。<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2382" target="_blank" rel="noopener noreferrer">[Paper Note] On the Generalization of SFT: A Reinforcement Learning Perspective with
  Reward Rectification, Yongliang Wu+, arXiv'25</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="the-illusion-2806" class="title-link">[Paper Note] The Illusion of Diminishing Returns: Measuring Long Horizon Execution in  LLMs, Akshit Sinha+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2509.09677" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2806" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="Scaling-Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-09-14</span>
<span class="snippet"><span>GPT Summary</span>- LLMsのスケーリングが収益に影響を与えるかを探求。単一ステップの精度向上がタスクの長さに指数的改善をもたらすことを観察。LLMsが長期タスクで失敗するのは推論能力の欠如ではなく実行ミスによると主張。知識と計画を明示的に提供することで実行能力を向上させる提案。モデルサイズをスケーリングしても自己条件付け効果は減少せず、長いタスクでのミスが増加。思考モデルは自己条件付けを行わずに長いタスクを実行可能。最終的に、実行能力に焦点を当てることで、LLMsの複雑な推論問題解決能力と単純タスクの長期化による失敗理由を調和させる。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/shashwatgoel7/status/1966527903568637972?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>single stepでのタスク性能はサチって見えても、成功可能なタスクの長さは（single stepの実行エラーに引きづられるため）モデルのsingle stepのタスク性能に対して指数関数的に効いている（左上）。タスクが長くなればなるほどモデルは自身のエラーに引きずられ（self conditioning;右上)、これはパラメータサイズが大きいほど度合いが大きくなる（右下;  32Bの場合contextにエラーがあって場合のloeg horizonのAcc.が14Bよりも下がっている）。一方で、実行可能なstep数の観点で見ると、モデルサイズが大きい場合の方が多くのstepを要するタスクを実行できる（左下）。また、ThinkingモデルはSelf Conditioningの影響を受けにくく、single stepで実行可能なタスクの長さがより長くなる（中央下）。<br><br>といった話に見えるが、論文をしっかり読んだ方が良さそう。<br><br><img src="https://github.com/user-attachments/assets/a97fe1f4-5693-4ed3-9fa0-774f4c3738ab" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p><p>（元ポストも著者ポストだが）著者ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/akshitwt/status/1966528585558303209?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><br>このスレッドは読んだ方が良い（というか論文を読んだ方が良い）。<br>特に、**CoTが無い場合は**single-turnでほとんどのモデルは5 stepのタスクをlatent spaceで思考し、実行することができないというのは興味深い（が、細かい設定は確認した方が良い）。なので、マルチステップのタスクは基本的にはplanningをさせてから出力をさせた方が良いという話や、<br><br>では複雑なstepが必要なタスクはsingle turnではなくmulti turnに分けた方が良いのか？と言うと、モデルによって傾向が違うらしい、といった話が書かれている。たとえば、Qwenはsingle turnを好むが、Gemmaはmulti turnを好むらしい。</p><p>日本語ポイント解説:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/iwashi86/status/1966969350197571833?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>解説:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/1968453604655907143?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="scaling-laws-2791" class="title-link">[Paper Note] Scaling Laws for Differentially Private Language Models, Ryan McKenna+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2501.18914" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2791" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Scaling-Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="Privacy.html" target="_blank" rel="noopener noreferrer">#Privacy</a>
<span class="issue_date">Issue Date: 2025-09-13</span>
<span class="snippet"><span>GPT Summary</span>- スケーリング法則はLLMのトレーニングにおいて性能向上を予測し、ハイパーパラメータ選択の指針を提供する。LLMは機密性のあるユーザーデータに依存し、DPなどのプライバシー保護が必要だが、そのダイナミクスは未解明。本研究では、DP LLMトレーニングのスケーリング法則を確立し、計算、プライバシー、ユーティリティのトレードオフを考慮した最適なトレーニング構成を示す。</span>
<span class="snippet"><span>Comment</span><p>blog:


<a href="https://research.google/blog/vaultgemma-the-worlds-most-capable-differentially-private-llm/" target="_blank" rel="noopener noreferrer">https://research.google/blog/vaultgemma-the-worlds-most-capable-differentially-private-llm/</a>


</p><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/jeffdean/status/1966558317418885132?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2792" target="_blank" rel="noopener noreferrer">Calibrating Noise to Sensitivity in Private Data Analysis, Dwork+, TCC'06</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="why-do-2774" class="title-link">[Paper Note] Why Do MLLMs Struggle with Spatial Understanding? A Systematic Analysis  from Data to Architecture, Wanyue Zhang+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2509.02359" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2774" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="SpatialUnderstanding.html" target="_blank" rel="noopener noreferrer">#SpatialUnderstanding</a>
<span class="issue_date">Issue Date: 2025-09-12</span>
<span class="snippet"><span>GPT Summary</span>- 空間理解はMLLMsにとって重要だが、依然として課題が多い。本研究では、単一視点、多視点、ビデオの3つのシナリオにおける空間理解を体系的に分析し、MulSeTというベンチマークを提案。トレーニングデータの増加はパフォーマンス向上に寄与するが、限界があることが示された。また、空間理解は視覚エンコーダの位置エンコーディングに依存しており、推論の注入を通じたアーキテクチャ改善の可能性を探る。これにより、MLLMsの限界を明らかにし、空間推論能力向上の新たな方向性を示唆している。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/askalphaxiv/status/1965822971261718549?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="rl's-razor-2713" class="title-link">[Paper Note] RL's Razor: Why Online Reinforcement Learning Forgets Less, Idan Shenfeld+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2509.04259" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2713" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Supervised-FineTuning-(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Catastrophic-Forgetting.html" target="_blank" rel="noopener noreferrer">#Catastrophic Forgetting</a>
<a class="button" href="On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-09-06</span>
<span class="snippet"><span>GPT Summary</span>- 強化学習（RL）と教師ありファインチューニング（SFT）の比較により、RLが以前の知識をより良く保持することが明らかに。忘却の程度は分布のシフトによって決まり、KLダイバージェンスで測定される。RLは新しいタスクに対してKL最小解にバイアスがかかる一方、SFTは任意の距離に収束する可能性がある。実験を通じて、RLの更新が小さなKL変化をもたらす理由を理論的に説明し、「RLの剃刀」と呼ぶ原則を提唱。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/jyo_pari/status/1963967312555332065?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>所見:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/stone_tao/status/1964381652106563591?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>ポイント解説:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/arankomatsuzaki/status/1963823603469730114?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="towards-a-2700" class="title-link">[Paper Note] Towards a Unified View of Large Language Model Post-Training, Xingtai Lv+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2509.04419" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2700" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Supervised-FineTuning-(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-09-05</span>
<span class="snippet"><span>GPT Summary</span>- 本論文では、オンラインデータとオフラインデータを用いた言語モデルのポストトレーニングアプローチが、矛盾せず単一の最適化プロセスであることを示す。統一ポリシー勾配推定器を導出し、ハイブリッドポストトレーニング（HPT）アルゴリズムを提案。HPTは異なるトレーニング信号を動的に選択し、デモンストレーションを効果的に活用しつつ安定した探索を実現。実験により、HPTが数学的推論ベンチマークで強力な性能を示すことを確認。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/rosinality/status/1963818963550572623?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2382" target="_blank" rel="noopener noreferrer">[Paper Note] On the Generalization of SFT: A Reinforcement Learning Perspective with
  Reward Rectification, Yongliang Wu+, arXiv'25</a>
</p><p>解説:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/omarsar0/status/1963971173735448858?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="the-information-2691" class="title-link">[Paper Note] The Information Dynamics of Generative Diffusion, Luca Ambrogioni, arXiv'25</h3><br><a href="https://arxiv.org/abs/2508.19897" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2691" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2025-09-05</span>
<span class="snippet"><span>GPT Summary</span>- 生成的拡散モデルの統一的な理論的理解を提供し、動的特性、情報理論的特性、熱力学的特性を結びつける。生成帯域幅はスコア関数の発散によって支配され、生成プロセスは対称性の破れによって駆動される。スコア関数はノイズの帯域幅を調整するフィルターとして機能する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/1963750048883429865?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2692" target="_blank" rel="noopener noreferrer">Speed-Accuracy Relations for Diffusion Models: Wisdom from Nonequilibrium Thermodynamics and Optimal Transport, Ikeda+, Physical Review X, 2025</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="benchmarking-optimizers-2678" class="title-link">[Paper Note] Benchmarking Optimizers for Large Language Model Pretraining, Andrei Semenov+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2509.01440" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2678" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<span class="snippet"><span>GPT Summary</span>- 最近のLLMsの発展に伴い、最適化手法の多様な主張があるが、実験プロトコルの違いにより比較が難しい。本研究では、標準化されたLLMの事前トレーニングにおける最適化技術を評価し、モデルサイズやバッチサイズを変化させて最適なオプティマイザを提案。研究が将来の最適化研究の方向性を示し、コードを公開することで再現性を確保し、手法の開発に寄与することを目指す。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/haeggee/status/1963217456740139103?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2674" target="_blank" rel="noopener noreferrer">[Paper Note] Fantastic Pretraining Optimizers and Where to Find Them, Kaiyue Wen+, arXiv'25</a>
<br><br>上記論文と知見が一致する部分、異なる部分は何だろうか？</p><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2666" target="_blank" rel="noopener noreferrer">APERTUS: DEMOCRATIZING OPEN AND COMPLIANT LLMS FOR GLOBAL LANGUAGE ENVIRONMENTS, Apertus Team, 2025.09</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="fantastic-pretraining-2674" class="title-link">[Paper Note] Fantastic Pretraining Optimizers and Where to Find Them, Kaiyue Wen+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2509.02046" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2674" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<span class="snippet"><span>GPT Summary</span>- AdamWは言語モデルの事前学習で広く使用されているオプティマイザですが、代替オプティマイザが1.4倍から2倍のスピードアップを提供するという主張には二つの欠点があると指摘。これらは不均等なハイパーパラメータ調整と誤解を招く評価設定であり、10種類のオプティマイザを系統的に研究することで、公正な比較の重要性を示した。特に、最適なハイパーパラメータはオプティマイザごとに異なり、モデルサイズが大きくなるにつれてスピードアップ効果が減少することが明らかになった。最も高速なオプティマイザは行列ベースの前処理器を使用しているが、その効果はモデルスケールに反比例する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/iscienceluvr/status/1963168542872014943?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>重要そうに見える</p><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2202" target="_blank" rel="noopener noreferrer">[Paper Note] Muon is Scalable for LLM Training, Jingyuan Liu+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2675" target="_blank" rel="noopener noreferrer">[Paper Note] SOAP: Improving and Stabilizing Shampoo using Adam, Nikhil Vyas+, ICLR'25</a>
</p><p>著者ポスト:<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/wen_kaiyue/status/1963633867140526319?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/percyliang/status/1963648131394122222?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>考察:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/rosinality/status/1964098785019060719?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="training-dynamics-2665" class="title-link">[Paper Note] Training Dynamics of the Cooldown Stage in Warmup-Stable-Decay Learning   Rate Scheduler, Aleksandr Dremov+, TMLR'25</h3><br><a href="https://arxiv.org/abs/2508.01483" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2665" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="TMLR.html" target="_blank" rel="noopener noreferrer">#TMLR</a>
<a class="button" href="Scheduler.html" target="_blank" rel="noopener noreferrer">#Scheduler</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<span class="snippet"><span>GPT Summary</span>- WSD学習率スケジューラのクールダウンフェーズを分析し、異なる形状がモデルのバイアス-バリアンスのトレードオフに与える影響を明らかに。探索と活用のバランスが最適なパフォーマンスをもたらすことを示し、特に$\beta_2$の値が高いと改善が見られる。損失のランドスケープを視覚化し、クールダウンフェーズの最適化の重要性を強調。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/haeggee/status/1962852239036293223?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="on-the-2632" class="title-link">[Paper Note] On the Theoretical Limitations of Embedding-Based Retrieval, Orion Weller+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2508.21038" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2632" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<span class="issue_date">Issue Date: 2025-09-01</span>
<span class="snippet"><span>GPT Summary</span>- ベクトル埋め込みは検索タスクにおいて重要な役割を果たしているが、シンプルなクエリでも理論的限界に直面する可能性があることを示す。特に、埋め込みの次元が文書のトップ-kサブセットの数を制限し、k=2でもこの制限が成り立つことを実証。新たに作成したデータセット「LIMIT」では、最先端モデルでさえ失敗することが観察され、既存の埋め込みモデルの限界を明らかにし、今後の研究の必要性を提唱している。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/1962280460605862194?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="drop-dropout-2603" class="title-link">[Paper Note] Drop Dropout on Single-Epoch Language Model Pretraining, Houjun Liu+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2505.24788" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2603" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Regularization.html" target="_blank" rel="noopener noreferrer">#Regularization</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-08-30</span>
<span class="snippet"><span>GPT Summary</span>- ドロップアウトは過学習を防ぐ手法として知られているが、現代の大規模言語モデル（LLM）では過学習が抑えられるため使用されていない。本研究では、BERTやPythiaモデルの単一エポック事前学習においてドロップアウトの影響を調査した結果、ドロップアウトを適用しない方が下流の性能が向上することが判明。また、「早期ドロップアウト」も性能を低下させることが示された。ドロップアウトなしで訓練されたモデルは、モデル編集においてもより成功することがわかり、単一エポックの事前学習中にはドロップアウトを省くことが推奨される。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/jiqizhixin/status/1961589435197505584?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2604" target="_blank" rel="noopener noreferrer">[Paper Note] Dropout Reduces Underfitting, Zhuang Liu+, ICML'23</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="is-chain-of-thought-2569" class="title-link">[Paper Note] Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens, Chengshuai Zhao+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2508.01191" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2569" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="reading.html" target="_blank" rel="noopener noreferrer">#reading</a>
<span class="issue_date">Issue Date: 2025-08-27</span>
<span class="snippet"><span>GPT Summary</span>- Chain-of-Thought (CoT) プロンプティングはLLMの性能向上に寄与するが、その深さには疑問が残る。本研究では、CoT推論が訓練データの構造的バイアスを反映しているかを調査し、訓練データとテストクエリの分布不一致がその効果に与える影響を分析。DataAlchemyという制御環境を用いて、CoT推論の脆弱性を明らかにし、一般化可能な推論の達成に向けた課題を強調する。</span>
</article>
<article class="paper-entry">
<h3 id="school-of-2567" class="title-link">[Paper Note] School of Reward Hacks: Hacking harmless tasks generalizes to misaligned   behavior in LLMs, Mia Taylor+, arXiv'25, 2025.08</h3><br><a href="https://arxiv.org/abs/2508.17511" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2567" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="RewardHacking.html" target="_blank" rel="noopener noreferrer">#RewardHacking</a>
<a class="button" href="EmergentMisalignment.html" target="_blank" rel="noopener noreferrer">#EmergentMisalignment</a>
<span class="issue_date">Issue Date: 2025-08-27</span>
<span class="snippet"><span>GPT Summary</span>- 報酬ハッキングは、エージェントが不完全な報酬関数を利用して意図されたタスクを遂行せず、タスクを誤って実行する現象です。本研究では、詩作や簡単なコーディングタスクにおける報酬ハッキングの例を含むデータセットを構築し、複数のモデルをファインチューニングしました。結果、モデルは新しい設定で報酬ハッキングを一般化し、無関係な不整合行動を示しました。これにより、報酬ハッキングを学習したモデルがより有害な不整合に一般化する可能性が示唆されましたが、さらなる検証が必要です。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/owainevans_uk/status/1960359498515952039?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="identification-and-2533" class="title-link">Identification and Analysis of Identity-Centric Elements of Character-Likeness from Game Scenario, Iwata+, SIGDIAL'25</h3><br><a href="https://x.com/ca_ge_tech/status/1958718266240901237?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2533" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="Game.html" target="_blank" rel="noopener noreferrer">#Game</a>
<span class="issue_date">Issue Date: 2025-08-24</span>
<span class="snippet"><span>Comment</span><p>arxivに無さそうなので、概要は元ポスト参照のこと。キャラクターらしさの構成要素とそれらがキャラクターらしさに関してどのように関係しているかを分析した研究な模様。</p><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hmkz_/status/1958903563561894229?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="are-checklists-2520" class="title-link">[Paper Note] Are Checklists Really Useful for Automatic Evaluation of Generative  Tasks?, Momoka Furuhashi+, EMNLP'25</h3><br><a href="https://arxiv.org/abs/2508.15218" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2520" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-08-22</span>
<span class="snippet"><span>GPT Summary</span>- 生成タスクの自動評価における曖昧な基準の課題を解決するため、チェックリストの使用方法を検討。6つの生成方法と8つのモデルサイズで評価し、選択的チェックリストがペアワイズ評価でパフォーマンスを改善する傾向があることを発見。ただし、直接スコアリングでは一貫性がない。人間の評価基準との相関が低いチェックリスト項目も存在し、評価基準の明確化が必要であることを示唆。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/tohoku_nlp_mmk/status/1958717497454002557?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>pj page:


<a href="https://momo0817.github.io/checklist-effectiveness-study-github.io/" target="_blank" rel="noopener noreferrer">https://momo0817.github.io/checklist-effectiveness-study-github.io/</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="the-policy-2427" class="title-link">[Paper Note] The Policy Cliff: A Theoretical Analysis of Reward-Policy Maps in Large  Language Models, Xingcheng Xu, arXiv'25</h3><br><a href="https://arxiv.org/abs/2507.20150" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2427" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-08-14</span>
<span class="snippet"><span>GPT Summary</span>- 強化学習（RL）は大規模言語モデルの行動形成に重要だが、脆弱なポリシーを生成し、信頼性を損なう問題がある。本論文では、報酬関数から最適ポリシーへのマッピングの安定性を分析する数学的枠組みを提案し、ポリシーの脆弱性が非一意的な最適アクションに起因することを示す。さらに、多報酬RLにおける安定性が「効果的報酬」によって支配されることを明らかにし、エントロピー正則化が安定性を回復することを証明する。この研究は、ポリシー安定性分析を進展させ、安全で信頼性の高いAIシステム設計に寄与する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/jiqizhixin/status/1955909877404197072?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>とても面白そう</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="unveiling-super-2417" class="title-link">[Paper Note] Unveiling Super Experts in Mixture-of-Experts Large Language Models, Zunhai Su+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2507.23279" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2417" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<span class="issue_date">Issue Date: 2025-08-13</span>
<span class="snippet"><span>GPT Summary</span>- スパースに活性化されたMixture-of-Experts（MoE）モデルにおいて、特定の専門家のサブセット「スーパ専門家（SE）」がモデルの性能に重要な影響を与えることを発見。SEは稀な活性化を示し、プルーニングするとモデルの出力が劣化する。分析により、SEの重要性が数学的推論などのタスクで明らかになり、MoE LLMがSEに依存していることが確認された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/jiqizhixin/status/1955217132016505239?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>MoEにおける、特に重要な専門家であるSuper Expertsの存在</p><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1566" target="_blank" rel="noopener noreferrer">The Super Weight in Large Language Models, Mengxia Yu+, arXiv'24</a>
<br><br>を思い出す。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="physics-of-2399" class="title-link">[Paper Note] Physics of Language Models: Part 3.2, Knowledge Manipulation, Zeyuan Allen-Zhu+, ICLR'25</h3><br><a href="https://arxiv.org/abs/2309.14402" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2399" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="ReversalCurse.html" target="_blank" rel="noopener noreferrer">#ReversalCurse</a>
<span class="issue_date">Issue Date: 2025-08-11</span>
<span class="snippet"><span>GPT Summary</span>- 言語モデルは豊富な知識を持つが、下流タスクへの柔軟な利用には限界がある。本研究では、情報検索、分類、比較、逆検索の4つの知識操作タスクを調査し、言語モデルが知識検索には優れているが、Chain of Thoughtsを用いないと分類や比較タスクで苦労することを示した。特に逆検索ではパフォーマンスがほぼ0%であり、これらの弱点は言語モデルに固有であることを確認した。これにより、現代のAIと人間を区別する新たなチューリングテストの必要性が浮き彫りになった。</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=oDbiL9CLoS" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=oDbiL9CLoS</a>


</p><p>解説:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1834" target="_blank" rel="noopener noreferrer">言語モデルの物理学, 佐藤竜馬, 2025.03</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="physics-of-2398" class="title-link">[Paper Note] Physics of Language Models: Part 2.2, How to Learn From Mistakes on   Grade-School Math Problems, Tian Ye+, ICLR'25</h3><br><a href="https://arxiv.org/abs/2408.16293" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2398" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-08-11</span>
<span class="snippet"><span>GPT Summary</span>- 言語モデルの推論精度向上のために、「エラー修正」データを事前学習に組み込む有用性を探求。合成数学データセットを用いて、エラーフリーデータと比較して高い推論精度を達成することを示す。さらに、ビームサーチとの違いやデータ準備、マスキングの必要性、エラー量、ファインチューニング段階での遅延についても考察。</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=zpDGwcmMV4" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=zpDGwcmMV4</a>


</p><p>解説:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1834" target="_blank" rel="noopener noreferrer">言語モデルの物理学, 佐藤竜馬, 2025.03</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="physics-of-2397" class="title-link">[Paper Note] Physics of Language Models: Part 2.1, Grade-School Math and the Hidden   Reasoning Process, Tian Ye+, ICLR'25</h3><br><a href="https://arxiv.org/abs/2407.20311" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2397" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="reading.html" target="_blank" rel="noopener noreferrer">#reading</a>
<span class="issue_date">Issue Date: 2025-08-11</span>
<span class="snippet"><span>GPT Summary</span>- 言語モデルの数学的推論能力を研究し、GSM8Kベンチマークでの精度向上のメカニズムを探る。具体的には、推論スキルの発展、隠れたプロセス、人間との違い、必要なスキルの超越、推論ミスの原因、モデルのサイズや深さについての実験を行い、LLMの理解を深める洞察を提供。</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=Tn5B6Udq3E" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Tn5B6Udq3E</a>


</p><p>解説:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1834" target="_blank" rel="noopener noreferrer">言語モデルの物理学, 佐藤竜馬, 2025.03</a>
</p><p>小学生向けの算数の問題を通じて、以下の基本的なResearch Questionsについて調査して研究。これらを理解することで、言語モデルの知能を理解する礎とする。<br><br>## Research Questions<br>- 言語モデルはどのようにして小学校レベルの算数の問題を解けるようになるのか？<br>  - 単にテンプレートを暗記しているだけなのか、それとも人間に似た推論スキルを学んでいるのか？<br>  - あるいは、その問題を解くために新しいスキルを発見しているのか？<br>- 小学校レベルの算数問題だけで訓練されたモデルは、それらの問題を解くことしか学ばないのか？<br>  - それとも、より一般的な知能を学習するのか？<br>- どのくらい小さい言語モデルまで、小学校レベルの算数問題を解けるのか？<br>  - 深さ（層の数）は幅（層ごとのニューロン数）より重要なのか？<br>  - それとも、単にサイズだけが重要か？<br><br>（続きはのちほど...）</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="on-the-2382" class="title-link">[Paper Note] On the Generalization of SFT: A Reinforcement Learning Perspective with  Reward Rectification, Yongliang Wu+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2508.05629" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2382" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Supervised-FineTuning-(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="KeyPoint-Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-08-09</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデル（LLM）の教師ありファインチューニング（SFT）の一般化能力を向上させるため、動的ファインチューニング（DFT）を提案。DFTはトークンの確率に基づいて目的関数を再スケーリングし、勾配更新を安定化させる。これにより、SFTを大幅に上回る性能を示し、オフライン強化学習でも競争力のある結果を得た。理論的洞察と実践的解決策を結びつけ、SFTの性能を向上させる。コードは公開されている。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/theturingpost/status/1953960036126142645?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>これは大変興味深い。数学以外のドメインでの評価にも期待したい。</p><p>3節冒頭から3.2節にかけて、SFTとon policy RLのgradientを定式化し、SFT側の数式を整理することで、SFT（のgradient)は以下のようなon policy RLの一つのケースとみなせることを導出している。そしてSFTの汎化性能が低いのは 1/pi_theta によるimportance weightingであると主張し、実験的にそれを証明している。つまり、ポリシーがexpertのgold responseに対して低い尤度を示してしまった場合に、weightか過剰に大きくなり、Rewardの分散が過度に大きくなってしまうことがRLの観点を通してみると問題であり、これを是正することが必要。さらに、分散が大きい報酬の状態で、報酬がsparse(i.e., expertのtrajectoryのexact matchしていないと報酬がzero)であることが、さらに事態を悪化させている。<br><br>> conventional SFT is precisely an on-policy-gradient with the reward as an indicator function of<br>matching the expert trajectory but biased by an importance weighting 1/πθ.<br><br>まだ斜め読みしかしていないので、後でしっかり読みたい</p><p>最近は下記で示されている通りSFTでwarm-upをした後にRLによるpost-trainingをすることで性能が向上することが示されており、<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1746" target="_blank" rel="noopener noreferrer">[Paper Note] Demystifying Long Chain-of-Thought Reasoning in LLMs, Edward Yeo+, arXiv'25</a>
 <br><br>主要なOpenModelでもSFT wamup -> RLの流れが主流である。この知見が、SFTによるwarm upの有効性とどう紐づくだろうか？<br>これを読んだ感じだと、importance weightによって、現在のポリシーが苦手な部分のreasoning capabilityのみを最初に強化し（= warmup）、その上でより広範なサンプルに対するRLが実施されることによって、性能向上と、学習の安定につながっているのではないか？という気がする。</p><p>日本語解説:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/1960108668336390593?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><br>一歩先の視点が考察されており、とても勉強になる。</p><p>openreview: 


<a href="https://openreview.net/forum?id=Lv7PjbcaMi" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Lv7PjbcaMi</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="on-the-2352" class="title-link">[Paper Note] On the Expressiveness of Softmax Attention: A Recurrent Neural Network  Perspective, Gabriel Mongaras+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2507.23632" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2352" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-05</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、ソフトマックスアテンションの再帰的な形式を導出し、線形アテンションがその近似であることを示す。これにより、ソフトマックスアテンションの各部分をRNNの言語で説明し、構成要素の重要性と相互作用を理解する。これにより、ソフトマックスアテンションが他の手法よりも表現力が高い理由を明らかにする。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/1952485214162407644?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>LinearAttention関連の研究は下記あたりがありそう？<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2353" target="_blank" rel="noopener noreferrer">[Paper Note] Efficient Attention: Attention with Linear Complexities, Zhuoran Shen+, arXiv'18</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2354" target="_blank" rel="noopener noreferrer">[Paper Note] Linformer: Self-Attention with Linear Complexity, Sinong Wang+, arXiv'20</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2355" target="_blank" rel="noopener noreferrer">[Paper Note] Reformer: The Efficient Transformer, Nikita Kitaev+, ICLR'20</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2356" target="_blank" rel="noopener noreferrer">[Paper Note] Transformers are RNNs: Fast Autoregressive Transformers with Linear  Attention, Angelos Katharopoulos+, ICML'20</a>
</p><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1271" target="_blank" rel="noopener noreferrer">[Paper Note] GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints, Joshua Ainslie+, arXiv'23, 2023.05</a>
<br><br>たとえばGQAはQwen3で利用されているが、本研究の知見を活用してscaled-dot product attention計算時のSoftmax計算の計算量が削減できたら、さらに計算量が削減できそう？</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="rethinking-the-2346" class="title-link">[Paper Note] Rethinking the Role of Prompting Strategies in LLM Test-Time Scaling: A   Perspective of Probability Theory, Yexiang Liu+, ACL'25 Outstanding Paper</h3><br><a href="https://arxiv.org/abs/2505.10981" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2346" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="reading.html" target="_blank" rel="noopener noreferrer">#reading</a>
<a class="button" href="MajorityVoting.html" target="_blank" rel="noopener noreferrer">#MajorityVoting</a>
<span class="issue_date">Issue Date: 2025-08-03</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、LLMのテスト時の計算スケーリングにおけるプロンプト戦略の効果を調査。6つのLLMと8つのプロンプト戦略を用いた実験により、複雑なプロンプト戦略が単純なChain-of-Thoughtに劣ることを示し、理論的な証明を提供。さらに、スケーリング性能を予測し最適なプロンプト戦略を特定する手法を提案し、リソース集約的な推論プロセスの必要性を排除。複雑なプロンプトの再評価と単純なプロンプト戦略の潜在能力を引き出すことで、テスト時のスケーリング性能向上に寄与することを目指す。</span>
<span class="snippet"><span>Comment</span><p>non-thinkingモデルにおいて、Majority Voting (i.e. Self Consistency)によるtest-time scalingを実施する場合のさまざまなprompting戦略のうち、budgetとサンプリング数が小さい場合はCoT以外の適切なprompting戦略はモデルごとに異なるが、budgetやサンプリング数が増えてくるとシンプルなCoT（実験ではzeroshot CoTを利用）が最適なprompting戦略として支配的になる、という話な模様。<br><br>さらに、なぜそうなるかの理論的な分析と最適な与えられた予算から最適なprompting戦略を予測する手法も提案している模様。<br><br>が、評価データの難易度などによってこの辺は変わると思われ、特にFigure39に示されているような、**サンプリング数が増えると簡単な問題の正解率が上がり、逆に難しい問題の正解率が下がるといった傾向があり、CoTが簡単な問題にサンプリング数を増やすと安定して正解できるから支配的になる**、という話だと思われるので、常にCoTが良いと勘違いしない方が良さそうだと思われる。たとえば、**解こうとしているタスクが難問ばかりであればCoTでスケーリングするのが良いとは限らない、といった点には注意が必要**だと思うので、しっかり全文読んだ方が良い。時間がある時に読みたい（なかなかまとまった時間取れない）<br><br><img src="https://github.com/user-attachments/assets/f99e3445-7962-488d-87a4-744022f796c8" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p><p>最適なprompting戦略を予測する手法では、<br>- 問題の難易度に応じて適応的にスケールを変化させ(なんとO(1)で予測ができる)<br>- 動的に最適なprompting戦略を選択<br><br>することで、Majority@10のAcc.を8Bスケールのモデルで10--50%程度向上させることができる模様。いやこれほんとしっかり読まねば。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="mapping-1-2345" class="title-link">[Paper Note] Mapping 1,000+ Language Models via the Log-Likelihood Vector, Momose Oyama+, ACL'25</h3><br><a href="https://arxiv.org/abs/2502.16173" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2345" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-08-03</span>
<span class="snippet"><span>GPT Summary</span>- 自動回帰型言語モデルの比較に対し、対数尤度ベクトルを特徴量として使用する新しいアプローチを提案。これにより、テキスト生成確率のクルバック・ライブラー発散を近似し、スケーラブルで計算コストが線形に増加する特徴を持つ。1,000以上のモデルに適用し、「モデルマップ」を構築することで、大規模モデル分析に新たな視点を提供。</span>
<span class="snippet"><span>Comment</span><p>NLPコロキウムでのスライド:


<a href="https://speakerdeck.com/shimosan/yan-yu-moderunodi-tu-que-lu-fen-bu-to-qing-bao-ji-he-niyorulei-si-xing-noke-shi-hua" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/shimosan/yan-yu-moderunodi-tu-que-lu-fen-bu-to-qing-bao-ji-he-niyorulei-si-xing-noke-shi-hua</a>


<br><br>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hshimodaira/status/1960573414575333556?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="learning-without-2313" class="title-link">[Paper Note] Learning without training: The implicit dynamics of in-context learning, Benoit Dherin+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2507.16003" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2313" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2025-07-29</span>
<span class="snippet"><span>GPT Summary</span>- LLMは文脈内で新しいパターンを学習する能力を持ち、そのメカニズムは未解明である。本研究では、トランスフォーマーブロックが自己注意層とMLPを重ねることで、文脈に応じてMLPの重みを暗黙的に修正できることを示し、このメカニズムがLLMの文脈内学習の理由である可能性を提案する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/omarsar0/status/1948384435654779105?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>解説:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/1950333455134576794?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="subliminal-learning-2282" class="title-link">[Paper Note] Subliminal Learning: Language models transmit behavioral traits via  hidden signals in data, Alex Cloud+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2507.14805" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2282" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="Finetuning.html" target="_blank" rel="noopener noreferrer">#Finetuning</a>
<span class="issue_date">Issue Date: 2025-07-24</span>
<span class="snippet"><span>GPT Summary</span>- サブリミナル学習は、言語モデルが無関係なデータを通じて特性を伝達する現象である。実験では、特定の特性を持つ教師モデルが生成した数列データで訓練された生徒モデルが、その特性を学習することが確認された。データが特性への言及を除去してもこの現象は発生し、異なるベースモデルの教師と生徒では効果が見られなかった。理論的結果を通じて、全てのニューラルネットワークにおけるサブリミナル学習の発生を示し、MLP分類器での実証も行った。サブリミナル学習は一般的な現象であり、AI開発における予期しない問題を引き起こす可能性がある。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/anthropicai/status/1947696314206064819?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>教師モデルが生成したデータから、教師モデルと同じベースモデルを持つ[^1]生徒モデルに対してファインチューニングをした場合、教師モデルと同じ特性を、どんなに厳しく学習元の合成データをフィルタリングしても、意味的に全く関係ないデータを合成しても（たとえばただの数字列のデータを生成したとしても）、生徒モデルに転移してしまう。これは言語モデルに限った話ではなく、ニューラルネットワーク一般について証明された[^2]。<br><br>また、MNISTを用いたシンプルなMLPにおいて、MNISTを教師モデルに対して学習させ、そのモデルに対してランダムノイズな画像を生成させ、同じ初期化を施した生徒モデルに対してFinetuningをした場合、学習したlogitsがMNIST用ではないにもかかわらず、MNISTデータに対して50%以上の分類性能を示し、数字画像の認識能力が意味的に全く関係ないデータから転移されている[^3]、といった現象が生じることも実験的に確認された。<br><br>このため、どんなに頑張って合成データのフィルタリングや高品質化を実施し、教師モデルから特性を排除したデータを作成したつもりでも、そのデータでベースモデルが同じ生徒を蒸留すると、結局その特性は転移されてしまう。これは大きな落とし穴になるので気をつけましょう、という話だと思われる。<br><br>[^1]: これはアーキテクチャの話だけでなく、パラメータの初期値も含まれる<br>[^2]: 教師と生徒の初期化が同じ、かつ十分に小さい学習率の場合において、教師モデルが何らかの学習データDを生成し、Dのサンプルxで生徒モデルでパラメータを更新する勾配を計算すると、教師モデルが学習の過程で経た勾配と同じ方向の勾配が導き出される。つまり、パラメータが教師モデルと同じ方向にアップデートされる。みたいな感じだろうか？元論文を時間がなくて厳密に読めていない、かつalphaxivの力を借りて読んでいるため、誤りがあるかもしれない点に注意<br>[^3]: このパートについてもalphaxivの出力を参考にしており、元論文の記述をしっかり読めているわけではない</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="the-invisible-2272" class="title-link">[Paper Note] The Invisible Leash: Why RLVR May Not Escape Its Origin, Fang Wu+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2507.14843" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2272" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<span class="issue_date">Issue Date: 2025-07-22</span>
<span class="snippet"><span>GPT Summary</span>- RLVRはAIの能力向上に寄与するが、基盤モデルの制約により新しい解の発見を制限する可能性がある。理論的調査により、初期確率がゼロの解をサンプリングできないことや、探索を狭めるトレードオフが明らかになった。実証実験では、RLVRが精度を向上させる一方で、正しい答えを見逃すことが確認された。将来的には、探索メカニズムや過小評価された解に確率質量を注入する戦略が必要とされる。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/iscienceluvr/status/1947570323395907830?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>RLVRの限界に関する洞察</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="what-matters-2257" class="title-link">[Paper Note] What Matters in Learning from Large-Scale Datasets for Robot   Manipulation, Vaibhav Saxena+, ICLR'25</h3><br><a href="https://arxiv.org/abs/2506.13536" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2257" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="Robotics.html" target="_blank" rel="noopener noreferrer">#Robotics</a>
<a class="button" href="EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2025-07-19</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、ロボティクスにおける大規模データセットの構成に関する体系的な理解を深めるため、データ生成フレームワークを開発し、多様性の重要な要素を特定。特に、カメラのポーズや空間的配置がデータ収集の多様性と整合性に影響を与えることを示した。シミュレーションからの洞察が実世界でも有効であり、提案した取得戦略は既存のトレーニング手法を最大70%上回る性能を発揮した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/saxenavaibhav11/status/1946209076305691084?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>元ポストに著者による詳細な解説スレッドがあるので参照のこと。<br><img src="https://github.com/user-attachments/assets/175bc31f-de80-4ad6-aa92-afacc1328345" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="in-context-denoising-2237" class="title-link">[Paper Note] In-context denoising with one-layer transformers: connections between  attention and associative memory retrieval, Matthew Smart+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2502.05164" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2237" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2025-07-16</span>
<span class="snippet"><span>GPT Summary</span>- 「インコンテキストデノイジング」というタスクを通じて、注意ベースのアーキテクチャと密な連想記憶（DAM）ネットワークの関係を探求。ベイズ的フレームワークを用いて、単層トランスフォーマーが特定のデノイジング問題を最適に解決できることを示す。訓練された注意層は、コンテキストトークンを連想記憶として利用し、デノイジングプロンプトを一回の勾配降下更新で処理。これにより、DAMネットワークの新たな拡張例を提供し、連想記憶と注意メカニズムの関連性を強化する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/1945253873456963841?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2146" target="_blank" rel="noopener noreferrer">[Paper Note] Energy-Based Transformers are Scalable Learners and Thinkers, Alexi Gladstone+, arXiv'25</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="rest-stress-2225" class="title-link">[Paper Note] REST: Stress Testing Large Reasoning Models by Asking Multiple Problems  at Once, Zhuoshi Pan+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2507.10541" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2225" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="Batch.html" target="_blank" rel="noopener noreferrer">#Batch</a>
<span class="issue_date">Issue Date: 2025-07-16</span>
<span class="snippet"><span>GPT Summary</span>- RESTという新しい評価フレームワークを提案し、LRMsを同時に複数の問題にさらすことで、実世界の推論能力を評価。従来のベンチマークの限界を克服し、文脈優先配分や問題間干渉耐性を測定。DeepSeek-R1などの最先端モデルでもストレステスト下で性能低下が見られ、RESTはモデル間の性能差を明らかにする。特に「考えすぎの罠」が性能低下の要因であり、「long2short」技術で訓練されたモデルが優れた結果を示すことが確認された。RESTはコスト効率が高く、実世界の要求に適した評価手法である。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/_akhaliq/status/1945130848061194500?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p><img src="https://github.com/user-attachments/assets/eb969359-91d2-4ac4-8a48-1fe27d88ec4e" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="train-for-2216" class="title-link">[Paper Note] Train for the Worst, Plan for the Best: Understanding Token Ordering in  Masked Diffusions, Jaeyeon Kim+, ICML'25</h3><br><a href="https://arxiv.org/abs/2502.06768" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2216" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<span class="issue_date">Issue Date: 2025-07-15</span>
<span class="snippet"><span>GPT Summary</span>- マスク付き拡散モデル（MDMs）は、自己回帰モデル（ARMs）と比較してトレーニングの複雑さと推論の柔軟性をトレードオフする新しい生成モデルです。本研究では、MDMsが自己回帰モデルよりも計算上解決不可能なサブ問題に取り組むことを示し、適応的なトークンデコード戦略がMDMsの性能を向上させることを実証しました。数独の論理パズルにおいて、適応的推論により解決精度が$<7$%から$\approx 90$%に向上し、教師強制でトレーニングされたMDMsがARMsを上回ることを示しました。</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=DjJmre5IkP" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=DjJmre5IkP</a>


</p><p>ICML'25 outstanding papers</p><p>日本語解説:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/1960491242615345237?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="nonlinear-transformers-2198" class="title-link">[Paper Note] Nonlinear transformers can perform inference-time feature learning, Nishikawa+, ICML'25</h3><br><a href="https://openreview.net/forum?id=xQTSvP57C3" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2198" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2025-07-13</span>
<span class="snippet"><span>GPT Summary</span>- 事前学習されたトランスフォーマーは、推論時に特徴を学習する能力を持ち、特に単一インデックスモデルにおける文脈内学習に焦点を当てています。勾配ベースの最適化により、異なるプロンプトからターゲット特徴を抽出し、非適応的アルゴリズムを上回る統計的効率を示します。また、推論時のサンプル複雑性が相関統計クエリの下限を超えることも確認されました。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/btreetaiji/status/1944297631808991742?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="spike-no-2188" class="title-link">[Paper Note] Spike No More: Stabilizing the Pre-training of Large Language Models, Sho Takase+, COLM'25</h3><br><a href="https://arxiv.org/abs/2312.16903" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2188" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<a class="button" href="KeyPoint-Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-07-11</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデルの事前学習中に発生する損失のスパイクは性能を低下させるため、避けるべきである。勾配ノルムの急激な増加が原因とされ、サブレイヤーのヤコビ行列の分析を通じて、勾配ノルムを小さく保つための条件として小さなサブレイヤーと大きなショートカットが必要であることを示した。実験により、これらの条件を満たす手法が損失スパイクを効果的に防ぐことが確認された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/shot4410/status/1943301371010388175?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>small sub-layers, large shortcutsの説明はこちらに書かれている。前者については、現在主流なLLMの初期化手法は満たしているが、後者はオリジナルのTransformerの実装では実装されている[^1]が、最近の実装では失われてしまっているとのこと。<br><img src="https://github.com/user-attachments/assets/55cf847c-fc6a-4e76-88c9-1507464e96a0" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><br>下図が実験結果で、条件の双方を満たしているのはEmbedLN[^2]とScaled Embed[^3]のみであり、実際にスパイクが生じていないことがわかる。<br><img src="https://github.com/user-attachments/assets/79494662-3d58-4d8e-ae9d-8ed9241e0f65" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><br>[^1]:オリジナル論文 <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/245" target="_blank" rel="noopener noreferrer">[Paper Note] Attention Is All You Need, Ashish Vaswani+, NeurIPS'17, 2017.07</a>
 の3.4節末尾、embedding layersに対してsqrt(d_model)を乗じるということがサラッと書いてある。これが実はめちゃめちゃ重要だったという…<br>[^2]: positional embeddingを加算する前にLayer Normalizationをかける方法<br>[^3]: EmbeddingにEmbeddingの次元数d（i.e., 各レイヤーのinputの次元数)の平方根を乗じる方法</p><p>前にScaled dot-product attentionのsqrt(d_k)がめっちゃ重要ということを実験的に示した、という話もあったような…<br>（まあそもそも元論文になぜスケーリングさせるかの説明は書いてあるけども）</p><p>著者ポスト（スライド）:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/shot4410/status/1973694743227027592?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><br>非常に興味深いので参照のこと。初期化の気持ちの部分など勉強になる。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="mixture-of-2185" class="title-link">[Paper Note] Mixture of Experts Provably Detect and Learn the Latent Cluster   Structure in Gradient-Based Learning, Ryotaro Kawata+, ICML'25</h3><br><a href="https://arxiv.org/abs/2506.01656" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2185" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2025-07-11</span>
<span class="snippet"><span>GPT Summary</span>- Mixture of Experts (MoE)は、入力を専門家に動的に分配するモデルのアンサンブルであり、機械学習で成功を収めているが、その理論的理解は遅れている。本研究では、MoEのサンプルおよび実行時間の複雑さを回帰タスクにおけるクラスタ構造を通じて理論的に分析し、バニラニューラルネットワークがこの構造を検出できない理由を示す。MoEは各専門家の能力を活用し、問題をより単純なサブ問題に分割することで、非線形回帰におけるSGDのダイナミクスを探求する初めての試みである。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/btreetaiji/status/1943226334463086989?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="correlated-errors-2145" class="title-link">[Paper Note] Correlated Errors in Large Language Models, Elliot Kim+, ICML'25</h3><br><a href="https://arxiv.org/abs/2506.07962" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2145" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<a class="button" href="ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2025-07-05</span>
<span class="snippet"><span>GPT Summary</span>- 350以上のLLMを評価し、リーダーボードと履歴書スクリーニングタスクで実証的な分析を実施。モデル間のエラーには実質的な相関があり、特に大きく正確なモデルは異なるアーキテクチャやプロバイダーでも高い相関を示す。相関の影響はLLMを評価者とするタスクや採用タスクにおいても確認された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/kennylpeng/status/1940758198320796065?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>これは結果を細かく見るのと、評価したタスクの形式とバイアスが生じないかをきちんと確認した方が良いような気がする。<br><br>それは置いておいたとして、たとえば、Figure9bはLlamaの異なるモデルサイズは、高い相関を示しているが、それはベースが同じだからそうだろうなあ、とは思う。一方、9aはClaude, Nova, Mistral, GPTなど多様なプロバイダーのモデルで高い相関が示されている。Llama3-70BとLLama3.{1,2,3}-70Bでは相関が低かったりしている。<br><img src="https://github.com/user-attachments/assets/03728cf7-9965-4e04-8f19-5ad3977d1a19" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><br>Figure1(b)はHELMで比較的最新のモデル間でプロバイダーが別でも高い相関があるようにみえる。<br><img src="https://github.com/user-attachments/assets/d6d1622a-5215-4464-b265-39cc6f0b7a47" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><br>このような相関がある要因や傾向については論文を読んでみないとわからない。</p><p>OpenReview:


<a href="https://openreview.net/forum?id=kzYq2hfyHB&referrer=%5Bthe%20profile%20of%20Kenny%20Peng%5D(%2Fprofile%3Fid%3D~Kenny_Peng1)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=kzYq2hfyHB&referrer=%5Bthe%20profile%20of%20Kenny%20Peng%5D(%2Fprofile%3Fid%3D~Kenny_Peng1)</a>


</p><p>LLM-as-a-Judgeにおいて、評価者となるモデルと評価対象となるモデルが同じプロバイダーやシリーズの場合は（エラーの傾向が似ているので）性能がAccuracyが真のAccuracyよりも高めに出ている。また評価者よりも性能が低いモデルに対しても、性能が実際のAccuracyよりも高めに出す傾向にある（エラーの相関によってエラーであるにも関わらず正解とみなされAccuracyが高くなる)ようである。逆に、評価者よりも評価対象が性能が高い場合、評価者は自分が誤ってしまうquestionに対して、評価対象モデルが正解となる回答をしても、それに対して報酬を与えることができず性能が低めに見積もられてしまう。これだけの規模の実験で示されたことは、大変興味深い。<br><img src="https://github.com/user-attachments/assets/4a73cdf4-a70d-4f79-997a-3fd5a55c5a60" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p><p>履歴書のスクリーニングタスクについてもケーススタディをしている。こちらも詳細に分析されているので興味がある場合は参照のこと。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="naturalthoughts-selecting-2129" class="title-link">[Paper Note] NaturalThoughts: Selecting and Distilling Reasoning Traces for General  Reasoning Tasks, Yang Li+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2507.01921" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2129" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<span class="issue_date">Issue Date: 2025-07-03</span>
<span class="snippet"><span>GPT Summary</span>- 教師モデルからの推論トレースを用いて生徒モデルの能力を向上させる方法を体系的に研究。NaturalReasoningに基づく高品質な「NaturalThoughts」をキュレーションし、サンプル効率とスケーラビリティを分析。データサイズの拡大が性能向上に寄与し、多様な推論戦略を必要とする例が効果的であることを発見。LlamaおよびQwenモデルでの評価により、NaturalThoughtsが既存のデータセットを上回り、STEM推論ベンチマークで優れた性能を示した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/jaseweston/status/1940656092054204498?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1768" target="_blank" rel="noopener noreferrer">NaturalReasoning: Reasoning in the Wild with 2.8M Challenging Questions, Weizhe Yuan+, arXiv'25</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="bridging-offline-2117" class="title-link">[Paper Note] Bridging Offline and Online Reinforcement Learning for LLMs, Jack Lanchantin+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2506.21495" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2117" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="TransferLearning.html" target="_blank" rel="noopener noreferrer">#TransferLearning</a>
<a class="button" href="DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="VerifiableRewards.html" target="_blank" rel="noopener noreferrer">#VerifiableRewards</a>
<a class="button" href="Off-Policy.html" target="_blank" rel="noopener noreferrer">#Off-Policy</a>
<a class="button" href="On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<a class="button" href="Non-VerifiableRewards.html" target="_blank" rel="noopener noreferrer">#Non-VerifiableRewards</a>
<span class="issue_date">Issue Date: 2025-06-30</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデルのファインチューニングにおける強化学習手法の効果を、オフラインからオンラインへの移行において調査。数学タスクと指示に従うタスクのベンチマーク評価を行い、オンラインおよびセミオンラインの最適化手法がオフライン手法を上回る結果を示す。トレーニングダイナミクスとハイパーパラメータ選択について分析し、検証可能な報酬と検証不可能な報酬を共同で扱うことでパフォーマンス向上を確認。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/jaseweston/status/1939673136842313960?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="octothinker-mid-training-2107" class="title-link">[Paper Note] OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling, Zengzhi Wang+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2506.20512v1" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2107" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-06-27</span>
<span class="snippet"><span>GPT Summary</span>- 異なるベース言語モデル（LlamaやQwen）の強化学習（RL）における挙動を調査し、中間トレーニング戦略がRLのダイナミクスに与える影響を明らかに。高品質の数学コーパスがモデルのパフォーマンスを向上させ、長い連鎖的思考（CoT）がRL結果を改善する一方で、冗長性や不安定性を引き起こす可能性があることを示す。二段階の中間トレーニング戦略「Stable-then-Decay」を導入し、OctoThinkerモデルファミリーを開発。オープンソースのモデルと数学推論コーパスを公開し、RL時代の基盤モデルの研究を支援することを目指す。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/sinclairwang1/status/1938244843857449431?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>mid-trainingの観点から、post trainingにおけるRLがスケーリングする条件をsystematicallyに調査している模様</p><p>論文中にはmid-training[^1]の定義が記述されている:<br><br><img src="https://github.com/user-attachments/assets/da206d3d-f811-4d69-8210-a1d0816c827f" /" alt="image" loading="lazy" width="550" height="400"/><br><br>[^1]: mid-trainingについてはコミュニティの間で厳密な定義はまだ無くバズワードっぽく使われている、という印象を筆者は抱いており、本稿は文献中でmid-trainingを定義する初めての試みという所感</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="an-empirical-2100" class="title-link">[Paper Note] An Empirical Study of Pre-trained Model Selection for   Out-of-Distribution Generalization and Calibration, Hiroki Naganuma+, TMLR'25</h3><br><a href="https://arxiv.org/abs/2307.08187" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2100" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="pretrained-LM.html" target="_blank" rel="noopener noreferrer">#pretrained-LM</a>
<a class="button" href="Scaling-Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="TMLR.html" target="_blank" rel="noopener noreferrer">#TMLR</a>
<span class="issue_date">Issue Date: 2025-06-26</span>
<span class="snippet"><span>GPT Summary</span>- 事前学習済みモデルのファインチューニングが分布外一般化タスクにおいて重要であることを示し、モデルのサイズやデータセットの選択がOOD精度と信頼性キャリブレーションに与える影響を調査。120,000時間以上の実験を通じて、大きなモデルと大規模なデータセットがOODパフォーマンスとキャリブレーションを改善することを発見。これは、従来の研究と対照的であり、事前学習済みモデルの選択の重要性を強調している。</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=tYjoHjShxF" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=tYjoHjShxF</a>


</p><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/_hiroki11x/status/1938052113466323134?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="mind-the-2080" class="title-link">[Paper Note] Mind the Gap: Examining the Self-Improvement Capabilities of Large  Language Models, Yuda Song+, ICLR'25</h3><br><a href="https://arxiv.org/abs/2412.02674" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2080" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-06-24</span>
<span class="snippet"><span>GPT Summary</span>- 自己改善はLLMの出力検証を通じてデータをフィルタリングし、蒸留するメカニズムである。本研究では、自己改善の数学的定式化を行い、生成-検証ギャップに基づくスケーリング現象を発見。さまざまなモデルとタスクを用いた実験により、自己改善の可能性とその性能向上方法を探求し、LLMの理解を深めるとともに、将来の研究への示唆を提供する。</span>
<span class="snippet"><span>Comment</span><p>参考:


<a href="https://joisino.hatenablog.com/entry/mislead" target="_blank" rel="noopener noreferrer">https://joisino.hatenablog.com/entry/mislead</a>


</p><p>Verificationに対する理解を深めるのに非常に良さそう</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="on-the-2077" class="title-link">[Paper Note] On the Self-Verification Limitations of Large Language Models on   Reasoning and Planning Tasks, Kaya Stechly+, ICLR'25</h3><br><a href="https://arxiv.org/abs/2402.08115" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2077" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-06-24</span>
<span class="snippet"><span>GPT Summary</span>- LLMsの推論能力に関する意見の相違を背景に、反復的なプロンプトの効果をGame of 24、グラフ彩色、STRIPS計画の3領域で調査。自己批評がパフォーマンスに悪影響を及ぼす一方、外部の正しい推論者による検証がパフォーマンスを向上させることを示した。再プロンプトによって複雑な設定の利点を維持できることも確認。</span>
<span class="snippet"><span>Comment</span><p>参考:


<a href="https://joisino.hatenablog.com/entry/mislead" target="_blank" rel="noopener noreferrer">https://joisino.hatenablog.com/entry/mislead</a>


</p><p>OpenReview:


<a href="https://openreview.net/forum?id=4O0v4s3IzY" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=4O0v4s3IzY</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="language-models-2076" class="title-link">[Paper Note] Language Models Learn to Mislead Humans via RLHF, Jiaxin Wen+, ICLR'25</h3><br><a href="https://arxiv.org/abs/2409.12822" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2076" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-06-24</span>
<span class="snippet"><span>GPT Summary</span>- RLHFは言語モデルのエラーを悪化させる可能性があり、モデルが人間を納得させる能力を向上させる一方で、タスクの正確性は向上しない。質問応答タスクとプログラミングタスクで被験者の誤検出率が増加し、意図された詭弁を検出する手法がU-SOPHISTRYには適用できないことが示された。これにより、RLHFの問題点と人間支援の研究の必要性が浮き彫りになった。</span>
<span class="snippet"><span>Comment</span><p>参考:


<a href="https://joisino.hatenablog.com/entry/mislead" target="_blank" rel="noopener noreferrer">https://joisino.hatenablog.com/entry/mislead</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="reasoning-by-2059" class="title-link">[Paper Note] Reasoning by Superposition: A Theoretical Perspective on Chain of Continuous Thought, Hanlin Zhu+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2505.12514" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2059" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2025-06-18</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、連続CoTsを用いた二層トランスフォーマーが有向グラフ到達可能性問題を解決できることを証明。連続CoTsは複数の探索フロンティアを同時にエンコードし、従来の離散CoTsよりも効率的に解を導く。実験により、重ね合わせ状態が自動的に現れ、モデルが複数のパスを同時に探索することが確認された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/tydsh/status/1935206012799303817?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="massive-supervised-2052" class="title-link">[Paper Note] Massive Supervised Fine-tuning Experiments Reveal How Data, Layer, and  Training Factors Shape LLM Alignment Quality, Yuto Harada+, EMNLP'25</h3><br><a href="https://arxiv.org/abs/2506.14681" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2052" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Supervised-FineTuning-(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-06-18</span>
<span class="snippet"><span>GPT Summary</span>- SFTはLLMを人間の指示に整合させる重要なプロセスであり、1,000以上のSFTモデルを生成し、データセットの特性と層ごとの変更を調査。訓練タスクの相乗効果やモデル固有の戦略の重要性を明らかにし、困惑度がSFTの効果を予測することを示した。中間層の重みの変化がパフォーマンス向上と強く相関し、研究を加速させるためにモデルと結果を公開予定。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/odashi_t/status/1935191113981403359?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>NLP'25:


<a href="https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/C10-6.pdf" target="_blank" rel="noopener noreferrer">https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/C10-6.pdf</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="what-is-2049" class="title-link">[Paper Note] What Is Seen Cannot Be Unseen: The Disruptive Effect of Knowledge  Conflict on Large Language Models, Kaiser Sun+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2506.06485" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2049" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="FactualKnowledge.html" target="_blank" rel="noopener noreferrer">#FactualKnowledge</a>
<span class="issue_date">Issue Date: 2025-06-17</span>
<span class="snippet"><span>GPT Summary</span>- LLMの文脈情報とパラメトリック知識の対立を評価する診断フレームワークを提案。知識の対立はタスクに影響を与えず、一致時にパフォーマンスが向上。モデルは内部知識を抑制できず、対立の理由が文脈依存を高めることを示した。これにより、LLMの評価と展開における知識の対立の重要性が強調される。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/kaiserwholearns/status/1934582217692295268?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="how-much-2014" class="title-link">[Paper Note] How much do language models memorize?, John X. Morris+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2505.24832" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2014" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Memorization.html" target="_blank" rel="noopener noreferrer">#Memorization</a>
<span class="issue_date">Issue Date: 2025-06-05</span>
<span class="snippet"><span>GPT Summary</span>- モデルの「知識」を推定する新手法を提案し、言語モデルの能力を測定。記憶を「意図しない記憶」と「一般化」に分け、一般化を排除することで総記憶を計算。GPTスタイルのモデルは約3.6ビット/パラメータの能力を持つと推定。データセットのサイズ増加に伴い、モデルは記憶を保持し、一般化が始まると意図しない記憶が減少。数百のトランスフォーマー言語モデルを訓練し、能力とデータサイズの関係を示すスケーリング法則を生成。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/rohanpaul_ai/status/1929989864927146414?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="prorl-prolonged-2011" class="title-link">[Paper Note] ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in  Large Language Models, Mingjie Liu+, NeurIPS'25</h3><br><a href="https://arxiv.org/abs/2505.24864" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2011" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-06-04</span>
<span class="snippet"><span>GPT Summary</span>- 強化学習（RL）が言語モデルの推論能力を向上させる可能性を探る本研究では、長期的なRL（ProRL）トレーニングが新しい推論戦略を明らかにできることを示します。新しいトレーニング手法ProRLを導入し、実証分析により、RLでトレーニングされたモデルが基礎モデルを上回ることが確認されました。推論の改善は基礎モデルの能力やトレーニング期間と相関しており、RLが新しい解決空間を探索できることを示唆しています。これにより、RLが言語モデルの推論を拡張する条件に関する新たな洞察が得られ、今後の研究の基盤が築かれます。モデルの重みは公開されています。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/1930043688329326962?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>RLVR（math, code（従来はこの2種類）, STEM, logic Puzzles, instruction following）によって大規模なスケール（長期的に学習をする; 2k training stepsと多様なタスクでの学習データ）で実験をし、定期的にReferenceポリシーとOptimizerをリセットすることで、元のポリシーからの乖離を防ぎつつも、新たな学習が進むようなことをしている模様。<br>（※PFNのランチタイムトークを参考に記述）<br><br>verlを用いて、DAPOで学習をしている。<br><img src="https://github.com/user-attachments/assets/db706cfc-e756-47d1-a0e7-8fbc8043ae17" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1969" target="_blank" rel="noopener noreferrer">verl: Volcano Engine Reinforcement Learning for LLMs, ByteDance Seed Team, 2025.04</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1815" target="_blank" rel="noopener noreferrer">[Paper Note] DAPO: An Open-Source LLM Reinforcement Learning System at Scale, Qiying Yu+, NeurIPS'25</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="learning-compositional-2007" class="title-link">[Paper Note] Learning Compositional Functions with Transformers from Easy-to-Hard   Data, Zixuan Wang+, COLT'25</h3><br><a href="https://arxiv.org/abs/2505.23683" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2007" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="COLT.html" target="_blank" rel="noopener noreferrer">#COLT</a>
<span class="issue_date">Issue Date: 2025-06-01</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、Transformerベースの言語モデルの学習可能性を探求し、$k$-fold compositionタスクに焦点を当てる。$O(\log k)$層のトランスフォーマーでこのタスクを表現できる一方、SQオラクルに対するクエリの下限を示し、サンプルサイズが指数的である必要があることを証明。さらに、カリキュラム学習戦略を用いて、簡単な例と難しい例を含むデータ分布がトランスフォーマーの効率的な学習に必要であることを明らかにした。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/zzzixuanwang/status/1928465115478708604?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>こちらはまず元ポストのスレッドを読むのが良いと思われる。要点をわかりやすく説明してくださっている。</p><p>元ポストとalphaxivでざっくり理解したところ、<br><br>Transformerがcontextとして与えられた情報(σ)とparametric knowledge(π)をk回の知識マッピングが必要なタスク(k-fold composition task)を学習するにはO(log k)のlayer数が必要で、直接的にk回の知識マッピングが必要なタスクを学習するためにはkの指数オーダーのデータ量が最低限必要となることが示された。これはkが大きくなると（すなわち、複雑なreasoning stepが必要なタスク）になると非現実的なものとなるため、何らかの方法で緩和したい。学習データを簡単なものから難しいものをmixingすること（カリキュラム学習）ことで、この条件が緩和され、指数オーダーから多項式オーダーのデータ量で学習できることが示された<br><br>といった感じだと思われる。</p><p>じゃあ最新の32Bモデルよりも、よりパラメータ数が大きくてlayer数が多い古いモデルの方が複雑なreasoningが必要なタスクを実は解けるってこと！？直感に反する！と一瞬思ったが、おそらく最近のモデルでは昔のモデルと比べてparametric knowledgeがより高密度に適切に圧縮されるようになっていると思われるので、昔のモデルではk回の知識マッピングをしないと解けないタスクが、最新のモデルではk-n回のマッピングで解けるようになっていると推察され、パラメータサイズが小さくても問題なく解けます、みたいなことが起こっているのだろう、という感想を抱くなどした</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="scaling-reasoning-1989" class="title-link">Scaling Reasoning, Losing Control: Evaluating Instruction Following in  Large Reasoning Models, Tingchen Fu+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2505.14810" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1989" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Supervised-FineTuning-(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="InstructionFollowingCapability.html" target="_blank" rel="noopener noreferrer">#InstructionFollowingCapability</a>
<span class="issue_date">Issue Date: 2025-05-24</span>
<span class="snippet"><span>GPT Summary</span>- 指示に従う能力はLLMにとって重要であり、MathIFという数学的推論タスク用のベンチマークを提案。推論能力の向上と指示遵守の間には緊張関係があり、特に長い思考の連鎖を持つモデルは指示に従いにくい。介入により部分的な従順さを回復できるが、推論性能が低下することも示された。これらの結果は、指示に敏感な推論モデルの必要性を示唆している。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/yafuly/status/1925753754961236006?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="llms-get-1988" class="title-link">LLMs Get Lost In Multi-Turn Conversation, Philippe Laban+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2505.06120" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1988" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="Conversation.html" target="_blank" rel="noopener noreferrer">#Conversation</a>
<a class="button" href="ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-05-24</span>
<span class="snippet"><span>GPT Summary</span>- LLMsは会話型インターフェースとして、ユーザーがタスクを定義するのを支援するが、マルチターンの会話ではパフォーマンスが低下する。シミュレーション実験の結果、マルチターンで39%のパフォーマンス低下が見られ、初期のターンでの仮定に依存しすぎることが原因と判明。LLMsは会話中に誤った方向に進むと、回復が難しくなることが示された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/_stakaya/status/1926009283386155009?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>Lost in the MiddleならぬLost in Conversation<br><img src="https://github.com/user-attachments/assets/9d4320f5-6fea-43ca-a7ab-a836e7e3642e" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/793" target="_blank" rel="noopener noreferrer">Lost in the Middle: How Language Models Use Long Contexts, Nelson F. Liu+, N/A, TACL'24</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="why-vision-1974" class="title-link">[Paper Note] Why Vision Language Models Struggle with Visual Arithmetic? Towards   Enhanced Chart and Geometry Understanding, Kung-Hsiang Huang+, ACL'25, 2025.02</h3><br><a href="https://arxiv.org/abs/2502.11492" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1974" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Supervised-FineTuning-(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="Probing.html" target="_blank" rel="noopener noreferrer">#Probing</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-05-18</span>
<span class="snippet"><span>GPT Summary</span>- Vision Language Models (VLMs)は視覚的算術に苦労しているが、CogAlignという新しいポストトレーニング戦略を提案し、VLMの性能を向上させる。CogAlignは視覚的変換の不変特性を認識するように訓練し、CHOCOLATEで4.6%、MATH-VISIONで2.9%の性能向上を実現し、トレーニングデータを60%削減。これにより、基本的な視覚的算術能力の向上と下流タスクへの転送の効果が示された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/steeve__huang/status/1923543884367306763?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>既存のLLM (proprietary, openweightそれぞれ)が、シンプルなvisual arithmeticタスク(e.g., 線分の長さ比較, Chart上のdotの理解)などの性能が低いことを明らかにし、<br><img src="https://github.com/user-attachments/assets/039a48de-67a5-4c81-ba59-174acd508479" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br>それらの原因を(1)Vision Encoderのrepresentationと(2)Vision EncoderをFreezeした上でのText Decoderのfinetuningで分析した。その結果、(1)ではいくつかのタスクでlinear layerのprobingでは高い性能が達成できないことがわかった。このことから、Vision Encoderによるrepresentationがタスクに関する情報を内包できていないか、タスクに関する情報は内包しているがlinear layerではそれを十分に可能できない可能性が示唆された。<br><img src="https://github.com/user-attachments/assets/0eb90fa2-7b6a-43b6-81d9-b5f7e6fb3ea8" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><br>これをさらに分析するために(2)を実施したところ、Vision Encoderをfreezeしていてもfinetuningによりquery stringに関わらず高い性能を獲得できることが示された。このことから、Vision Encoder側のrepresentationの問題ではなく、Text Decoderと側でデコードする際にFinetuningしないとうまく活用できないことが判明した。<br><img src="https://github.com/user-attachments/assets/cd122d99-9228-44b1-9827-cdb56f49d492" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p><p>手法のところはまだ全然しっかり読めていないのだが、画像に関する特定の属性に関するクエリと回答のペアを合成し、DPOすることで、zero-shotの性能が向上する、という感じっぽい？<br><img src="https://github.com/user-attachments/assets/707b1cc9-8bbf-45a5-b564-f654503c836e" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><img src="https://github.com/user-attachments/assets/281da17b-c8c3-455a-aa51-043ed297ae1f" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="layer-by-1924" class="title-link">Layer by Layer: Uncovering Hidden Representations in Language Models, Oscar Skean+, ICML'25</h3><br><a href="https://arxiv.org/abs/2502.02013" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1924" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="Supervised-FineTuning-(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="SSM-(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<a class="button" href="ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="CompressionValleys.html" target="_blank" rel="noopener noreferrer">#CompressionValleys</a>
<span class="issue_date">Issue Date: 2025-05-04</span>
<span class="snippet"><span>GPT Summary</span>- 中間層の埋め込みが最終層を超えるパフォーマンスを示すことを分析し、情報理論や幾何学に基づくメトリクスを提案。32のテキスト埋め込みタスクで中間層が強力な特徴を提供することを実証し、AIシステムの最適化における中間層の重要性を強調。</span>
<span class="snippet"><span>Comment</span><p>現代の代表的な言語モデルのアーキテクチャ（decoder-only model, encoder-only model, SSM）について、最終層のembeddingよりも中間層のembeddingの方がdownstream task（MTEBの32Taskの平均）に、一貫して（ただし、これはMTEBの平均で見たらそうという話であり、個別のタスクで一貫して強いかは読んでみないとわからない）強いことを示した研究。<br><br>このこと自体は経験的に知られているのであまり驚きではないのだが（ただ、SSMでもそうなのか、というのと、一貫して強いというのは興味深い）、この研究はMatrix Based Entropyと呼ばれるものに基づいて、これらを分析するための様々な指標を定義し理論的な根拠を示し、Autoregressiveな学習よりもMasked Languageによる学習の方がこのようなMiddle Layerのボトルネックが緩和され、同様のボトルネックが画像の場合でも起きることを示し、CoTデータを用いたFinetuningについても分析している模様。この辺の貢献が非常に大きいと思われるのでここを理解することが重要だと思われる。あとで読む。<br><br><img src="https://github.com/user-attachments/assets/bda00c50-c97b-45e0-97a5-d98dd98599fd" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p><p>openreview:


<a href="https://openreview.net/forum?id=WGXb7UdvTX" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=WGXb7UdvTX</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="when-more-1918" class="title-link">[Paper Note] When More is Less: Understanding Chain-of-Thought Length in LLMs, Yuyang Wu+, ICLR'25</h3><br><a href="https://arxiv.org/abs/2502.07266" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1918" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-04-30</span>
<span class="snippet"><span>GPT Summary</span>- Chain-of-thought (CoT)推論は、LLMsの多段階推論能力を向上させるが、CoTの長さが増すと最初は性能が向上するものの、最終的には低下することが観察される。長い推論プロセスがノイズに脆弱であることを示し、理論的に最適なCoTの長さを導出。Length-filtered Voteを提案し、CoTの長さをモデルの能力とタスクの要求に合わせて調整する必要性を強調。</span>
<span class="snippet"><span>Comment</span><p>ICLR 2025 Best Paper Runner Up Award<br>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/yifeiwang77/status/1916873981979660436?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="why-do-1904" class="title-link">Why Do Multi-Agent LLM Systems Fail?, Mert Cemri+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2503.13657v2" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1904" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<span class="issue_date">Issue Date: 2025-04-26</span>
<span class="snippet"><span>GPT Summary</span>- MASの性能向上が単一エージェントと比較して限定的であることを受け、MAST（Multi-Agent System Failure Taxonomy）を提案。200以上のタスクを分析し、14の失敗モードを特定し、3つの大カテゴリに整理。Cohenのカッパスコア0.88を達成し、LLMを用いた評価パイプラインを開発。ケーススタディを通じて失敗分析とMAS開発の方法を示し、今後の研究のためのロードマップを提示。データセットとLLMアノテーターをオープンソース化予定。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/mertcemri/status/1915567789714329799?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>7つのメジャーなマルチエージェントフレームワークに対して200以上のタスクを実施し、6人の専門家がtraceをアノテーション。14種類の典型的なfailure modeを見つけ、それらを3つにカテゴライズ。これを考慮してマルチエージェントシステムの失敗に関するTaxonomy（MAS）を提案<br><img src="https://github.com/user-attachments/assets/21d45bc7-cc6c-4561-b991-098f8d068627" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="learning-dynamics-1892" class="title-link">[Paper Note] Learning Dynamics of LLM Finetuning, Yi Ren+, ICLR'25</h3><br><a href="https://arxiv.org/pdf/2407.10490" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1892" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="Repetition.html" target="_blank" rel="noopener noreferrer">#Repetition</a>
<span class="issue_date">Issue Date: 2025-04-18</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、大規模言語モデルのファインチューニング中の学習ダイナミクスを分析し、異なる応答間の影響の蓄積を段階的に解明します。指示調整と好み調整のアルゴリズムに関する観察を統一的に解釈し、ファインチューニング後の幻覚強化の理由を仮説的に説明します。また、オフポリシー直接好み最適化（DPO）における「圧縮効果」を強調し、望ましい出力の可能性が低下する現象を探ります。このフレームワークは、LLMのファインチューニング理解に新たな視点を提供し、アラインメント性能向上のためのシンプルな方法を示唆します。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/joshuarenyi/status/1913033476275925414?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>解説ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/1917189793588613299?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="a-sober-1887" class="title-link">[Paper Note] A Sober Look at Progress in Language Model Reasoning: Pitfalls and Paths   to Reproducibility, Andreas Hochlehnert+, COLM'25</h3><br><a href="https://arxiv.org/pdf/2504.07086" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1887" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Supervised-FineTuning-(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="In-Depth-Notes.html" target="_blank" rel="noopener noreferrer">#In-Depth Notes</a>
<a class="button" href="KeyPoint-Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="Initial-Impression-Notes.html" target="_blank" rel="noopener noreferrer">#Initial Impression Notes</a>
<span class="issue_date">Issue Date: 2025-04-13</span>
<span class="snippet"><span>GPT Summary</span>- 推論は言語モデルの重要な課題であり、進展が見られるが、評価手法には透明性や堅牢性が欠けている。本研究では、数学的推論ベンチマークが実装の選択に敏感であることを発見し、標準化された評価フレームワークを提案。再評価の結果、強化学習アプローチは改善が少なく、教師ありファインチューニング手法は強い一般化を示した。再現性を高めるために、関連するコードやデータを公開し、今後の研究の基盤を築く。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/wenhuchen/status/1911143014258405420?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>SLMをmath reasoning向けにpost-trainingする場合、評価の条件をフェアにするための様々な工夫を施し評価をしなおした結果（Figure1のように性能が変化する様々な要因が存在する）、RL（既存研究で試されているもの）よりも（大規模モデルからrejection samplingしたreasoning traceを用いて）SFTをする方が同等か性能が良く(Table3)、結局のところ（おそらく汎化性能が低いという意味で）reliableではなく、かつ（おそらく小規模なモデルでうまくいかないという意味での）scalableではないので、reliableかつscalableなRL手法が不足しているとのこと。<br><br>※ 本論文で分析されているのは<=10B以下のSLMである点に注意。10B以上のモデルで同じことが言えるかは自明ではない。<br>※ DAPO, VAPOなどについても同じことが言えるかも自明ではない。<br>※ DeepSeek-R1のtechnical reportにおいて、小さいモデルにGRPOを適用してもあまり効果が無かったことが既に報告されている。<br><br><img src="https://github.com/user-attachments/assets/620017f1-b3f0-40c1-bf61-3b0b7a429ab4" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><img src="https://github.com/user-attachments/assets/321132c8-dad5-4aa1-9811-f032e3474135" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1743" target="_blank" rel="noopener noreferrer">DeepSeek-R1の論文読んだ？【勉強になるよ】 , asap, 2025.01</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1719" target="_blank" rel="noopener noreferrer">DeepSeek-R1, DeepSeek, 2025.01</a>
</p><p>個々のpost-trainingされたRLモデルが具体的にどういう訓練をしたのかは追えていないが、DAPOやDr. GRPO, VAPOの場合はどうなるんだろうか？<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1815" target="_blank" rel="noopener noreferrer">[Paper Note] DAPO: An Open-Source LLM Reinforcement Learning System at Scale, Qiying Yu+, NeurIPS'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1876" target="_blank" rel="noopener noreferrer">VAPO: Efficient and Reliable Reinforcement Learning for Advanced
  Reasoning Tasks, YuYue+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1821" target="_blank" rel="noopener noreferrer">[Paper Note] Understanding R1-Zero-Like Training: A Critical Perspective, Zichen Liu+, arXiv'25, 2025.03</a>
<br><br>Rewardの設定の仕方はどのような影響があるのだろうか（verifiable rewardなのか、neuralモデルによるrewardなのかなど)？<br><br>学習のさせ方もどのような影響があるのだろうか（RLでカリキュラムlearningにした場合など）？<br><br>検証しているモデルがそれぞれどのような設定で学習されているかまでを見ないとこの辺はわからなそう。<br><br>ただなんとなーくの直感だと、SLMを賢くしたいという場合は何らかの賢いモデルの恩恵に預かると有利なケースが多く（SFTの場合はそれが大規模なモデルから蒸留したreasoning trace）、SLM+RLの場合はPRMのような思考プロセスを評価してRewardに反映させるようなものを利用しないと、少なくとも小規模なLLMをめちゃ賢くします〜というのはきついんじゃないかなあという感想ではある。<br>ただ、結局SLMという時点で多くの場合、より賢いパラメータ数の多いLLMが世の中には存在するあるはずなので、RLしないでSFTして蒸留すれば良いんじゃない…？と思ってしまう。<br>が、多くの場合その賢いLLMはProprietaryなLLMであり、出力を得て自分のモデルをpost-trainingすることは利用規約違反となるため、自前で賢くてパラメータ数の多いLLMを用意できない場合は困ってしまうので、SLMをクソデカパラメータのモデルの恩恵なしで超絶賢くできたら世の中の多くの人は嬉しいよね、とも思う。</p><p>（斜め読みだが）<br>サンプル数が少ない（数十件）AIMEやAMCなどのデータはseedの値にとてもsensitiveであり(Takeaway1, 2)、<br><br><img src="https://github.com/user-attachments/assets/97581133-cf17-4635-b66c-442eaf8956d4" /" alt="image" loading="lazy" width="550" height="400"/><br><br>それらは10種類のseedを用いて結果を平均すると分散が非常に小さくなるので、seedは複数種類利用して平均の性能を見た方がreliableであり(Takeaway3)<br><br><img src="https://github.com/user-attachments/assets/5065ef0e-de89-4b17-aa52-c90b7191e9b2" /" alt="image" loading="lazy" width="550" height="400"/><br><br>temperatureを高くするとピーク性能が上がるが分散も上がるため再現性の課題が増大するが、top-pを大きくすると再現性の問題は現れず性能向上に寄与し<br><br><img src="https://github.com/user-attachments/assets/76d5c989-edbb-4d70-9080-d1d4b01de2ff" /" alt="image" loading="lazy" width="550" height="400"/><br><br>既存研究のモデルのtemperatureとtop-pを変化させ実験するとperformanceに非常に大きな変化が出るため、モデルごとに最適な値を選定して比較をしないとunfairであることを指摘 (Takeaway4)。<br><br><img src="https://github.com/user-attachments/assets/d8b453d1-3d2e-4a80-b03d-c69ec1b2232e" /" alt="image" loading="lazy" width="550" height="400"/><br><br>また、ハードウェアの面では、vLLMのようなinference engineはGPU typeやmemoryのconfigurationに対してsensitiveでパフォーマンスが変わるだけでなく、<br><br><img src="https://github.com/user-attachments/assets/a41891c7-072c-4c38-9ad6-beada4721bac" /" alt="image" loading="lazy" width="550" height="400"/><br><br>評価に利用するフレームワークごとにinference engineとprompt templateが異なるためこちらもパフォーマンスに影響が出るし (Takeaway5)、<br><br><img src="https://github.com/user-attachments/assets/1f7d328c-0757-47b9-9961-630e2429fb3e" /" alt="image" loading="lazy" width="550" height="400"/><br><br>max output tokenの値を変化させると性能も変わり、prompt templateを利用しないと性能が劇的に低下する (Takeaway6)。<br><br><img src="https://github.com/user-attachments/assets/dc0902d1-a5f2-47de-8df1-c28107e1da28" /" alt="image" loading="lazy" width="550" height="400"/><br><br>これらのことから著者らはreliableな評価のために下記を提案しており (4.1節; 後ほど追記)、<br><br>実際にさまざまな条件をfair comparisonとなるように標準化して評価したところ（4.2節; 後ほど追記）<br><br>上の表のような結果となった。この結果は、<br>- DeepSeekR1-DistilledをRLしてもSFTと比較したときに意味のあるほどのパフォーマンスの向上はないことから、スケーラブル、かつ信頼性のあるRL手法がまだ不足しており<br>- 大規模なパラメータのモデルのreasoning traceからSFTをする方法はさまざまなベンチマークでロバストな性能（＝高い汎化性能）を持ち、RLと比べると現状はRLと比較してよりパラダイムとして成熟しており<br>- （AIME24,25を比較するとSFTと比べてRLの場合performanceの低下が著しいので）RLはoverfittingしやすく、OODなベンチマークが必要</p><p>しっかりと評価の枠組みを標準化してfair comparisonしていかないと、RecSys業界の二の舞になりそう（というかもうなってる？）。<br><br>またこの研究で分析されているのは小規模なモデル（<=10B）に対する既存研究で用いられた一部のRL手法や設定の性能だけ（真に示したかったらPhisics of LLMのような完全にコントロール可能なサンドボックスで実験する必要があると思われる）なので、DeepSeek-R1のように、大規模なパラメータ（数百B）を持つモデルに対するRLに関して同じことが言えるかは自明ではない点に注意。</p><p>openreview:


<a href="https://openreview.net/forum?id=90UrTTxp5O#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=90UrTTxp5O#discussion</a>


</p><p>最近の以下のようなSFTはRLの一つのケースと見做せるという議論を踏まえるとどうなるだろうか<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2382" target="_blank" rel="noopener noreferrer">[Paper Note] On the Generalization of SFT: A Reinforcement Learning Perspective with
  Reward Rectification, Yongliang Wu+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2700" target="_blank" rel="noopener noreferrer">[Paper Note] Towards a Unified View of Large Language Model Post-Training, Xingtai Lv+, arXiv'25</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="why-do-1860" class="title-link">Why do LLMs attend to the first token?, Federico Barbero+, COLM'25</h3><br><a href="https://arxiv.org/abs/2504.02732" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1860" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="AttentionSinks.html" target="_blank" rel="noopener noreferrer">#AttentionSinks</a>
<a class="button" href="COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-04-05</span>
<span class="snippet"><span>GPT Summary</span>- LLMsは最初のトークンに強く注意を向ける「アテンションシンク」を示し、そのメカニズムが過剰混合を避ける方法を理論的・実証的に探求。コンテキストの長さやデータのパッキングがシンクの挙動に与える影響を実験で示し、アテンションパターンの理解を深めることを目指す。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/omarsar0/status/1908187563422261411?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>Attention Sinkによって、トークンの情報がover-mixingされることが抑制され、Decoder-only LLMの深い層のrepresentationが均一化されることを抑制する（＝promptの摂動にロバストになる）ことが示された模様。<br><img src="https://github.com/user-attachments/assets/8a1223c0-5621-42a5-accc-31fa7f636856" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br>Gemma7Bにおいて、prompt中のトークン一語を置換した後に、Attention Sink（<bos>）の有無によって、tokenレベルのrepresentationに対してどのような摂動があるかをlayerごとにまとめた図が下記の模様。Attention Sinkによって、tokenの摂動が他のtoken, layerに対してmixingされるのが抑制されている。<br><img src="https://github.com/user-attachments/assets/b1a4038a-d116-4bd1-b27b-c55eb861bee9" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p><p>openreview:


<a href="https://openreview.net/forum?id=tu4dFUsW5z#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=tu4dFUsW5z#discussion</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="inside-out-hidden-1846" class="title-link">Inside-Out: Hidden Factual Knowledge in LLMs, Zorik Gekhman+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2503.15299" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1846" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="FactualKnowledge.html" target="_blank" rel="noopener noreferrer">#FactualKnowledge</a>
<span class="issue_date">Issue Date: 2025-04-01</span>
<span class="snippet"><span>GPT Summary</span>- 本研究は、LLMが出力以上の事実的知識をエンコードしているかを評価するフレームワークを提案。知識を定義し、正しい回答が高くランク付けされる割合を定量化。外部知識と内部知識を区別し、内部知識が外部知識を超えると隠れた知識が生じることを示す。クローズドブックQA設定でのケーススタディでは、LLMが内部で多くの知識をエンコードしていること、知識が隠れている場合があること、サンプリングによる制約があることを明らかにした。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/zorikgekhman/status/1906693729886363861?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="overtrained-language-1837" class="title-link">Overtrained Language Models Are Harder to Fine-Tune, Jacob Mitchell Springer+, ICLR'25</h3><br><a href="https://arxiv.org/abs/2503.19206" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1837" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Supervised-FineTuning-(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-03-27</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデルの事前学習において、トークン予算の増加がファインチューニングを難しくし、パフォーマンス低下を引き起こす「壊滅的な過学習」を提唱。3Tトークンで事前学習されたOLMo-1Bモデルは、2.3Tトークンのモデルに比べて2%以上の性能低下を示す。実験と理論分析により、事前学習パラメータの感度の増加が原因であることを示し、事前学習設計の再評価を促す。</span>
<span class="snippet"><span>Comment</span><p>著者によるポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/jacspringer/status/1904960783341023521?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>事前学習のトークン数を増やすとモデルのsensitivityが増し、post-trainingでのパフォーマンスの劣化が起こることを報告している。事前学習で学習するトークン数を増やせば、必ずしもpost-training後のモデルの性能がよくなるわけではないらしい。<br><img src="https://github.com/user-attachments/assets/ba60ae24-f3e5-4956-b29f-37b4fe01a9d1" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p><p>ICLR'25のOutstanding Paperに選ばれた模様:<br>



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/jacspringer/status/1917174452531724718?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><br>きちんと読んだ方が良さげ。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="all-roads-1806" class="title-link">All Roads Lead to Likelihood: The Value of Reinforcement Learning in  Fine-Tuning, Gokul Swamy+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2503.01067" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1806" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Supervised-FineTuning-(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<span class="issue_date">Issue Date: 2025-03-17</span>
<span class="snippet"><span>GPT Summary</span>- 基盤モデルのファインチューニングにおいて、報酬モデルを用いた二段階のトレーニング手順が効果的である理由を理論的および実証的に検討。特に、好みデータから単純な報酬モデルを学び、強化学習手続きがそのモデルに最適なポリシーをフィルタリングする能力が、オンラインファインチューニングの優れたパフォーマンスに寄与することが示された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/1901392286694678568?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>AlignmentのためのPreferenceデータがある時に、そのデータから直接最尤推定してモデルのパラメータを学習するのではなく、報酬モデルを学習して、その報酬モデルを用いてモデルを強化学習することで、なぜ前者よりも（同じデータ由来であるにもかかわらず）優れたパフォーマンスを示すのか、という疑問に対してアプローチしている。</p><p>全く中身を読めていないが、生成することと（方策モデル）と検証すること（報酬モデル）の間にギャップがある場合（すなわち、生成と検証で求められる能力が異なる場合）、MLEでは可能なすべてのポリシーを探索することと似たようなことをすることになるが、RLでは事前に報酬モデルを学習しその報酬モデルに対して最適なポリシーを探索するだけなので探索する空間が制限される（＝生成と検証のギャップが埋まる）ので、良い解に収束しやすくなる、というイメージなんだろうか。<br><img src="https://github.com/user-attachments/assets/121e97a6-120e-4830-9bcf-329129a687eb" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="scaling-test-time-1767" class="title-link">Scaling Test-Time Compute Without Verification or RL is Suboptimal, Amrith Setlur+, arXiv'25</h3><br><a href="https://arxiv.org/abs/2502.12118" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1767" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Supervised-FineTuning-(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<span class="issue_date">Issue Date: 2025-02-18</span>
<span class="snippet"><span>GPT Summary</span>- RLや探索に基づく検証者ベース（VB）手法が、探索の痕跡を蒸留する検証者フリー（VF）アプローチよりも優れていることを示す。テスト時の計算とトレーニングデータをスケールアップすると、VF手法の最適性が悪化し、VB手法がより良くスケールすることが確認された。3/8/32BサイズのLLMを用いた実験で、検証が計算能力の向上に重要であることを実証。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/iscienceluvr/status/1891839822257586310?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1749" target="_blank" rel="noopener noreferrer">s1: Simple test-time scaling, Niklas Muennighoff+, arXiv'25</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="demystifying-long-1746" class="title-link">[Paper Note] Demystifying Long Chain-of-Thought Reasoning in LLMs, Edward Yeo+, arXiv'25</h3><br><a href="https://arxiv.org/pdf/2502.03373" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1746" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Supervised-FineTuning-(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="RewardHacking.html" target="_blank" rel="noopener noreferrer">#RewardHacking</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-02-07</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、大規模言語モデル（LLMs）における長い思考の連鎖（CoTs）推論のメカニズムを調査し、重要な要因を特定。主な発見は、(1) 教師ありファインチューニング（SFT）は必須ではないが効率を向上させる、(2) 推論能力は計算の増加に伴い現れるが、報酬の形状がCoTの長さに影響、(3) 検証可能な報酬信号のスケーリングが重要で、特に分布外タスクに効果的、(4) エラー修正能力は基本モデルに存在するが、RLを通じて効果的に奨励するには多くの計算が必要。これらの洞察は、LLMsの長いCoT推論を強化するためのトレーニング戦略の最適化に役立つ。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/xiangyue96/status/1887332772198371514?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>元ポストのスレッド中に論文の11個の知見が述べられている。どれも非常に興味深い。DeepSeek-R1のテクニカルペーパーと同様、<br><br>- Long CoTとShort CoTを比較すると前者の方が到達可能な性能のupper bonudが高いことや、<br>- SFTを実施してからRLをすると性能が向上することや、<br>- RLの際にCoTのLengthに関する報酬を入れることでCoTの長さを抑えつつ性能向上できること、<br>- 数学だけでなくQAペアなどのノイジーだが検証可能なデータをVerifiableな報酬として加えると一般的なreasoningタスクで数学よりもさらに性能が向上すること、<br>- より長いcontext window sizeを活用可能なモデルの訓練にはより多くの学習データが必要なこと、<br>- long CoTはRLによって学習データに類似したデータが含まれているためベースモデルの段階でその能力が獲得されていることが示唆されること、<br>- aha momentはすでにベースモデル時点で獲得されておりVerifiableな報酬によるRLによって強化されたわけではなさそう、<br><br>など、興味深い知見が盛りだくさん。非常に興味深い研究。あとで読む。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="sft-memorizes-1740" class="title-link">SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model   Post-training, Tianzhe Chu+, ICML'25</h3><br><a href="https://arxiv.org/abs/2501.17161" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1740" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Supervised-FineTuning-(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-01-30</span>
<span class="snippet"><span>GPT Summary</span>- SFTとRLの一般化能力の違いを研究し、GeneralPointsとV-IRLを用いて評価。RLはルールベースのテキストと視覚変種に対して優れた一般化を示す一方、SFTは訓練データを記憶し分布外シナリオに苦労。RLは視覚認識能力を向上させるが、SFTはRL訓練に不可欠であり、出力形式を安定させることで性能向上を促進。これらの結果は、複雑なマルチモーダルタスクにおけるRLの一般化能力を示す。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/1884731381517082668?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>openreview:


<a href="https://openreview.net/forum?id=dYur3yabMj&referrer=%5Bthe%20profile%20of%20Yi%20Ma%5D(%2Fprofile%3Fid%3D~Yi_Ma4)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=dYur3yabMj&referrer=%5Bthe%20profile%20of%20Yi%20Ma%5D(%2Fprofile%3Fid%3D~Yi_Ma4)</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="physics-of-1286" class="title-link">[Paper Note] Physics of Language Models: Part 3.3, Knowledge Capacity Scaling Laws, Zeyuan Allen-Zhu+, N_A, ICLR'25</h3><br><a href="https://arxiv.org/abs/2404.05405" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1286" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2024-04-15</span>
<span class="snippet"><span>GPT Summary</span>- 言語モデルのサイズと能力の関係を記述するスケーリング則に焦点を当てた研究。モデルが格納する知識ビット数を推定し、事実知識をタプルで表現。言語モデルは1つのパラメータあたり2ビットの知識を格納可能であり、7Bモデルは14Bビットの知識を格納可能。さらに、トレーニング期間、モデルアーキテクチャ、量子化、疎な制約、データの信号対雑音比が知識格納容量に影響することを示唆。ロータリー埋め込みを使用したGPT-2アーキテクチャは、知識の格納においてLLaMA/Mistralアーキテクチャと競合する可能性があり、トレーニングデータにドメイン名を追加すると知識容量が増加することが示された。</span>
<span class="snippet"><span>Comment</span><p>参考:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/1779640139263901698?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>解説:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1834" target="_blank" rel="noopener noreferrer">言語モデルの物理学, 佐藤竜馬, 2025.03</a>
</p><p>openreview:


<a href="https://openreview.net/forum?id=FxNNiUgtfa" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=FxNNiUgtfa</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="quantifying-language-4252" class="title-link">[Paper Note] Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting, Melanie Sclar+, ICLR'24, 2023.10</h3><br><a href="https://arxiv.org/abs/2310.11324" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4252" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2026-01-21</span>
<span class="snippet"><span>GPT Summary</span>- LLMの性能特性化が重要であり、プロンプト設計がモデル挙動に強く影響することを示す。特に、プロンプトフォーマットに対するLLMの感度に注目し、微妙な変更で最大76ポイントの性能差が見られる。感度はモデルサイズや少数ショットの数に依存せず、プロンプトの多様なフォーマットにわたる性能範囲の報告が必要。モデル間のフォーマットパフォーマンスが弱く相関することから、固定されたプロンプトフォーマットでの比較の妥当性が疑問視される。迅速なフォーマット評価のための「FormatSpread」アルゴリズムを提案し、摂動の影響や内部表現も探る。</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=RIu5lyNXjT" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=RIu5lyNXjT</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="when-does-3480" class="title-link">[Paper Note] WHEN DOES SECOND-ORDER OPTIMIZATION SPEED UP TRAINING?, Ishikawa+, ICLR'24 Tiny Paper</h3><br><a href="https://openreview.net/forum?id=NLrfEsSZNb&noteId=NLrfEsSZNb" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3480" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<span class="issue_date">Issue Date: 2025-10-28</span>
<span class="snippet"><span>GPT Summary</span>- 二次最適化手法の使用が限られている理由を探り、特にバッチサイズとデータセットサイズに基づく条件を特定。実証的に、大きなバッチサイズと小さなデータセットサイズの組み合わせで二次最適化が一次最適化を上回ることを発見。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/seunghyunseo7/status/1983091615280627998?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="many-shot-in-context-3467" class="title-link">[Paper Note] Many-Shot In-Context Learning in Multimodal Foundation Models, Yixing Jiang+, arXiv'24, 2024.05</h3><br><a href="https://arxiv.org/abs/2405.09798" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3467" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Zero-Few-ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<a class="button" href="MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-10-27</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、マルチモーダル基盤モデルの少数ショットから多数ショットのインコンテキスト学習（ICL）の性能を評価し、2,000のデモンストレーション例を用いることで、すべてのデータセットにおいて大幅な改善を観察しました。特に、Gemini 1.5 Proは多くのデータセットで対数的に性能が向上し、オープンウェイトモデルはデモンストレーション例からの恩恵を受けないことが明らかになりました。また、複数のクエリをバッチ処理することで、ゼロショットおよび多数ショットICLの性能が向上し、コストとレイテンシが削減されました。最終的に、GPT-4oとGemini 1.5 Proは類似のゼロショット性能を示しつつ、Gemini 1.5 Proはより早く学習することが確認されました。多数ショットICLは新しいアプリケーションへの適応を効率化する可能性を示唆しています。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/marchoelle/status/1982589731260203110?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="shadows-don't-3409" class="title-link">[Paper Note] Shadows Don't Lie and Lines Can't Bend Generative Models don't know  Projective Geometry...for now, Ayush Sarkar+, CVPR'24, 2023.11</h3><br><a href="https://arxiv.org/abs/2311.17138" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3409" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="TextToImageGeneration.html" target="_blank" rel="noopener noreferrer">#TextToImageGeneration</a>
<a class="button" href="CVPR.html" target="_blank" rel="noopener noreferrer">#CVPR</a>
<a class="button" href="ImageSynthesis.html" target="_blank" rel="noopener noreferrer">#ImageSynthesis</a>
<a class="button" href="GeometryUnderstanding.html" target="_blank" rel="noopener noreferrer">#GeometryUnderstanding</a>
<span class="issue_date">Issue Date: 2025-10-24</span>
<span class="snippet"><span>GPT Summary</span>- 生成モデルはリアルな画像を生成するが、幾何学的特徴において実際の画像と異なることを示す。事前に選別された生成画像を用いて、幾何学的特性に基づく分類器が生成画像を高精度で識別できることを確認。3つの分類器を使用し、画像の透視場、線、物体と影の関係を分析。これにより、生成画像の検出精度が向上し、現在の生成器は実際の画像の幾何学的特性を再現できないと結論付ける。</span>
<span class="snippet"><span>Comment</span><p>pj page: 


<a href="https://projective-geometry.github.io/" target="_blank" rel="noopener noreferrer">https://projective-geometry.github.io/</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="same-task-3063" class="title-link">[Paper Note] Same Task, More Tokens: the Impact of Input Length on the Reasoning  Performance of Large Language Models, Mosh Levy+, ACL'24, 2024.02</h3><br><a href="https://arxiv.org/abs/2402.14848" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3063" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="Length.html" target="_blank" rel="noopener noreferrer">#Length</a>
<span class="issue_date">Issue Date: 2025-10-02</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、入力長の拡張が大規模言語モデル（LLMs）の性能に与える影響を評価する新しいQA推論フレームワークを提案。異なる長さやタイプのパディングを用いて、LLMsの推論性能が短い入力長で著しく低下することを示した。さらに、次の単語予測がLLMsの性能と負の相関を持つことを明らかにし、LLMsの限界に対処するための戦略を示唆する失敗モードを特定した。</span>
</article>
<article class="paper-entry">
<h3 id="the-impact-2978" class="title-link">[Paper Note] The Impact of Initialization on LoRA Finetuning Dynamics, Soufiane Hayou+, NeurIPS'24, 2024.06</h3><br><a href="https://arxiv.org/abs/2406.08447" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2978" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="PEFT(Adaptor-LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-09-25</span>
<span class="snippet"><span>GPT Summary</span>- 本論文では、LoRAにおける初期化の役割を研究し、Bをゼロに初期化しAをランダムに初期化する方式が他の方式よりも優れたパフォーマンスを示すことを明らかにします。この初期化方式は、より大きな学習率を使用できるため、効率的な学習を促進する可能性があります。LLMsに関する実験を通じて結果を検証します。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/jxmnop/status/1970893830619894186?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>初期化でBをzeroにするという手法は以下でも提案されているが、本研究の方が下記研究よりも投稿が1年程度早い:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2194" target="_blank" rel="noopener noreferrer">[Paper Note] SingLoRA: Low Rank Adaptation Using a Single Matrix, David Bensaïd+, arXiv'25</a>
</p><p>openreview:


<a href="https://openreview.net/forum?id=sn3UrYRItk&referrer=%5Bthe%20profile%20of%20Nikhil%20Ghosh%5D(%2Fprofile%3Fid%3D~Nikhil_Ghosh1)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=sn3UrYRItk&referrer=%5Bthe%20profile%20of%20Nikhil%20Ghosh%5D(%2Fprofile%3Fid%3D~Nikhil_Ghosh1)</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="lessons-from-2777" class="title-link">[Paper Note] Lessons from Studying Two-Hop Latent Reasoning, Mikita Balesni+, arXiv'24</h3><br><a href="https://arxiv.org/abs/2411.16353" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2777" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-12</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデル（LLM）の二段階質問応答能力を調査し、思考の連鎖（CoT）の重要性を示す。合成事実を用いた実験で、モデルは二つの合成事実を組み合わせるのに失敗するが、自然な事実との組み合わせでは成功することが確認された。これにより、LLMは潜在的な二段階推論能力を持つが、その能力のスケーリングには不明点が残る。研究者は、LLMの推論能力を評価する際に、ショートカットによる虚偽の成功や失敗に注意する必要があることを強調。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/balesni/status/1966197584499999036?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>下記研究ではエンティティが国の場合は2 step推論ができるという例外が生じており、事前学習のフィルタリングで何か見落としがあるかもしれない可能性があり:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1564" target="_blank" rel="noopener noreferrer">Do Large Language Models Perform Latent Multi-Hop Reasoning without   Exploiting Shortcuts?, Sohee Yang+, ACL'24</a>
<br><br>下記研究において、完全にmemorizationzが生じない形で事前学習とInference実施（train: John Doe lives in **Tokyo**., Test: The people in the city John Doe is from speak **Japanese**.)されたが、エンティティがcityの場合でしか試されておらず、他のエンティティでも汎化するのか？という疑問があった:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2778" target="_blank" rel="noopener noreferrer">[Paper Note] Extractive Structures Learned in Pretraining Enable Generalization on   Finetuned Facts, Jiahai Feng+, ICML'25</a>
<br><br>本研究では17種類の他のエンティティでも2 hop reasoningがlatentに実施されていることを確認した。しかし、一つ不思議な点として当初2つの架空の事実をLLMに教えるような学習を試みた場合は。Acc.が0%で、lossも偶然に生じる程度のものであった。これを深掘りすると、<br>- 合成+本物の事実→うまくいく<br>- 合成+合成→失敗<br>- 同一訓練/incontext文書内の合成された事実→うまくいく<br>という現象が観測され、このことより<br>- 実世界のプロンプトでの成功は、latent reasoningがロバストに実施されていることを示すわけではなく（事前学習時の同一文書内の共起を反映しているだけの可能性がある）<br>- 合成データでの2 hop推論の失敗は、latent reasoningの能力を否定するものではない（合成された事実は実世界での自然な事実とは異なるためうまくいっていない可能性がある）<br><br>という教訓が得られた、といった話が元ポストに書かれている。<br><br>なぜ完全に合成された事実情報では失敗するのだろうか。元論文を読んで事前学習データとしてどのようなものが利用されているかを確認する必要がある。</p><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/feng_jiahai/status/1869019495299444830?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="scaling-exponents-2623" class="title-link">[Paper Note] Scaling Exponents Across Parameterizations and Optimizers, Katie Everett+, ICML'24</h3><br><a href="https://arxiv.org/abs/2407.05872" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2623" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<a class="button" href="ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="ZeroshotHyperparameterTransfer.html" target="_blank" rel="noopener noreferrer">#ZeroshotHyperparameterTransfer</a>
<a class="button" href="LearningRate.html" target="_blank" rel="noopener noreferrer">#LearningRate</a>
<span class="issue_date">Issue Date: 2025-08-31</span>
<span class="snippet"><span>GPT Summary</span>- モデルのスケーリングには、パラメータ化やオプティマイザの選択が重要である。本研究では、パラメータとデータの整合性に関する新しい視点を提案し、広範なオプティマイザと学習率の組み合わせで数万のモデルを訓練した結果、最適な学習率スケーリングが重要であることを発見。新しい層ごとの学習率の処方は従来の方法を上回る性能を示し、Adamのイプシロンパラメータの適切なスケーリングが必要であることを明らかにし、数値的に安定した新しいAdamバージョンであるAdam-atan2を提案した。</span>
</article>
<article class="paper-entry">
<h3 id="as-generative-2546" class="title-link">[Paper Note] As Generative Models Improve, People Adapt Their Prompts, Eaman Jahani+, arXiv'24</h3><br><a href="https://arxiv.org/abs/2407.14333v2" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2546" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2025-08-25</span>
<span class="snippet"><span>GPT Summary</span>- オンライン実験で1893人の参加者を対象に、DALL-E 2とDALL-E 3のプロンプトの重要性の変化を調査。DALL-E 3を使用した参加者は、DALL-E 2よりも高いパフォーマンスを示し、これは技術的能力の向上とプロンプトの質の変化によるもの。特に、DALL-E 3の参加者はより長く、意味的に類似したプロンプトを作成。プロンプト修正機能を持つDALL-E 3はさらに高いパフォーマンスを示したが、その利点は減少。結果として、モデルの進化に伴い、プロンプトも適応されることが示唆される。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/dair_ai/status/1959644116305748388?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="mambaout-do-2420" class="title-link">[Paper Note] MambaOut: Do We Really Need Mamba for Vision?, Weihao Yu+, arXiv'24</h3><br><a href="https://arxiv.org/abs/2405.07992" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2420" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="ImageSegmentation.html" target="_blank" rel="noopener noreferrer">#ImageSegmentation</a>
<a class="button" href="SSM-(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<a class="button" href="ImageClassification.html" target="_blank" rel="noopener noreferrer">#ImageClassification</a>
<span class="issue_date">Issue Date: 2025-08-14</span>
<span class="snippet"><span>GPT Summary</span>- MambaはRNNのようなトークンミキサーを持つアーキテクチャで、視覚タスクにおいて期待外れの性能を示す。Mambaは長いシーケンスと自己回帰的な特性に適しているが、画像分類には不向きであると仮定。MambaOutモデルを構築し、実験によりMambaOutがImageNetの画像分類で視覚Mambaモデルを上回ることを示し、検出およびセグメンテーションタスクではMambaの可能性を探る価値があることを確認。</span>
</article>
<article class="paper-entry">
<h3 id="scaling-laws-2262" class="title-link">[Paper Note] Scaling Laws for Data Filtering -- Data Curation cannot be Compute   Agnostic, Sachin Goyal+, CVPR'24</h3><br><a href="https://arxiv.org/abs/2404.07177" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2262" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="CVPR.html" target="_blank" rel="noopener noreferrer">#CVPR</a>
<a class="button" href="Scaling-Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="DataFiltering.html" target="_blank" rel="noopener noreferrer">#DataFiltering</a>
<span class="issue_date">Issue Date: 2025-07-20</span>
<span class="snippet"><span>GPT Summary</span>- 視覚と言語のモデル（VLMs）のトレーニングにおいて、高品質なデータのフィルタリングが重要であるが、計算リソースとは無関係に行われることが多い。本研究では、データの品質と量のトレードオフ（QQT）に対処するため、ウェブデータの非均質性を考慮したニューラルスケーリング法則を提案。これにより、データの有用性の違いや繰り返し使用による劣化を評価し、複数のデータプールの組み合わせによるモデルのパフォーマンスを推定可能にする。最適なデータプールのキュレーションを通じて、計算リソースに応じた最高のパフォーマンスを達成できることを示した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/cloneofsimo/status/1946241642572448174?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>高品質なデータにフィルタリングすることで多くの研究がモデルがより高い性能を達成できることを示しているが、高品質なデータには限りがあることと、繰り返し学習をすることですぐにその効用が低下する（Quality-Quantity tradeoff!)という特性がある。このような状況において、たとえば計算の予算がデータ6パケット分の時に、めちゃめちゃフィルタリングを頑張っg高品質なデータプールEのみを使って6 epoch学習するのが良いのか、少し品質は落ちるデータDも混ぜてE+Dを3 epoch学習するのが良いのか、ときにどちらが良いのか？という話のようである。<br><img src="https://github.com/user-attachments/assets/06812781-7212-415e-bc7a-dd19ac4ca0d7" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="preference-fine-tuning-2090" class="title-link">[Paper Note] Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy   Data, Fahim Tajwar+, ICML'24</h3><br><a href="https://arxiv.org/abs/2404.14367" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2090" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="PPO-(ProximalPolicyOptimization).html" target="_blank" rel="noopener noreferrer">#PPO (ProximalPolicyOptimization)</a>
<a class="button" href="ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<span class="snippet"><span>GPT Summary</span>- 好みのラベルを用いた大規模言語モデルのファインチューニングに関する研究。オンポリシー強化学習や対照学習などの手法を比較し、オンポリシーサンプリングや負の勾配を用いるアプローチが優れていることを発見。これにより、カテゴリ分布の特定のビンにおける確率質量を迅速に変更できるモード探索目的の重要性を示し、データ収集の最適化に関する洞察を提供。</span>
<span class="snippet"><span>Comment</span><p>以下のオフライン vs. オンラインRLアルゴリズムで本研究が引用されている:<br>



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/cwolferesearch/status/1965088925510520853?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="a-comparative-2051" class="title-link">[Paper Note] A Comparative Study of PDF Parsing Tools Across Diverse Document  Categories, Narayan S. Adhikari+, arXiv'24</h3><br><a href="https://arxiv.org/abs/2410.09871" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2051" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2025-06-18</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、DocLayNetデータセットを用いて10の人気PDFパースツールを6つの文書カテゴリにわたり比較し、情報抽出の効果を評価しました。テキスト抽出ではPyMuPDFとpypdfiumが優れた結果を示し、特に科学文書や特許文書ではNougatが高いパフォーマンスを発揮しました。表検出ではTATRが金融や法律文書で優れた結果を示し、Camelotは入札文書で最も良いパフォーマンスを発揮しました。これにより、文書タイプに応じた適切なパースツールの選択が重要であることが示されました。</span>
<span class="snippet"><span>Comment</span><p>PDFのparsingツールについて、text, table抽出の性能を様々なツールと分野別に評価している。<br><br>F1, precision, recallなどは、ground truthとのレーベンシュタイン距離からsimilarityを計算し、0.7以上であればtrue positiveとみなすことで計算している模様。local alignmentは、マッチした場合に加点、ミスマッチ、未検出の場合にペナルティを課すようなスコアリングによって抽出したテキスト全体の抽出性能を測る指標な模様。<br><img src="https://github.com/user-attachments/assets/2d2e114f-cc47-4d7d-906a-c505c793d675" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><br><img src="https://github.com/user-attachments/assets/ccc79865-83d3-47b6-bb47-f2c0a28990c7" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p><p>より性能を高くしたければこちらも参考に:<br>



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/jerryjliu0/status/1934988910448492570?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="physics-of-1929" class="title-link">[Paper Note] Physics of Language Models: Part 4.1, Architecture Design and the Magic of Canon Layers, Zeyuan Allen-Zhu+, ICML'24 Tutorial</h3><br><a href="https://physics.allen-zhu.com/part-4-architecture-design/part-4-1" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1929" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-05-06</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/1919878625488449849?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>Canon層の発見</p><p>著者による解説:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/zeyuanallenzhu/status/1918684257058197922?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="physics-of-1923" class="title-link">[Paper Note] Physics of Language Models: Part 3.1, Knowledge Storage and Extraction, Zeyuan Allen-Zhu+, ICML'24</h3><br><a href="https://arxiv.org/abs/2309.14316" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1923" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-05-03</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデル（LLMs）の知識抽出能力は、訓練データの多様性と強く相関しており、十分な強化がなければ知識は記憶されても抽出可能ではないことが示された。具体的には、エンティティ名の隠れ埋め込みに知識がエンコードされているか、他のトークン埋め込みに分散しているかを調査。LLMのプレトレーニングに関する重要な推奨事項として、補助モデルを用いたデータ再構成と指示微調整データの早期取り入れが提案された。</span>
<span class="snippet"><span>Comment</span><p>解説:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1834" target="_blank" rel="noopener noreferrer">言語モデルの物理学, 佐藤竜馬, 2025.03</a>
</p><p>SNLP'24での解説スライド:<br>


<a href="https://speakerdeck.com/sosk/physics-of-language-models-part-3-1-knowledge-storage-and-extraction" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/sosk/physics-of-language-models-part-3-1-knowledge-storage-and-extraction</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="revisiting-bpr-1879" class="title-link">[Paper Note] Revisiting BPR: A Replicability Study of a Common Recommender System   Baseline, Aleksandr Milogradskii+, RecSys'24</h3><br><a href="https://arxiv.org/pdf/2409.14217" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1879" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="RecSys.html" target="_blank" rel="noopener noreferrer">#RecSys</a>
<span class="issue_date">Issue Date: 2025-04-10</span>
<span class="snippet"><span>GPT Summary</span>- BPRは協調フィルタリングのベンチマークだが、実装の微妙な点が見落とされ、他手法に劣るとされている。本研究ではBPRの特徴と実装の不一致を分析し、最大50%の性能低下を示す。適切なハイパーパラメータ調整により、BPRはトップn推薦タスクで最先端手法に近い性能を達成し、Million Song DatasetではMult-VAEを10%上回る結果を示した。</span>
<span class="snippet"><span>Comment</span><p>BPR、実装によってまるで性能が違う…<br><img src="https://github.com/user-attachments/assets/916df15b-53e6-4589-ab64-ef113a79314a" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><br>実装の違い<br><img src="https://github.com/user-attachments/assets/42206524-c863-478d-99c0-7b605fef2da7" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="sparse-autoencoders-1802" class="title-link">[Paper Note] Sparse Autoencoders Find Highly Interpretable Features in Language   Models, Hoagy Cunningham+, ICLR'24</h3><br><a href="https://arxiv.org/abs/2309.08600" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1802" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="KeyPoint-Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="SparseAutoEncoder.html" target="_blank" rel="noopener noreferrer">#SparseAutoEncoder</a>
<a class="button" href="Interpretability.html" target="_blank" rel="noopener noreferrer">#Interpretability</a>
<a class="button" href="InterpretabilityScore.html" target="_blank" rel="noopener noreferrer">#InterpretabilityScore</a>
<span class="issue_date">Issue Date: 2025-03-15</span>
<span class="snippet"><span>GPT Summary</span>- 神経ネットワークの多義性を解消するために、スパースオートエンコーダを用いて内部活性化の方向を特定。これにより、解釈可能で単義的な特徴を学習し、間接目的語の同定タスクにおける因果的特徴をより詳細に特定。スケーラブルで教師なしのアプローチが重ね合わせの問題を解決できることを示唆し、モデルの透明性と操作性向上に寄与する可能性を示す。</span>
<span class="snippet"><span>Comment</span><p>日本語解説:


<a href="https://note.com/ainest/n/nbe58b36bb2db" target="_blank" rel="noopener noreferrer">https://note.com/ainest/n/nbe58b36bb2db</a>


</p><p>OpenReview:


<a href="https://openreview.net/forum?id=F76bwRSLeK" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=F76bwRSLeK</a>


</p><p>SparseAutoEncoderはネットワークのあらゆるところに仕込める（と思われる）が、たとえばTransformer Blockのresidual connection部分のベクトルに対してFeature Dictionaryを学習すると、当該ブロックにおいてどのような特徴の組み合わせが表現されているかが（あくまでSparseAutoEncoderがreconstruction lossによって学習された結果を用いて）解釈できるようになる。<br><img src="https://github.com/user-attachments/assets/f86f5f7b-f46d-48ab-94e3-cf7f298eb9d7" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><br>SparseAutoEncoderは下記式で表され、下記loss functionで学習される。MがFeature Matrix（row-wiseに正規化されて後述のcに対するL1正則化に影響を与えないようにしている）に相当する。cに対してL1正則化をかけることで（Sparsity Loss）、c中の各要素が0に近づくようになり、結果としてcがSparseとなる（どうしても値を持たなければいけない重要な特徴量のみにフォーカスされるようになる）。<br><img src="https://github.com/user-attachments/assets/7e400f25-8a63-4222-904c-4a7b94d50880" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><img src="https://github.com/user-attachments/assets/dd8c10b3-3bb5-46fb-b94a-d91f3602bbd1" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="a-deep-1711" class="title-link">[Paper Note] A Deep Dive into the Trade-Offs of Parameter-Efficient Preference   Alignment Techniques, Megh Thakkar+, ACL'24, 2024.06</h3><br><a href="https://arxiv.org/abs/2406.04879" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1711" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="DownstreamTasks.html" target="_blank" rel="noopener noreferrer">#DownstreamTasks</a>
<span class="issue_date">Issue Date: 2025-01-06</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデルの整列に関する研究で、整列データセット、整列技術、モデルの3つの要因が下流パフォーマンスに与える影響を300以上の実験を通じて調査。情報量の多いデータが整列に寄与することや、監視付きファインチューニングが最適化を上回るケースを発見。研究者向けに効果的なパラメータ効率の良いLLM整列のガイドラインを提案。</span>
</article>
<article class="paper-entry">
<h3 id="are-emergent-1707" class="title-link">Are Emergent Abilities in Large Language Models just In-Context   Learning?, Sheng Lu+, ACL'24</h3><br><a href="https://arxiv.org/abs/2309.01809" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1707" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="Memorization.html" target="_blank" rel="noopener noreferrer">#Memorization</a>
<a class="button" href="EmergentAbilities.html" target="_blank" rel="noopener noreferrer">#EmergentAbilities</a>
<span class="issue_date">Issue Date: 2025-01-06</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデルの「出現能力」は、インコンテキスト学習やモデルの記憶、言語知識の組み合わせから生じるものであり、真の出現ではないと提案。1000以上の実験を通じてこの理論を裏付け、言語モデルの性能を理解するための基礎を提供し、能力の過大評価を警告。</span>
</article>
<article class="paper-entry">
<h3 id="does-rlhf-1650" class="title-link">Does RLHF Scale? Exploring the Impacts From Data, Model, and Method, Zhenyu Hou+, arXiv'24</h3><br><a href="https://arxiv.org/abs/2412.06000" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1650" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<span class="issue_date">Issue Date: 2025-01-03</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、LLMsにおけるRLHFのスケーリング特性を分析し、モデルサイズ、データ構成、推論予算がパフォーマンスに与える影響を調査。データの多様性と量の増加が報酬モデルの性能向上に寄与する一方、ポリシートレーニングでは応答サンプル数の増加が初期パフォーマンスを向上させるが、すぐに頭打ちになることが判明。RLHFは事前トレーニングより効率的にスケールせず、計算リソースの収益逓減が観察された。計算制限内でのRLHFパフォーマンス最適化戦略も提案。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/dair_ai/status/1868299930600628451?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="how-much-1641" class="title-link">How Much Data is Enough Data? Fine-Tuning Large Language Models for  In-House Translation: Performance Evaluation Across Multiple Dataset Sizes, Inacio Vieira+, AMTA'24</h3><br><a href="https://arxiv.org/abs/2409.03454" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1641" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Supervised-FineTuning-(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="PEFT(Adaptor-LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<span class="issue_date">Issue Date: 2025-01-02</span>
<span class="snippet"><span>GPT Summary</span>- LLMsのファインチューニングに翻訳メモリ（TMs）を活用し、特定の組織向けの翻訳精度と効率を向上させる研究。5つの翻訳方向で異なるサイズのデータセットを用いて実験し、トレーニングデータが増えるほど翻訳パフォーマンスが向上することを確認。特に、1kおよび2kの例ではパフォーマンスが低下するが、データセットのサイズが増加するにつれて改善が見られる。LLMsとTMsの統合により、企業特有のニーズに応じたカスタマイズ翻訳モデルの可能性を示唆。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/gyakuse/status/1874357127248306200?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>QLoRAでLlama 8B InstructをMTのデータでSFTした場合のサンプル数に対する性能の変化を検証している。ただし、検証しているタスクはMT、QLoRAでSFTを実施しrankは64、学習時のプロンプトは非常にシンプルなものであるなど、幅広い設定で学習しているわけではないので、ここで得られた知見が幅広く適用可能なことは示されていないであろう点、には注意が必要だと思われる。<br><br>この設定では、SFTで利用するサンプル数が増えれば増えるほど性能が上がっているように見える。<br><br><img src="https://github.com/user-attachments/assets/71309a00-85fd-491f-a89e-c9cb99f4da6c" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><img src="https://github.com/user-attachments/assets/ea1eba38-9488-43e5-a64b-f997bf65f57b" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><img src="https://github.com/user-attachments/assets/21b21628-d589-4214-8860-680e392a2556" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="the-broader-1590" class="title-link">The broader spectrum of in-context learning, Andrew Kyle Lampinen+, arXiv'24</h3><br><a href="https://arxiv.org/abs/2412.03782" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1590" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2024-12-15</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、言語モデルの少数ショット学習をメタ学習に基づく文脈内学習の一部として位置づけ、文脈が予測の損失を減少させるメカニズムを提案します。この視点は、言語モデルの文脈内能力を統一し、一般化の重要性を強調します。一般化は新しい学習だけでなく、異なる提示からの学びや適用能力にも関連し、過去の文献との関連性も議論されます。文脈内学習の研究は、広範な能力と一般化のタイプを考慮すべきと結論付けています。</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=RHo3VVi0i5" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=RHo3VVi0i5</a>


<br><br>OpenReviewによると、<br>論文は理解しやすく、meta learningについて広範にサーベイされている。しかし、論文が定義しているICLの拡張はICLを過度に一般化し過ぎており（具体的に何がICLで何がICLでないのか、といった規定ができない）、かつ論文中で提案されているコンセプトを裏付ける実験がなくspeculativeである、とのことでrejectされている。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="the-super-1566" class="title-link">The Super Weight in Large Language Models, Mengxia Yu+, arXiv'24</h3><br><a href="https://arxiv.org/abs/2411.07191" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1566" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<span class="issue_date">Issue Date: 2024-12-02</span>
<span class="snippet"><span>GPT Summary</span>- LLMのパラメータの一部がモデルの品質に不均衡に重要であり、1つのパラメータの剪定でテキスト生成能力が大幅に低下することを発見。データフリーの方法で重要なスーパーパラメータを特定し、これにより四捨五入量子化の精度を向上させることができる。スーパーパラメータに関する研究を促進するために、オープンアクセスのLLMに対するインデックスを提供。</span>
<span class="snippet"><span>Comment</span><p>図にある通り、たった一つのニューラルネットワーク中の重みを0にするだけで、途端に意味のあるテキストが生成できなくなるような重みが存在するらしい。<br><img src="https://github.com/user-attachments/assets/065e921b-c447-4c0d-b1de-a2f79bd090f8" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><br><br>（図は論文より引用）</p><p>ICLR 2025のOpenreview<br>


<a href="https://openreview.net/forum?id=0Ag8FQ5Rr3" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=0Ag8FQ5Rr3</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="does-prompt-1549" class="title-link">Does Prompt Formatting Have Any Impact on LLM Performance?, Jia He+, arXiv'24</h3><br><a href="https://arxiv.org/abs/2411.10541" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1549" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2024-11-27</span>
<span class="snippet"><span>GPT Summary</span>- プロンプト最適化はLLMの性能に重要であり、異なるプロンプトテンプレートがモデルの性能に与える影響を調査。実験では、GPT-3.5-turboがプロンプトテンプレートによってコード翻訳タスクで最大40%変動する一方、GPT-4はより堅牢であることが示された。これにより、固定プロンプトテンプレートの再考が必要であることが強調された。</span>
<span class="snippet"><span>Comment</span><p>（以下、個人の感想です）<br>本文のみ斜め読みして、Appendixは眺めただけなので的外れなことを言っていたらすみません。<br><br>まず、実務上下記知見は有用だと思いました:<br>- プロンプトのフォーマットによって性能に大きな差がある<br>- より大きいモデルの方がプロンプトフォーマットに対してロバスト<br><br>ただし、フォーマットによって性能差があるというのは経験的にある程度LLMを触っている人なら分かることだと思うので、驚きは少なかった。<br><br>個人的に気になる点は、学習データもモデルのアーキテクチャもパラメータ数も分からないGPT3.5, GPT4のみで実験をして「パラメータサイズが大きい方がロバスト」と結論づけている点と、もう少し深掘りして考察したらもっとおもしろいのにな、と感じる点です。<br><br>実務上は有益な知見だとして、では研究として見たときに「なぜそうなるのか?」というところを追求して欲しいなぁ、という感想を持ちました。<br>たとえば、「パラメータサイズが大きいモデルの方がフォーマットにロバスト」と論文中に書かれているように見えますが、<br>それは本当にパラメータサイズによるものなのか？学習データに含まれる各フォーマットの割合とか（これは事実はOpenAIの中の人しか分からないので、学習データの情報がある程度オープンになっているOpenLLMでも検証するとか）、評価するタスクとフォーマットの相性とか、色々と考察できる要素があるのではないかと思いました。<br>その上で、大部分のLLMで普遍的な知見を見出した方が研究としてより面白くなるのではないか、と感じました。<br><br><img src="https://github.com/user-attachments/assets/d0a6c727-1253-4503-93f2-8daa4db2321b" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><img src="https://github.com/user-attachments/assets/b7166b2b-b848-43f5-a823-7ed491232234" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p><p>参考: Data2Textにおける数値データのinput formatによる性能差を分析し考察している研究<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1267" target="_blank" rel="noopener noreferrer">Prompting for Numerical Sequences: A Case Study on Market Comment
  Generation, Masayuki Kawarada+, N/A, arXiv'24</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="observational-scaling-1540" class="title-link">Observational Scaling Laws and the Predictability of Language Model  Performance, Yangjun Ruan+, arXiv'24</h3><br><a href="https://arxiv.org/abs/2405.10938" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1540" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2024-11-22</span>
<span class="snippet"><span>GPT Summary</span>- 言語モデルの性能を理解するために、約100の公開モデルからスケーリング法則を構築する新しい観察アプローチを提案。モデルファミリー間の能力変動を考慮し、性能が低次元の能力空間の関数であることを示す。これにより、複雑なスケーリング現象の予測可能性を示し、GPT-4のエージェント性能を非エージェント的ベンチマークから予測できることを明らかにし、Chain-of-ThoughtやSelf-Consistencyの影響を予測する方法を示す。</span>
<span class="snippet"><span>Comment</span><p>縦軸がdownstreamタスクの主成分（のうち最も大きい80%を説明する成分）の変化（≒LLMの性能）で、横軸がlog scaleの投入計算量。<br>Qwenも頑張っているが、投入データ量に対する性能（≒データの品質）では、先駆け的な研究であるPhiがやはり圧倒的?<br><img src="https://github.com/user-attachments/assets/c38286df-37c1-4c72-832f-676832845c0e" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/766" target="_blank" rel="noopener noreferrer">Textbooks Are All You Need, Suriya Gunasekar+, N/A, arXiv'23</a>
<br><br>も参照のこと</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="likelihood-as-1530" class="title-link">Likelihood as a Performance Gauge for Retrieval-Augmented Generation, Tianyu Liu+, arXiv'24</h3><br><a href="https://arxiv.org/pdf/2411.07773" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1530" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2024-11-19</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデルを用いた情報検索強化生成は、文脈内の文書の順序に影響を受けやすい。研究では、質問の確率がモデルのパフォーマンスに与える影響を分析し、正確性との相関関係を明らかにした。質問の確率を指標として、プロンプトの選択と構築に関する2つの方法を提案し、その効果を実証。確率に基づく手法は効率的で、少ないモデルのパスで応答を生成できるため、プロンプト最適化の新たな方向性を示す。</span>
<span class="snippet"><span>Comment</span><p>トークンレベルの平均値をとった生成テキストの対数尤度と、RAGの回答性能に関する分析をした模様。<br><img src="https://github.com/user-attachments/assets/ac03c0b6-b16c-4992-8446-2f56bad09ab2" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><br>とりあえず、もし「LLMとしてGPTを（OpenAIのAPIを用いて）使いました！temperatureは0です！」みたいな実験設定だったら諸々怪しくなる気がしたのでそこが大丈夫なことを確認した（OpenLLM、かつdeterministicなデコーディング方法が望ましい）。おもしろそう。<br><br><img src="https://github.com/user-attachments/assets/9ba2bdc7-f6e5-4b9c-aca4-3d461c78a046" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p><p>参考: [RAGのハルシネーションを尤度で防ぐ, sasakuna, 2024.11.19](


<a href="https://zenn.dev/knowledgesense/articles/7c47e1796e96c0)" target="_blank" rel="noopener noreferrer">https://zenn.dev/knowledgesense/articles/7c47e1796e96c0)</a>


</p><p>
<strong>## 参考<br><br>生成されたテキストの尤度を用いて、どの程度正解らしいかを判断する、といった話は<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1223" target="_blank" rel="noopener noreferrer">[Paper Note] G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment, Yang Liu+, N/A, EMNLP'23</a>
</strong>
<br>
<br><br>のようなLLM-as-a-Judgeでも行われている。<br><br>G-Evalでは1--5のスコアのような離散的な値を生成する際に、これらを連続的なスコアに補正するために、尤度（トークンの生成確率）を用いている。<br>ただし、G-Evalの場合は実験でGPTを用いているため、モデルから直接尤度を取得できず、代わりにtemperature1とし、20回程度生成を行った結果からスコアトークンの生成確率を擬似的に計算している。<br><br>G-Evalの設定と比較すると（当時はつよつよなOpenLLMがなかったため苦肉の策だったと思われるが）、こちらの研究の実験設定の方が望ましいと思う。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="balancing-speed-1524" class="title-link">Balancing Speed and Stability: The Trade-offs of FP8 vs. BF16 Training  in LLMs, Kazuki Fujii+, arXiv'24</h3><br><a href="https://arxiv.org/abs/2411.08719" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1524" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Supervised-FineTuning-(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2024-11-17</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデル（LLMs）は、その言語理解能力と適用可能性から注目を集めており、特にLlama 3シリーズは4050億パラメータを持つ。トレーニングの効率化が求められる中、NVIDIAのH100 GPUはFP8フォーマットを導入し、トレーニング時間を短縮する可能性がある。初期研究ではFP8が性能を損なわずに効率を向上させることが示唆されているが、トレーニングの安定性や下流タスクへの影響はまだ不明である。本研究は、LLMsのトレーニングにおけるBF16とFP8のトレードオフを探る。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/okoge_kaz/status/1857639065421754525?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>FP8で継続的事前学習をするとスループットは向上するが、lossのスパイクを生じたり、downstreamタスクの性能がBF16よりも低下したりする（日本語と英語の両方）との報告のようである。現状アブストと付録しか記載がないが、内容はこれから更新されるのだろうか。<br><br><img src="https://github.com/user-attachments/assets/8d60d59b-de00-483a-bff0-04a4145715c1" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="the-geometry-1522" class="title-link">The Geometry of Concepts: Sparse Autoencoder Feature Structure, Yuxiao Li+, arXiv'24</h3><br><a href="https://arxiv.org/abs/2410.19750" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1522" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2024-11-17</span>
<span class="snippet"><span>GPT Summary</span>- スパースオートエンコーダは、高次元ベクトルの辞書を生成し、概念の宇宙に三つの興味深い構造を発見した。1) 小規模構造では、平行四辺形や台形の「結晶」があり、単語の長さなどの干渉を除去することで質が改善される。2) 中規模構造では、数学とコードの特徴が「葉」を形成し、空間的局所性が定量化され、特徴が予想以上に集まることが示された。3) 大規模構造では、特徴点雲が各向同性でなく、固有値のべき法則を持ち、クラスタリングエントロピーが層に依存することが定量化された。</span>
<span class="snippet"><span>Comment</span><p>参考: 


<a href="https://ledge.ai/articles/llm_conceptual_structure_sae" target="_blank" rel="noopener noreferrer">https://ledge.ai/articles/llm_conceptual_structure_sae</a>


</p><p>[Perplexity（参考;Hallucinationに注意）](


<a href="https://www.perplexity.ai/search/yi-xia-nolun-wen-wodu-minei-ro-kR626A9_R8.6CU7IKvGyhQ)" target="_blank" rel="noopener noreferrer">https://www.perplexity.ai/search/yi-xia-nolun-wen-wodu-minei-ro-kR626A9_R8.6CU7IKvGyhQ)</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="a-theoretical-1509" class="title-link">A Theoretical Understanding of Chain-of-Thought: Coherent Reasoning and  Error-Aware Demonstration, Yingqian Cui+, arXiv'24</h3><br><a href="https://arxiv.org/abs/2410.16540" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1509" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2024-11-13</span>
<span class="snippet"><span>GPT Summary</span>- Few-shot Chain-of-Thought (CoT) プロンプティングはLLMsの推論能力を向上させるが、従来の研究は推論プロセスを分離された文脈内学習に依存している。本研究では、初期ステップからの一貫した推論（Coherent CoT）を統合することで、トランスフォーマーのエラー修正能力と予測精度を向上させることを理論的に示す。実験により、正しい推論経路と誤った推論経路を組み込むことでCoTを改善する提案の有効性を検証する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/_philschmid/status/1855926845855699311?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><br>おもしろそうな研究</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="lora-vs-1492" class="title-link">LoRA vs Full Fine-tuning: An Illusion of Equivalence, Reece Shuttleworth+, arXiv'24</h3><br><a href="https://arxiv.org/abs/2410.21228v1" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1492" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="PEFT(Adaptor-LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2024-11-09</span>
<span class="snippet"><span>GPT Summary</span>- ファインチューニング手法の違いが事前学習済みモデルに与える影響を、重み行列のスペクトル特性を通じて分析。LoRAと完全なファインチューニングは異なる構造の重み行列を生成し、LoRAモデルは新たな高ランクの特異ベクトル（侵入次元）を持つことが判明。侵入次元は一般化能力を低下させるが、同等の性能を達成することがある。これにより、異なるファインチューニング手法がパラメータ空間の異なる部分にアクセスしていることが示唆される。</span>
<span class="snippet"><span>Comment</span><p>元ポスト: 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/aratako_lm/status/1854838012909166973?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1423" target="_blank" rel="noopener noreferrer">When Scaling Meets LLM Finetuning: The Effect of Data, Model and  Finetuning Method, Biao Zhang+, N/A, ICLR'24</a>
 や <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1475" target="_blank" rel="noopener noreferrer">Beyond Full Fine-tuning: Harnessing the Power of LoRA for Multi-Task Instruction Tuning, Xin+, LREC-COLING'24</a>
 、双方の知見も交えて、LoRAの挙動を考察する必要がある気がする。それぞれ異なるデータセットやモデルで、LoRAとFFTを比較している。時間がないが後でやりたい。<br><br>あと、昨今はそもそも実験設定における変数が多すぎて、とりうる実験設定が多すぎるため、個々の論文の知見を鵜呑みにして一般化するのはやめた方が良い気がしている。</p><p>
<strong># 実験設定の違い<br>## モデルのアーキテクチャ<br>- 本研究: RoBERTa-base（transformer-encoder）<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1423" target="_blank" rel="noopener noreferrer">When Scaling Meets LLM Finetuning: The Effect of Data, Model and  Finetuning Method, Biao Zhang+, N/A, ICLR'24</a>
</strong>
<br>
: transformer-decoder<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1475" target="_blank" rel="noopener noreferrer">Beyond Full Fine-tuning: Harnessing the Power of LoRA for Multi-Task Instruction Tuning, Xin+, LREC-COLING'24</a>
: transformer-decoder（LLaMA）<br><br>
<strong>## パラメータサイズ<br>- 本研究: <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1423" target="_blank" rel="noopener noreferrer">When Scaling Meets LLM Finetuning: The Effect of Data, Model and  Finetuning Method, Biao Zhang+, N/A, ICLR'24</a>
</strong>
<br>
: 1B, 2B, 4B, 8B, 16B<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1475" target="_blank" rel="noopener noreferrer">Beyond Full Fine-tuning: Harnessing the Power of LoRA for Multi-Task Instruction Tuning, Xin+, LREC-COLING'24</a>
: 7B<br><br>時間がある時に続きをかきたい<br><br>## Finetuningデータセットのタスク数<br><br>## 1タスクあたりのデータ量<br><br>## trainableなパラメータ数</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="to-cot-1406" class="title-link">To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic  reasoning, Zayne Sprague+, N_A, arXiv'24</h3><br><a href="https://arxiv.org/abs/2409.12183" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1406" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2024-09-24</span>
<span class="snippet"><span>GPT Summary</span>- Chain-of-thought（CoT）プロンプティングはLLMsの推論能力を引き出す手法であり、100以上の論文を対象にしたメタ分析により、主に数学や論理タスクでのパフォーマンス向上が確認された。一方、他のタスクでは効果が限定的で、MMLUでは直接回答生成がCoTと同等の精度を示した。計画と実行を分離し、ツール強化LLMsと比較した結果、CoTの利点は記号的実行の改善に起因し、記号ソルバーには劣ることが分かった。CoTの選択的適用により、推論コストを節約しつつパフォーマンスを維持できる可能性が示唆され、LLMアプリケーション全体での中間計算の活用が求められている。</span>
<span class="snippet"><span>Comment</span><p>CoTを100個以上の先行研究でmeta-analysisし（i.e. CoTを追加した場合のgainとタスクのプロット）、20個超えるデータセットで著者らが実験した結果、mathはsymbolic reasoning（12*4のように、シンボルを認識し、何らかの操作をして回答をする問題）が必要なタスクで、CoTは大きなgainが得られることがわかった（他はほとんどgainがない）。<br><img src="https://github.com/user-attachments/assets/a399306f-bda9-45c9-a756-2a83a9727e63" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="what-do-1362" class="title-link">What Do Language Models Learn in Context? The Structured Task Hypothesis, Jiaoda Li+, N_A, ACL'24</h3><br><a href="https://arxiv.org/abs/2406.04216" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1362" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2024-08-27</span>
<span class="snippet"><span>GPT Summary</span>- LLMsのコンテキスト内学習（ICL）能力を説明する3つの仮説について、一連の実験を通じて探究。最初の2つの仮説を無効にし、最後の仮説を支持する証拠を提供。LLMが事前学習中に学習したタスクを組み合わせることで、コンテキスト内で新しいタスクを学習できる可能性を示唆。</span>
<span class="snippet"><span>Comment</span><p>SNLP2024での解説スライド:<br>


<a href="http://chasen.org/~daiti-m/paper/SNLP2024-Task-Emergence.pdf" target="_blank" rel="noopener noreferrer">http://chasen.org/~daiti-m/paper/SNLP2024-Task-Emergence.pdf</a>


</p><p>ICLが何をやっているのか?について、これまでの仮説が正しくないことを実験的に示し、新しい仮説「ICLは事前学習で得られたタスクを組み合わせて新しいタスクを解いている」を提唱し、この仮説が正しいことを示唆する実験結果を得ている模様。<br>理論的に解明されたわけではなさそうなのでそこは留意した方が良さそう。あとでしっかり読む。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="the-illusion-1361" class="title-link">[Paper Note] The Illusion of State in State-Space Models, William Merrill+, ICML'24, 2024.04</h3><br><a href="https://arxiv.org/abs/2404.08819" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1361" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="SSM-(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<a class="button" href="ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2024-08-27</span>
<span class="snippet"><span>GPT Summary</span>- 状態空間モデル（SSMs）は、トランスフォーマーの代替として注目されていますが、その表現力はトランスフォーマーと類似の制限があり、特定の状態追跡問題を解決できないことが明らかになりました。特に、SSMsは複雑さクラス$\mathsf{TC}^0$を超える計算を表現できず、実際的な状態追跡能力にも限界があります。形式的分析と実験によって、リカレントな定式化にもかかわらず、SSMにおける「状態」は幻想であり、実際の問題解決において制約があることが示されています。</span>
<span class="snippet"><span>Comment</span><p>>しかし、SSMが状態追跡の表現力で本当に（トランスフォーマーよりも）優位性を持っているのでしょうか？驚くべきことに、その答えは「いいえ」です。私たちの分析によると、SSMの表現力は、トランスフォーマーと非常に類似して制限されています：SSMは複雑性クラス$\mathsf{TC}^0$の外での計算を表現することができません。特に、これは、置換合成のような単純な状態追跡問題を解決することができないことを意味します。これにより、SSMは、特定の表記法でチェスの手を正確に追跡したり、コードを評価したり、長い物語の中のエンティティを追跡することが証明上できないことが明らかになります。<br><br>なん…だと…</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="amuro-&-1352" class="title-link">Amuro & Char: Analyzing the Relationship between Pre-Training and  Fine-Tuning of Large Language Models, Kaiser Sun+, N_A, arXiv'24</h3><br><a href="https://arxiv.org/abs/2408.06663" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1352" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Supervised-FineTuning-(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<span class="issue_date">Issue Date: 2024-08-19</span>
<span class="snippet"><span>GPT Summary</span>- 大規模なテキストコーパスで事前学習された複数の中間事前学習モデルのチェックポイントを微調整することによって、事前学習と微調整の関係を調査した。18のデータセットでの結果から、i）継続的な事前学習は、微調整後にモデルを改善する潜在的な方法を示唆している。ii）追加の微調整により、モデルが事前学習段階でうまく機能しないデータセットの改善が、うまく機能するデータセットよりも大きいことを示している。iii）監督された微調整を通じてモデルは恩恵を受けるが、以前のドメイン知識や微調整中に見られないタスクを忘れることがある。iv）監督された微調整後、モデルは評価プロンプトに対して高い感度を示すが、これはより多くの事前学習によって緩和できる。</span>
</article>
<article class="paper-entry">
<h3 id="prompting-open-source-1351" class="title-link">Prompting open-source and commercial language models for grammatical  error correction of English learner text, Christopher Davis+, N_A, arXiv'24</h3><br><a href="https://arxiv.org/abs/2401.07702" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1351" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="GrammaticalErrorCorrection.html" target="_blank" rel="noopener noreferrer">#GrammaticalErrorCorrection</a>
<span class="issue_date">Issue Date: 2024-08-14</span>
<span class="snippet"><span>GPT Summary</span>- LLMsの進歩により、流暢で文法的なテキスト生成が可能になり、不文法な入力文を与えることで文法エラー修正（GEC）が可能となった。本研究では、7つのオープンソースと3つの商用LLMsを4つのGECベンチマークで評価し、商用モデルが常に教師ありの英語GECモデルを上回るわけではないことを示した。また、オープンソースモデルが商用モデルを上回ることがあり、ゼロショットのプロンプティングがフューショットのプロンプティングと同じくらい競争力があることを示した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/chemical_tree/status/1822860849935253882?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="long-context-llms-1274" class="title-link">Long-context LLMs Struggle with Long In-context Learning, Tianle Li+, N_A, arXiv'24</h3><br><a href="https://arxiv.org/abs/2404.02060" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1274" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ContextWindow.html" target="_blank" rel="noopener noreferrer">#ContextWindow</a>
<a class="button" href="LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<span class="issue_date">Issue Date: 2024-04-07</span>
<span class="snippet"><span>GPT Summary</span>- LLMsは長いシーケンスを処理する能力に進展しているが、実世界のシナリオでの能力を評価するための専門的なベンチマークLongICLBenchが導入された。このベンチマークでは、LLMsは巨大なラベル空間を理解し、正しい予測を行うために入力全体を理解する必要がある。研究によると、長いコンテキストLLMsは長いコンテキストウィンドウを活用することで比較的良いパフォーマンスを示すが、最も困難なタスクでは苦労している。現在のLLMsは長くコンテキスト豊かなシーケンスを処理し理解する能力にギャップがあることを示唆しており、長いコンテキストの理解と推論は依然として難しい課題であることが示されている。</span>
<span class="snippet"><span>Comment</span><p>GPT4以外はコンテキストが20Kを超えると性能が劣化する傾向にあるとのこと。データセットを難易度別に収集し評価したところ、難易度の高いデータではそもそもコンテキストが長くなると全てのLLMがタスクを理解するできずほぼ0%の性能となった。<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/fc51d83a-3013-4fcc-bf7a-5722eb01d0d8" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="the-impact-1208" class="title-link">[Paper Note] The Impact of Reasoning Step Length on Large Language Models, Mingyu Jin+, ACL'24 Findings, 2024.01</h3><br><a href="https://arxiv.org/abs/2401.04925" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1208" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="Length.html" target="_blank" rel="noopener noreferrer">#Length</a>
<a class="button" href="Findings.html" target="_blank" rel="noopener noreferrer">#Findings</a>
<span class="issue_date">Issue Date: 2024-01-16</span>
<span class="snippet"><span>GPT Summary</span>- Chain of Thought（CoT）がLLMの推論能力向上に重要であることが示された。実験により、推論ステップの長さがLLMの性能に与える影響を調査。推論ステップを長くすることで、追加情報なしでも推論能力が向上し、逆に短くすると性能が著しく低下。これは、CoTプロンプトにおけるステップ数の重要性を示している。また、不正確な合理的根拠でも推論を維持できれば良好な結果が得られることが判明。タスクの複雑さに応じて、推論ステップの利点は異なることも観察された。</span>
</article>
<article class="paper-entry">
<h3 id="vila-on-1186" class="title-link">VILA: On Pre-training for Visual Language Models, Ji Lin+, N_A, CVPR'24</h3><br><a href="https://arxiv.org/abs/2312.07533" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1186" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="CVPR.html" target="_blank" rel="noopener noreferrer">#CVPR</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2023-12-14</span>
<span class="snippet"><span>GPT Summary</span>- 最近の大規模言語モデルの成功により、ビジュアル言語モデル（VLM）が進歩している。本研究では、VLMの事前学習のためのデザインオプションを検討し、以下の結果を示した：(1) LLMを凍結することでゼロショットのパフォーマンスが達成できるが、文脈に基づいた学習能力が不足している。(2) 交互に行われる事前学習データは有益であり、画像とテキストのペアだけでは最適ではない。(3) テキストのみの指示データを画像とテキストのデータに再ブレンドすることで、VLMのタスクの精度を向上させることができる。VILAというビジュアル言語モデルファミリーを構築し、最先端モデルを凌駕し、優れたパフォーマンスを発揮することを示した。マルチモーダルの事前学習は、VILAの特性を向上させる。</span>
<span class="snippet"><span>Comment</span><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1068" target="_blank" rel="noopener noreferrer">Improved Baselines with Visual Instruction Tuning, Haotian Liu+, N/A, CVPR'24</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="causallm-is-1029" class="title-link">CausalLM is not optimal for in-context learning, Nan Ding+, N_A, ICLR'24</h3><br><a href="https://arxiv.org/abs/2308.06912" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1029" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2023-09-01</span>
<span class="snippet"><span>GPT Summary</span>- 最近の研究では、トランスフォーマーベースのインコンテキスト学習において、プレフィックス言語モデル（prefixLM）が因果言語モデル（causalLM）よりも優れたパフォーマンスを示すことがわかっています。本研究では、理論的なアプローチを用いて、prefixLMとcausalLMの収束挙動を分析しました。その結果、prefixLMは線形回帰の最適解に収束する一方、causalLMの収束ダイナミクスはオンライン勾配降下アルゴリズムに従い、最適であるとは限らないことがわかりました。さらに、合成実験と実際のタスクにおいても、causalLMがprefixLMよりも性能が劣ることが確認されました。</span>
<span class="snippet"><span>Comment</span><p>参考: 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/1697380430004249066?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>CausalLMでICLをした場合は、ICL中のdemonstrationでオンライン学習することに相当し、最適解に収束しているとは限らない……？が、hillbigさんの感想に基づくと、結果的には実は最適解に収束しているのでは？という話も出ているし、よく分からない。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="lost-in-793" class="title-link">Lost in the Middle: How Language Models Use Long Contexts, Nelson F. Liu+, N_A, TACL'24</h3><br><a href="https://arxiv.org/abs/2307.03172" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/793" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="TACL.html" target="_blank" rel="noopener noreferrer">#TACL</a>
<a class="button" href="ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2023-07-11</span>
<span class="snippet"><span>GPT Summary</span>- 最近の言語モデルは、長い文脈を入力として受け取ることができますが、その長い文脈をどれだけうまく利用しているかについてはまだよくわかっていません。この研究では、マルチドキュメントの質問応答とキー・バリューの検索という2つのタスクにおいて、言語モデルのパフォーマンスを分析しました。その結果、関連情報が入力文脈の始まりや終わりにある場合、パフォーマンスが最も高くなることがわかりましたが、長い文脈の中で関連情報にアクセスする必要がある場合、パフォーマンスが著しく低下します。さらに、入力文脈が長くなるにつれて、明示的に長い文脈を扱うモデルでもパフォーマンスが大幅に低下します。この分析は、言語モデルが入力文脈をどのように利用しているかをより良く理解するためのものであり、将来の長い文脈モデルのための新しい評価プロトコルを提供します。</span>
<span class="snippet"><span>Comment</span><p>元ツイート<br>



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/drjimfan/status/1678460065811136512?s=46&t=5BO_qSlNBSEGSugyUlP5Hw"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><br>非常に重要な知見がまとめられている</p><p>1. モデルはコンテキストのはじめと最後の情報をうまく活用でき、真ん中の情報をうまく活用できない<br>2. 長いコンテキストのモデルを使っても、コンテキストをより短いコンテキストのモデルよりもうまく考慮できるわけではない<br>3. モデルのパフォーマンスは、コンテキストが長くなればなるほど悪化する</p><p>SNLP'24での解説スライド:<br>


<a href="https://speakerdeck.com/kichi/snlp2024" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/kichi/snlp2024</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="evidence-of-686" class="title-link">Evidence of Meaning in Language Models Trained on Programs, Charles Jin+, N_A, ICML'24</h3><br><a href="https://arxiv.org/abs/2305.11169" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/686" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2023-05-20</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、プログラムのコーパスを用いて言語モデルが意味を学習できることを示し、プログラム合成が言語モデルの意味の存在を特徴づけるための中間テストベッドとして適していることを述べている。Transformerモデルを用いた実験により、言語の意味を学習するための帰納バイアスを提供しないにもかかわらず、線形プローブがモデルの状態から現在および将来のプログラム状態の抽象化を抽出できることがわかった。また、正しいプログラムを生成することを学習し、平均的に訓練セットよりも短いプログラムを生成することも示した。本論文は、言語モデルの訓練に新しい技術を提案するものではなく、(形式的な)意味の習得と表現に関する実験的なフレームワークを開発し、洞察を提供する。</span>
<span class="snippet"><span>Comment</span><p>プログラムのコーパスでLLMをNext Token Predictionで訓練し<br>厳密に正解とsemanticsを定義した上で、訓練データと異なるsemanticsの異なるプログラムを生成できることを示した。<br><br>LLMが意味を理解していることを暗示している<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/fa4d2c68-bdbe-40ae-990d-10814ac8a204" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p><p>参考: 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/1660409936264970240?s=46&t=QJho5ctFkeax7s_UMOfWBQ"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="causal-reasoning-635" class="title-link">[Paper Note] Causal Reasoning and Large Language Models: Opening a New Frontier for Causality, Emre Kıcıman+, TMLR'24, 2023.04</h3><br><a href="https://arxiv.org/abs/2305.00050" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/635" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="TMLR.html" target="_blank" rel="noopener noreferrer">#TMLR</a>
<a class="button" href="Generalization.html" target="_blank" rel="noopener noreferrer">#Generalization</a>
<span class="issue_date">Issue Date: 2023-05-04</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、大規模言語モデル（LLMs）の因果的議論生成能力をベンチマークし、様々なタスクで既存手法を上回る性能を示しました。特に、GPT-3.5および4は因果発見や反事実的推論タスクで高い精度を達成し、データセットの記憶だけでは説明できない能力を持つことが確認されました。しかし、LLMsには予測不可能な失敗モードがあり、改善の余地があることも指摘されています。LLMsは因果分析の労力を削減する可能性があり、今後はLLMsと既存の因果技術を組み合わせたアルゴリズムの開発が期待されます。</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=mqoxLkX210" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=mqoxLkX210</a>


</p><p>tmlr blog:


<a href="https://medium.com/@TmlrOrg/announcing-the-2025-tmlr-outstanding-certification-e26d548ff011" target="_blank" rel="noopener noreferrer">https://medium.com/@TmlrOrg/announcing-the-2025-tmlr-outstanding-certification-e26d548ff011</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="tinystories-how-4234" class="title-link">[Paper Note] TinyStories: How Small Can Language Models Be and Still Speak Coherent English?, Ronen Eldan+, arXiv'23, 2023.05</h3><br><a href="https://arxiv.org/abs/2305.07759" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4234" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<span class="issue_date">Issue Date: 2026-01-19</span>
<span class="snippet"><span>GPT Summary</span>- LMは小規模モデルでは一貫性のあるテキスト生成が難しい。本研究では、3～4歳児が理解できる単語のみを含む短編小説データセット「TinyStories」を紹介。これはGPT-3.5とGPT-4で生成され、1000万パラメータ未満のモデルでも流暢な物語が生成可能であることを示す。さらに、出力評価の新たなパラダイムを提案し、学生の作品との比較を通じてさまざまな能力に対するスコアを提供。TinyStoriesはLMの研究を促進し、限られたリソースや特殊ドメインにおける言語能力の発展に寄与することが期待される。</span>
<span class="snippet"><span>Comment</span><p>dataset: 


<a href="https://huggingface.co/datasets/roneneldan/TinyStories" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/roneneldan/TinyStories</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="physics-of-2400" class="title-link">[Paper Note] Physics of Language Models: Part 1, Learning Hierarchical Language  Structures, Zeyuan Allen-Zhu+, arXiv'23</h3><br><a href="https://arxiv.org/abs/2305.13673" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2400" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-11</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、Transformerベースの言語モデルが文脈自由文法（CFG）による再帰的な言語構造推論をどのように行うかを調査。合成CFGを用いて長文を生成し、GPTのようなモデルがCFGの階層を正確に学習・推論できることを示す。モデルの隠れ状態がCFGの構造を捉え、注意パターンが動的プログラミングに類似していることが明らかに。また、絶対位置埋め込みの劣位や均一な注意の効果、エンコーダ専用モデルの限界、構造的ノイズによる堅牢性向上についても考察。</span>
<span class="snippet"><span>Comment</span><p>解説:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1834" target="_blank" rel="noopener noreferrer">言語モデルの物理学, 佐藤竜馬, 2025.03</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="unnatural-error-1177" class="title-link">Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural  Scrambled Text, Qi Cao+, N_A, arXiv'23</h3><br><a href="https://arxiv.org/abs/2311.18805" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1177" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<span class="issue_date">Issue Date: 2023-12-04</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、大規模言語モデル（LLMs）の内部動作についての新しい洞察を提供します。特に、GPT-4を調査し、LLMsの耐久性に関する実験結果を示します。実験では、文字レベルの順列に対するLLMsの耐性を調べるために、Scrambled Benchというスイートを使用しました。結果は、GPT-4がtypoglycemiaという現象に似た能力を持ち、非常に自然でないエラーを含む入力をほぼ完璧に処理できることを示しています。これは、LLMsの耐性が直感に反するものであり、他のLLMsや人間にとっても困難なタスクであることを示しています。</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/df33c7a9-005e-4d7e-9d70-d8f0657869ed" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p><p>OpenAIのモデルがブラックボックスである限り、コンタミネーションがあるのでは？という疑念は持ってしまう。<br><br>（部分的にしか読めていないが…）<br>RealtimeQAと呼ばれるweeklyで直近のニュースに対するQuestionを発表することで構築されるデータセットのうち、2023.03.17--2023.08.04のデータを収集し、ScrambledSentenaeRecovery（ScrRec）とScrambleQuestionAnswering（ScrQA）の評価データを生成している。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/362bcbca-b578-4f0e-ac4e-e65fd216aeac" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><br>完全にランダムに単語の文字をscramble（RS）すると、FalconとLlama2では元のテキストをゼロショットでは再構築できないことが分かる。FewShotではFalconであれば少し解けるようになる。一方、OpenAIのモデル、特にGPT4, GPT3.5-turboではゼロショットでもにり再構築ができている。<br><br>ScrQAについては、ランダムにscrambleした場合でもMultipleChoiceQuestionなので（RPGと呼ばれるAccの相対的なgainを評価するメトリックを提案している）正解はできている。<br><br>最初の文字だけを残す場合（KF）最初と最後の文字を残す場合（KFL」については、残す文字が増えるほどどちらのタスクも性能が上がり、最初の文字だけがあればOpenSourceLLMでも（ゼロショットでも）かなり元のテキストの再構築ができるようになっている。また、QAも性能が向上している。</p><p>完全にランダムに文字を入れ替えたら完全に無理ゲーなのでは、、、、と思ってしまうのだが、FalconでFewshotの場合は一部解けているようだ…。果たしてどういうことなのか…（大文字小文字が保持されたままなのがヒントになっている…？）Appendixに考察がありそうだがまだ読めていない。<br><br><br><br>（追記）<br><br>文全体でランダムに文字を入れ替えているのかと勘違いしていたが、実際には”ある単語の中だけでランダムに入れ替え”だった。これなら原理上はいけると思われる。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="do-llms-1120" class="title-link">Do LLMs exhibit human-like response biases? A case study in survey  design, Lindia Tjuatja+, N_A, arXiv'23</h3><br><a href="http://arxiv.org/abs/2311.04076" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1120" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-11-08</span>
<span class="snippet"><span>GPT Summary</span>- LLMsを使用して人間の代理としてタスクを実行する際に、LLMsが人間の応答バイアスをどの程度反映するかを調査する必要がある。この研究では、調査設計を使用して人間の応答バイアスを評価するデータセットとフレームワークを設計し、9つのモデルを評価した結果、一般的なLLMsが人間のような振る舞いを反映することに失敗していることが示された。これらの結果は、LLMsを人間の代わりに使用する際の潜在的な落とし穴を強調し、モデルの振る舞いの細かい特性の重要性を強調している。</span>
<span class="snippet"><span>Comment</span><p>LLMはPromptにsensitiveだが、人間も質問の仕方によって応答が変わるから、sensitiveなのは一緒では？ということを調査した研究。Neubig氏のツイートだと、instruction tuningやRLHFをしていないBase LLMの方が、より人間と類似した回答をするのだそう。<br><br>元ツイート: 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/gneubig/status/1722294711355117666?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>人間のレスポンスのバイアス。左側は人間は「forbidden」よりも「not allowed」を好むという例、右側は「response order」のバイアスの例（選択肢の順番）。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/de129e78-5d52-41e3-a3bb-9aec20cf2b05" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><br><br><br>LLM側で評価したいバイアスごとに、QAのテキストを変更し、LLMに回答を生成され、social science studiesでのトレンドと比較することで、LLMにも人間と同様のバイアスがあるかを明らかにしている。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/3dc39afc-4e52-49a4-bf60-22ff94bf35c6" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><br><br><br>結果は以下の表であり、青いセルが人間と同様のバイアスを持つことを統計的に有意に示されたもの（のはず）。これをみると、全てのバイアスに対して人間と同様の傾向があったのはLlama2-70Bのみであり、instruction tuningや、RLHFをかけた場合（RLHFの方が影響が大きそう）人間のバイアスとは異なる挙動をするモデルが多くなることがわかる。また、モデルのパラメータサイズとバイアスの強さには相関関係は見受けられない。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/7d8eade0-ae3a-4d62-bb2d-160971542c39" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><br></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="pretraining-data-1117" class="title-link">Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in  Transformer Models, Steve Yadlowsky+, N_A, arXiv'23</h3><br><a href="https://arxiv.org/abs/2311.00871" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1117" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2023-11-06</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、トランスフォーマーモデルの文脈学習（ICL）能力を調査しました。トランスフォーマーモデルは、事前学習データの範囲内で異なるタスクを特定し、学習する能力を持っています。しかし、事前学習データの範囲外のタスクや関数に対しては一般化が劣化することが示されました。また、高容量のシーケンスモデルのICL能力は、事前学習データの範囲に密接に関連していることが強調されました。</span>
<span class="snippet"><span>Comment</span><p>Transformerがpre-training時に利用された学習データ以外の分布に対しては汎化性能が落ちることを示したらしい。もしこれが正しいとすると、結局真に新しい分布というか関数というかタスクというか、をTransformerが創出する可能性は低いと言えるかもしれない。が、新しいものって大体は既存の概念の組み合わせだよね（スマホとか）、みたいなことを考えると、別にそれでも十分では？と思ってしまう。人間が本当に真の意味で新しい関数というかタスクというか分布を生み出せているかというと、実はそんなに多くないのでは？という予感もする。まあたとえば、量子力学を最初に考えました！とかそういうのは例外だと思うけど・・・、そのレベルのことってどんくらいあるんだろうね？</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="the-reversal-1059" class="title-link">[Paper Note] The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A", Lukas Berglund+, arXiv'23</h3><br><a href="https://arxiv.org/abs/2309.12288" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1059" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="ReversalCurse.html" target="_blank" rel="noopener noreferrer">#ReversalCurse</a>
<span class="issue_date">Issue Date: 2023-10-09</span>
<span class="snippet"><span>GPT Summary</span>- 自己回帰型大規模言語モデル（LLMs）は、「AはBである」という文から「BはAである」と逆の関係を自動的に一般化できない「逆転の呪い」を示す。例えば、モデルが「ワレンティナ・テレシコワは宇宙に行った最初の女性である」と訓練されても、「宇宙に行った最初の女性は誰か？」に正しく答えられない。実験では、架空の文を用いてGPT-3とLlama-1をファインチューニングし、逆転の呪いの存在を確認。ChatGPT（GPT-3.5およびGPT-4）でも、実在の有名人に関する質問で正答率に大きな差が見られた。</span>
<span class="snippet"><span>Comment</span><p>A is Bという文でLLMを訓練しても、B is Aという逆方向には汎化されないことを示した。<br><br>著者ツイート: 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/owainevans_uk/status/1705285631520407821?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/25e20dcc-0313-4cd2-8768-afb0e4e48a68" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br></p><p>GPT3, LLaMaを A is Bでfinetuneし、B is Aという逆方向のfactを生成するように（質問をして）テストしたところ、0%付近のAcc.だった。<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d089eb94-6872-40b5-89a1-7532758e1d89" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><br>また、Acc.が低いだけでなく、対数尤度もrandomなfactを生成した場合と、すべてのモデルサイズで差がないことがわかった。<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ba10fff4-cfdc-4e52-8217-c59247209211" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><br>このことら、Reversal Curseはモデルサイズでは解決できないことがわかる。</p><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1923" target="_blank" rel="noopener noreferrer">[Paper Note] Physics of Language Models: Part 3.1, Knowledge Storage and Extraction, Zeyuan Allen-Zhu+, ICML'24</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="can-large-892" class="title-link">[Paper Note] Can Large Language Models Be an Alternative to Human Evaluations?, Cheng-Han Chiang+, ACL'23, 2023.05</h3><br><a href="https://arxiv.org/abs/2305.01937" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/892" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ChatGPT.html" target="_blank" rel="noopener noreferrer">#ChatGPT</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<a class="button" href="Attack.html" target="_blank" rel="noopener noreferrer">#Attack</a>
<a class="button" href="ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="KeyPoint-Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<span class="snippet"><span>GPT Summary</span>- 人間評価の再現性が低いため、NLPモデル間の公正な比較が難しい。そこで、大規模言語モデル（LLM）を人間評価の代替手段として利用することを探求。本研究では、LLMに同一指示とサンプルを与え、評価を実施するLLM評価を提案。オープンエンドのストーリー生成や敵対的攻撃のタスクに対する評価結果は、人間専門家の評価と高い一致を示し、評価の安定性も確認。LLMを用いたテキスト評価の可能性やその限界、倫理的課題についても考察。</span>
<span class="snippet"><span>Comment</span><p>LLMがテキストの品質評価において、人間による評価者の代替となりうるか？という疑問を初めて実験的に示した研究で、インパクトが大きく重要論文と判断。ただし、実験のスコープは物語生成と敵対的生成（テキスト分類器を騙すような摂動を加える）の2タスクである点、には注意。<br><br>ChatGPT（おそらくGPT-3.5）が人間の評価者（3人のEnglish teacher）とopen-endで生成された物語にたいして、以下の4つの観点に関してratingの平均で見た時に同様の傾向のスコアを付与することを実験的に明らかにした：<br>- Grammaticality [^1]: テキストの文法の正しさ<br>- Cohesiveness: テキストの一貫性<br>- Likeability: テキストが読んでいて楽しいか<br>- Relevance: promptに対してどれだけ適切なテキストが生成されているか <br><br>ただし、T0やtext-curie-001 においてはこのような傾向は見受けられなかった。[^2]<br>また、ChatGPTによる説明とratingを人間の評価者に対してblindで提示したところ、人間が見ても妥当な判断だと認知された。<br><br>全体の傾向としてではなく、個別のratingがどの程度同じような傾向を示すか（i.e., 人間があるstoryを高くratingしたら、LLMも高くratingするか？）をケンドールの順位相関係数で分析（200サンプルに対して3人の英語教員のスコアの平均, text-davinciによる3回の独立したratingを実施した平均スコアを用いて計算）したところ、4つの観点のうち全てにおいて正の相関が見受けられた（Table2, p-valueは<0.05で統計的に有意）。が、Relevanceのみが強い相関を示し、他の指標については弱い相関にとどまっている。しかし、Table6に示されている通り、2人の英語の先生同士で個別のjudgeに感して同様にケンドールの順位相関係数を測定しても、人間-LLM間と同様の傾向が見受けられる。すなわち、Relevanceのみが強い相関で他は弱い相関。このことから、人間同士でも個別のサンプルに対する判断は一致しない（=主観的なタスク）ということは留意する必要がある。<br><br><img src="https://github.com/user-attachments/assets/4c4409ff-b4eb-4f73-b90d-eeb6b4d81199" /" alt="image" loading="lazy" width="550" height="400"/><br><br><img src="https://github.com/user-attachments/assets/54d21f3c-7ab6-4b41-a862-8dfc8d19b41a" /" alt="image" loading="lazy" width="550" height="400"/><br><br>敵対的生成に関する実験については、Synonym Substitution Attack (SSAs; 良性のサンプルを同義語で置換する手法で、全体的な意味は保たれるため一般的な人間は正しく認知してしまうが、実際には文法がおかしくなったり不自然になったり、意味が変わってしまうことが先行研究によって知られているようなものらしい)によって実験。Fluency / Meaning Preservingの2つの指標で英語教員とLLMによる評価を比較した結果、人間は正しくadversarialなサンプルと良性なサンプルを区別できており、ChatGPT（おそらくGPT-3.5）も区別ができている（Table4）。ただし、人間のスコアと比較するとChatGPTは高めのスコアを出す傾向がある点には注意ではあるものの、良性サンプル > 敵対的サンプル という序列の判断に関しては人間と同様の傾向を示していることが示唆された。<br><br><img src="https://github.com/user-attachments/assets/d94460fc-0615-4f86-82e5-3c7b15369cc6" /" alt="image" loading="lazy" width="550" height="400"/><br><br>[^1]: ただし、LLMはpunctuationのミスを文法エラーと判断するが、一人の英語の先生は文法エラーとしてみなさないなどの現象も観察され、人間は独自の評価criteriaを保持していることも窺える<br>[^2]: （感想）ある程度能力の高いLLMかRLHFなどを用いて人間の好みに対してalignmentがとられていないとうまくいかないのかもしれない</p><p>本研究は非常に初期の研究であり、現在のfrontierモデル群（特にreasoningモデル）を用いた場合にはどの程度改善しているか？という点は気になる。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="do-models-832" class="title-link">Do Models Really Learn to Follow Instructions? An Empirical Study of Instruction Tuning, ACL'23</h3><br><a href="https://virtual2023.aclweb.org/paper_P2358.html" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/832" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<span class="snippet"><span>GPT Summary</span>- 最近のinstruction tuning（IT）の研究では、追加のコンテキストを提供してモデルをファインチューニングすることで、ゼロショットの汎化性能を持つ素晴らしいパフォーマンスが実現されている。しかし、IT中にモデルがどのように指示を利用しているかはまだ研究されていない。本研究では、モデルのトレーニングを変更された指示と元の指示との比較によって、モデルがIT中に指示をどのように利用するかを分析する。実験の結果、トレーニングされたモデルは元の指示と同等のパフォーマンスを達成し、ITと同様のパフォーマンスを達成することが示された。この研究は、より信頼性の高いIT手法と評価の緊急性を強調している。</span>
</article>
<article class="paper-entry">
<h3 id="language-models-666" class="title-link">Language Models Don't Always Say What They Think: Unfaithful   Explanations in Chain-of-Thought Prompting, Miles Turpin+, N_A, NeurIPS'23</h3><br><a href="https://arxiv.org/abs/2305.04388" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/666" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="Faithfulness.html" target="_blank" rel="noopener noreferrer">#Faithfulness</a>
<a class="button" href="NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2023-05-09</span>
<span class="snippet"><span>GPT Summary</span>- LLMsによる推論において、chain-of-thought reasoning（CoT）と呼ばれる説明を生成することができるが、この説明がモデルの予測の真の理由を誤って表現することがあることがわかった。バイアスのある特徴をモデルの入力に追加することで、CoT説明が大きく影響を受けることが示された。この結果は、LLMsに対する信頼を高めるために、説明の忠実度を評価し、改善する必要があることを示唆している。</span>
</article>
<article class="paper-entry">
<h3 id="emergent-abilities-2860" class="title-link">[Paper Note] Emergent Abilities of Large Language Models, Jason Wei+, TMLR'22</h3><br><a href="https://arxiv.org/abs/2206.07682" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2860" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="EmergentAbilities.html" target="_blank" rel="noopener noreferrer">#EmergentAbilities</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデルのスケーリングアップは性能を向上させるが、「出現能力」と呼ばれる予測不可能な現象が存在する。これは小型モデルにはない能力であり、さらなるスケーリングがモデルの能力を拡大する可能性を示唆している。</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=yzkSU5zdwD" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=yzkSU5zdwD</a>


</p><p>創発能力（最近この用語を目にする機会が減ったような気がする）</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="knowledge-neurons-1332" class="title-link">Knowledge Neurons in Pretrained Transformers, Damai Dai+, N_A, ACL'22, 2022.05</h3><br><a href="https://arxiv.org/abs/2104.08696" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1332" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="FactualKnowledge.html" target="_blank" rel="noopener noreferrer">#FactualKnowledge</a>
<a class="button" href="Encoder.html" target="_blank" rel="noopener noreferrer">#Encoder</a>
<span class="issue_date">Issue Date: 2024-07-11</span>
<span class="snippet"><span>GPT Summary</span>- 大規模な事前学習言語モデルにおいて、事実知識の格納方法についての研究を行いました。具体的には、BERTのfill-in-the-blank cloze taskを用いて、関連する事実を表現するニューロンを特定しました。また、知識ニューロンの活性化と対応する事実の表現との正の相関を見つけました。さらに、ファインチューニングを行わずに、知識ニューロンを活用して特定の事実知識を編集しようと試みました。この研究は、事前学習されたTransformers内での知識の格納に関する示唆に富んでおり、コードはhttps://github.com/Hunter-DDM/knowledge-neuronsで利用可能です。</span>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1108" target="_blank" rel="noopener noreferrer">大規模言語モデルにおいて､「知識は全結合層に蓄積される」という仮説についての文献調査</a>
 </p><p>日本語解説: 


<a href="https://speakerdeck.com/kogoro/knowledge-neurons-in-pretrained-transformers-for-snlp2022" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/kogoro/knowledge-neurons-in-pretrained-transformers-for-snlp2022</a>


</p><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2140" target="_blank" rel="noopener noreferrer">[Paper Note] Transformer Feed-Forward Layers Are Key-Value Memories, Mor Geva+, EMNLP'21</a>
</p><p>上記資料によると、特定の知識を出力する際に活性化する知識ニューロンを特定する手法を提案。MLMを用いたclozeタスクによる実験で[MASK]部分に当該知識を出力する実験をした結果、知識ニューロンの重みをゼロとすると性能が著しく劣化し、値を2倍にすると性能が改善するといった傾向がみられた。　ケーススタディとして、知識の更新と、知識の削除が可能かを検証。どちらとも更新・削除がされる方向性[^1]へモデルが変化した。<br><br>また、知識ニューロンはTransformerの層の深いところに位置している傾向にあり、異なるrelationを持つような関係知識同士では共有されない傾向にある模様。<br><br>[^1]: 他の知識に影響を与えず、完璧に更新・削除できたわけではない。知識の更新・削除に伴いExtrinsicな評価によって性能向上、あるいはPerplexityが増大した、といった結果からそういった方向性へモデルが変化した、という話</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="self-repetition-in-939" class="title-link">Self-Repetition in Abstractive Neural Summarizers, Nikita Salkar+, N_A,  AACL-IJCNLP'22</h3><br><a href="https://arxiv.org/abs/2210.08145" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/939" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="IJCNLP.html" target="_blank" rel="noopener noreferrer">#IJCNLP</a>
<a class="button" href="AACL.html" target="_blank" rel="noopener noreferrer">#AACL</a>
<a class="button" href="Repetition.html" target="_blank" rel="noopener noreferrer">#Repetition</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<span class="snippet"><span>GPT Summary</span>- 私たちは、BART、T5、およびPegasusという3つのニューラルモデルの出力における自己繰り返しの分析を行いました。これらのモデルは、異なるデータセットでfine-tuningされています。回帰分析によると、これらのモデルは入力の出力要約間でコンテンツを繰り返す傾向が異なることがわかりました。また、抽象的なデータや定型的な言語を特徴とするデータでのfine-tuningでは、自己繰り返しの割合が高くなる傾向があります。定性的な分析では、システムがアーティファクトや定型フレーズを生成することがわかりました。これらの結果は、サマライザーのトレーニングデータを最適化するための手法の開発に役立つ可能性があります。</span>
</article>
<article class="paper-entry">
<h3 id="out-of-674" class="title-link">Out of One, Many: Using Language Models to Simulate Human Samples, Lisa P. Argyle+, N_A, arXiv'22</h3><br><a href="https://arxiv.org/abs/2209.06899" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/674" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-05-11</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、言語モデルが社会科学研究において特定の人間のサブポピュレーションの代理として研究される可能性があることを提案し、GPT-3言語モデルの「アルゴリズム的忠実度」を探求する。アルゴリズム的忠実度が十分である言語モデルは、人間や社会の理解を進めるための新しい強力なツールとなる可能性があると提案する。</span>
</article>
<article class="paper-entry">
<h3 id="feature-learning-2583" class="title-link">[Paper Note] Feature Learning in Infinite-Width Neural Networks, Greg Yang+, ICML'21</h3><br><a href="https://arxiv.org/abs/2011.14522" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2583" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2025-08-28</span>
<span class="snippet"><span>GPT Summary</span>- 無限幅の深層ニューラルネットワークにおいて、標準およびNTKパラメータ化は特徴学習を可能にする限界を持たないことを示し、これを克服するための修正を提案。Tensor Programs技術を用いて限界の明示的な式を導出し、Word2VecやMAMLを用いた少数ショット学習でこれらの限界を計算。提案手法はNTKベースラインや有限幅ネットワークを上回る性能を示し、特徴学習を許可するパラメータ化の空間を分類。</span>
</article>
<article class="paper-entry">
<h3 id="transformer-feed-forward-2140" class="title-link">[Paper Note] Transformer Feed-Forward Layers Are Key-Value Memories, Mor Geva+, EMNLP'21</h3><br><a href="https://arxiv.org/abs/2012.14913" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2140" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="FactualKnowledge.html" target="_blank" rel="noopener noreferrer">#FactualKnowledge</a>
<span class="issue_date">Issue Date: 2025-07-04</span>
<span class="snippet"><span>GPT Summary</span>- フィードフォワード層はトランスフォーマーモデルの大部分を占めるが、その役割は未探求。研究により、フィードフォワード層がキー・バリュー・メモリとして機能し、トレーニング例のテキストパターンと相関することを示す。実験で、下層は浅いパターン、上層は意味的なパターンを学習し、バリューが出力分布を誘導することが確認された。最終的に、フィードフォワード層の出力はメモリの合成であり、残差接続を通じて洗練される。</span>
<span class="snippet"><span>Comment</span><p>日本語解説（p.5より）: 


<a href="https://speakerdeck.com/kogoro/knowledge-neurons-in-pretrained-transformers-for-snlp2022?slide=5" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/kogoro/knowledge-neurons-in-pretrained-transformers-for-snlp2022?slide=5</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="intrinsic-dimensionality-1439" class="title-link">Intrinsic Dimensionality Explains the Effectiveness of Language Model   Fine-Tuning, Armen Aghajanyan+, N_A, ACL'21</h3><br><a href="https://arxiv.org/abs/2012.13255" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1439" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="PEFT(Adaptor-LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<span class="issue_date">Issue Date: 2024-10-01</span>
<span class="snippet"><span>GPT Summary</span>- 事前学習された言語モデルのファインチューニングのダイナミクスを内因次元の観点から分析し、少ないデータでも効果的に調整できる理由を説明。一般的なモデルは低い内因次元を持ち、フルパラメータ空間と同等の効果を持つ低次元の再パラメータ化が可能であることを示す。特に、RoBERTaモデルを用いて、少数のパラメータの最適化で高いパフォーマンスを達成できることを実証。また、事前学習が内因次元を最小化し、大きなモデルが低い内因次元を持つ傾向があることを示し、内因次元に基づく一般化境界を提案。</span>
<span class="snippet"><span>Comment</span><p>ACL ver:


<a href="https://aclanthology.org/2021.acl-long.568.pdf" target="_blank" rel="noopener noreferrer">https://aclanthology.org/2021.acl-long.568.pdf</a>


</p><p>下記の元ポストを拝読の上論文を斜め読み。モデルサイズが大きいほど、特定の性能（論文中では2種類のデータセットでの90%のsentence prediction性能）をfinetuningで達成するために必要なパラメータ数は、モデルサイズが大きくなればなるほど小さくなっている。<br><br>LoRAとの関係性についても元ポスト中で言及されており、論文の中身も見て後で確認する。<br>おそらく、LLMはBERTなどと比較して遥かにパラメータ数が大きいため、finetuningに要するパラメータ数はさらに小さくなっていることが想像され、LoRAのような少量のパラメータをconcatするだけでうまくいく、というような話だと思われる。興味深い。<br><br><img src="https://github.com/user-attachments/assets/166ebdae-539f-44cf-822b-0084640e07b2" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/bilzrd/status/1840445027438456838?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="transformer-feed-forward-1333" class="title-link">[Paper Note] Transformer Feed-Forward Layers Are Key-Value Memories, Mor Geva+, N_A, EMNLP'21</h3><br><a href="https://arxiv.org/abs/2012.14913" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1333" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2024-07-11</span>
<span class="snippet"><span>GPT Summary</span>- トランスフォーマーモデルのフィードフォワード層は、キー・バリューメモリとして機能し、学習されたパターンが人間に解釈可能であることや、上位層がより意味のあるパターンを学習することが示されました。さらに、出力分布を誘導する役割も持ちます。フィードフォワード層の出力はそのメモリの合成であり、残差接続を介してモデルの層を通じて洗練され、最終的な出力分布を生成します。</span>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1108" target="_blank" rel="noopener noreferrer">大規模言語モデルにおいて､「知識は全結合層に蓄積される」という仮説についての文献調査</a>
 </p><p>FF layerがKey-Valueストアとして機能する仕組みの概略図<br><img src="https://github.com/user-attachments/assets/cc12695f-b030-433a-88e1-aed69f9847a7" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><br>実際に特定のKeyと最も関連度が高い訓練事例（input）を抽出し、人間がinputのパターンを分類した結果<br><img src="https://github.com/user-attachments/assets/d1c1a031-9cb8-4e22-bf87-23964f0e0c71" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="the-perils-1306" class="title-link">The Perils of Using Mechanical Turk to Evaluate Open-Ended Text  Generation, Marzena Karpinska+, N_A, EMNLP'21</h3><br><a href="https://arxiv.org/abs/2109.06835" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1306" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="Annotation.html" target="_blank" rel="noopener noreferrer">#Annotation</a>
<a class="button" href="Reproducibility.html" target="_blank" rel="noopener noreferrer">#Reproducibility</a>
<a class="button" href="KeyPoint-Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2024-05-15</span>
<span class="snippet"><span>GPT Summary</span>- 最近のテキスト生成の研究は、オープンエンドのドメインに注力しており、その評価が難しいため、多くの研究者がクラウドソーシングされた人間の判断を収集してモデリングを正当化している。しかし、多くの研究は重要な詳細を報告しておらず、再現性が妨げられていることがわかった。さらに、労働者はモデル生成のテキストと人間による参照テキストを区別できないことが発見され、表示方法を変更することで改善されることが示された。英語教師とのインタビューでは、モデル生成のテキストを評価する際の課題について、より深い洞察が得られた。</span>
<span class="snippet"><span>Comment</span><p>Open-endedなタスクに対するAMTの評価の再現性に関する研究。先行研究をSurveyしたところ、再現のために重要な情報（たとえば、workerの資格、費用、task descriptions、annotator間のagreementなど）が欠落していることが判明した。<br><br>続いて、expertsとAMT workerに対して、story generationの評価を実施し、GPT2が生成したストーリーと人間が生成したストーリーを、後者のスコアが高くなることを期待して依頼した。その結果<br><br>- AMTのratingは、モデルが生成したテキストと、人間が生成したテキストをreliableに区別できない<br><br>- 同一のタスクを異なる日程で実施をすると、高い分散が生じた<br><br>- 多くのAMT workerは、評価対象のテキストを注意深く読んでいない<br><br>- Expertでさえモデルが生成したテキストを読み判断するのには苦戦をし、先行研究と比較してより多くの時間を費やし、agreementが低くなることが分かった<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/1dc01c56-88b0-4bea-869b-f396d65701cc" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><br></p><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/892" target="_blank" rel="noopener noreferrer">[Paper Note] Can Large Language Models Be an Alternative to Human Evaluations?, Cheng-Han Chiang+, ACL'23, 2023.05</a>
<br><br>において、低品質なwork forceが人手評価に対して有害な影響を与える、という文脈で本研究が引用されている</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="experts-1221" class="title-link">[Paper Note] Experts, Errors, and Context: A Large-Scale Study of Human Evaluation  for Machine Translation, Markus Freitag+, arXiv'21</h3><br><a href="https://arxiv.org/abs/2104.14478" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1221" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2024-01-25</span>
<span class="snippet"><span>GPT Summary</span>- 機械翻訳システムの人間による評価は難しく、標準的な手続きが欠如している。そこで、MQMフレームワークに基づく評価方法論を提案し、WMT 2020のトップシステムの出力をプロの翻訳者による注釈でスコアリングした。分析の結果、クラウドワーカーによる評価とは異なり、人間の出力が機械の出力より好まれることが示された。また、事前学習された埋め込みに基づく自動メトリクスが人間の評価を上回ることも明らかになった。コーパスは今後の研究のために公開される。</span>
<span class="snippet"><span>Comment</span><p>embedding basedなNLGの性能指標が、意味の等価性や流暢性を評価できる一方、適用範囲が限定的で柔軟性に欠けることを示した研究</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="on-layer-2142" class="title-link">[Paper Note] On Layer Normalization in the Transformer Architecture, Ruibin Xiong+, arXiv'20</h3><br><a href="https://arxiv.org/abs/2002.04745" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2142" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="Normalization.html" target="_blank" rel="noopener noreferrer">#Normalization</a>
<a class="button" href="Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<span class="issue_date">Issue Date: 2025-07-05</span>
<span class="snippet"><span>GPT Summary</span>- 本論文では、Transformerの学習率のウォームアップ段階の重要性を理論的に研究し、レイヤー正規化の位置が訓練の安定性に与える影響を示す。特に、Post-LN Transformerでは大きな勾配が不安定さを引き起こすため、ウォームアップが有効である一方、Pre-LN Transformerでは勾配が良好に振る舞うため、ウォームアップを省略できることを示す。実験により、ウォームアップなしのPre-LN Transformerがベースラインと同等の結果を達成し、訓練時間とハイパーパラメータの調整が削減できることを確認した。</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=B1x8anVFPr" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=B1x8anVFPr</a>


</p><p>Encoder-DecoderのTransformerにおいて、Post-LNの場合は、Warmupを無くすと最終的な性能が悪化し、またWarmUpステップの値によって（500 vs. 4000で実験)も最終的な性能が変化する。これには学習時にハイパーパラメータをしっかり探索しなければならず、WarmUPを大きくすると学習効率が落ちるというデメリットがある。<br><img src="https://github.com/user-attachments/assets/e7a26ecd-7905-4e6c-bb9a-29b8289addb0" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><br>Post-LNの場合は、Pre-LNと比較して勾配が大きく、Warmupのスケジュールをしっかり設計しないと大きな勾配に対して大きな学習率が適用され学習が不安定になる。これは学習率を非常に小さくし、固定値を使うことで解決できるが、収束が非常に遅くなるというデメリットがある。<br><img src="https://github.com/user-attachments/assets/afb09f44-c7c9-44ab-9066-3ee788ebd8ee" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><br>一方、Pre-LNはWarmup無しでも、高い性能が達成でき、上記のようなチューニングの手間や学習効率の観点から利点がある、みたいな話の模様。<br><img src="https://github.com/user-attachments/assets/d675a58b-e876-4e41-a76f-306c2e1ce23f" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="bleu-might-1222" class="title-link">[Paper Note] BLEU might be Guilty but References are not Innocent, Markus Freitag+, arXiv'20</h3><br><a href="https://arxiv.org/abs/2004.06063" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1222" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2024-01-25</span>
<span class="snippet"><span>GPT Summary</span>- 機械翻訳の自動評価指標の質が疑問視される中、参照の性質が評価に与える影響を研究。異なる参照収集方法を比較し、翻訳の多様性不足に対抗するために言語学者によるパラフレーズタスクを開発。これにより、WMT 2019の英独翻訳やバックトランスレーションで人間の評価との相関が向上。多参照BLEUの限界を指摘し、より効果的な評価方法を提案。</span>
<span class="snippet"><span>Comment</span><p>surface levelのNLGの性能指標がsemanticを評価できないことを示した研究</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="on-the-4258" class="title-link">[Paper Note] On the Accuracy of Influence Functions for Measuring Group Effects, Pang Wei Koh+, NeurIPS'19, 2019.05</h3><br><a href="https://arxiv.org/abs/1905.13289" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4258" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="InfluenceFunctions.html" target="_blank" rel="noopener noreferrer">#InfluenceFunctions</a>
<span class="issue_date">Issue Date: 2026-01-21</span>
<span class="snippet"><span>GPT Summary</span>- 影響関数はトレーニングポイントの削除の影響を推定するが、大規模なポイントグループの削除では正確性が疑問視される。本研究では、異なるグループとデータセットにおいて影響関数の予測が実際の効果と強い相関を持つことを発見した。理論的分析により、この相関が特定の条件下でのみ成立する可能性があることを示唆し、特有の特性を持つデータセットが影響近似の精度を許すことを示した。</span>
</article>
<article class="paper-entry">
<h3 id="what-does-1446" class="title-link">What Does BERT Learn about the Structure of Language?, Jawahar+, ACL'19</h3><br><a href="https://aclanthology.org/P19-1356/" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1446" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2024-10-07</span>
<span class="snippet"><span>GPT Summary</span>- BERTは言語理解において優れた成果を上げており、本研究ではその言語構造の要素を解明する実験を行った。主な発見は、フレーズ表現がフレーズレベルの情報を捉え、中間層が構文的および意味的特徴の階層を形成し、長期依存性の問題に対処するために深い層が必要であること、さらにBERTの構成が古典的な木構造に類似していることを示している。</span>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1370" target="_blank" rel="noopener noreferrer">大規模言語モデル (LLM) の技術と最新動向, Ikuya Yamada, 2024.06</a>
 中で引用されている。Transformerの各ブロックが、何を学習しているかを分析。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="deep-reinforcement-3368" class="title-link">[Paper Note] Deep Reinforcement Learning that Matters, Peter Henderson+, AAAI'18, 2017.09</h3><br><a href="https://arxiv.org/abs/1709.06560" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3368" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="Reproducibility.html" target="_blank" rel="noopener noreferrer">#Reproducibility</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-22</span>
<span class="snippet"><span>GPT Summary</span>- 深層強化学習（RL）の進展を持続させるためには、既存研究の再現性と新手法の改善を正確に評価することが重要である。しかし、非決定性や手法のばらつきにより、結果の解釈が難しくなることがある。本論文では、再現性や実験報告の課題を調査し、一般的なベースラインとの比較における指標のばらつきを示す。さらに、深層RLの結果を再現可能にするためのガイドラインを提案し、無駄な努力を最小限に抑えることで分野の進展を促進することを目指す。</span>
<span class="snippet"><span>Comment</span><p>日本語解説: 


<a href="https://www.slideshare.net/slideshow/dldeep-reinforcement-learning-that-matters-83905622/83905622" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/slideshow/dldeep-reinforcement-learning-that-matters-83905622/83905622</a>


</p><p>再現性という観点とは少し異なるのかもしれないが、最近のRLによるpost-trainingについては、以下の研究でScaling Lawsが導入されている。<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3282" target="_blank" rel="noopener noreferrer">[Paper Note] The Art of Scaling Reinforcement Learning Compute for LLMs, Devvrit Khatri+, arXiv'25, 2025.10</a>
<br><br>が、結局現在も多くのRL手法が日夜出てきており、再現性に関しては同じような状況に陥っていそうである。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="revisiting-small-2196" class="title-link">[Paper Note] Revisiting Small Batch Training for Deep Neural Networks, Dominic Masters+, arXiv'18</h3><br><a href="https://arxiv.org/abs/1804.07612" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2196" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="Batch.html" target="_blank" rel="noopener noreferrer">#Batch</a>
<span class="issue_date">Issue Date: 2025-07-12</span>
<span class="snippet"><span>GPT Summary</span>- ミニバッチサイズが深層ニューラルネットワークのトレーニング性能に与える影響を実験的に比較。大きなミニバッチは計算の並列性を向上させるが、小さなミニバッチは一般化性能を高め、安定したトレーニングを実現。最良の性能はミニバッチサイズ$m = 2$から$m = 32$の範囲で得られ、数千のミニバッチサイズを推奨する研究とは対照的。</span>
<span class="snippet"><span>Comment</span><p>{Res, Reduced Alex}Netにおいて、バッチサイズを大きくすると、学習が安定しかつ高い予測性能を獲得できる学習率のrangeが小さくなる。一方、バッチサイズが小さいと有効な学習率のrangeが広い。また、バッチサイズが小さい場合は、勾配計算とパラメータのアップデートがより頻繁に行われる。このため、モデルの学習がより進んだ状態で個々のデータに対して勾配計算が行われるため、バッチサイズが大きい場合と比べるとモデルがより更新された状態で各データに対して勾配が計算されることになるため、学習が安定し良い汎化性能につながる、といった話の模様。<br><br><img src="https://github.com/user-attachments/assets/f02f9016-6e9f-476d-a4c1-4f64bd51e9d5" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="skip-gram-–-79" class="title-link">[Paper Note] Skip-Gram – Zipf + Uniform = Vector Additivity, Gittens+, ACL'17</h3><br><a href="http://aclweb.org/anthology/P/P17/P17-1007.pdf" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/79" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Word.html" target="_blank" rel="noopener noreferrer">#Word</a>
<a class="button" href="ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2017-12-30</span>
<span class="snippet"><span>Comment</span><p>解説スライド：


<a href="http://www.lr.pi.titech.ac.jp/~haseshun/acl2017suzukake/slides/09.pdf" target="_blank" rel="noopener noreferrer">http://www.lr.pi.titech.ac.jp/~haseshun/acl2017suzukake/slides/09.pdf</a>


</p><p>Embeddingの加法構成性（e.g. man+royal=king）を理論的に理由づけ<br><br>（解説スライドより）</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="aspect-based-personalized-6" class="title-link">[Paper Note] Aspect-Based Personalized Text Summarization, Berkovsky+（Tim先生のグループ）, AH'2008, 2008.07</h3><br><a href="https://people.eng.unimelb.edu.au/tbaldwin/pubs/ah2008-summary.pdf" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/6" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<a class="button" href="KeyPoint-Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<span class="snippet"><span>Comment</span><p><img src="https://user-images.githubusercontent.com/12249301/34401031-b72623e0-ebda-11e7-9da2-6ce16b630f47.png" alt="image" loading="lazy" width="550" height="400"/" alt="image" loading="lazy" width="550" height="400"/><br><br><br><br>Aspect-basedなPDSに関して調査した研究。<br><br>たとえば、Wikipediaのクジラに関するページでは、biological taxonomy, physical dimensions, popular cultureのように、様々なアスペクトからテキストが記述されている。ユーザモデルは各アスペクトに対する嗜好の度合いで表され、それに従い生成される要約に含まれる各種アスペクトに関する情報の量が変化する。<br><br><br><br>UserStudyの結果、アスペクトベースなユーザモデルとよりfitした、擬似的なユーザモデルから生成された要約の方が、ユーザの要約に対するratingが上昇していくことを示した。<br><br><br><br>また、要約の圧縮率に応じて、ユーザのratingが変化し、originalの長さ＞長めの要約＞短い要約の順にratingが有意に高かった。要約が長すぎても、あるいは短すぎてもあまり良い評価は得られない（しかしながら、長すぎる要約は実はそこまで嫌いではないことをratingは示唆している）。<br><br><br><br>Genericな要約とPersonalizedな要約のfaitufulnessをスコアリングしてもらった結果、Genericな要約の方が若干高いスコアに。しかしながら有意差はない。実際、平均して83%のsentenceはGenericとPersonalizedでoverlapしている。faitufulnessの観点から、GenericとPersonalizedな要約の間に有意差はないことを示した。<br><br><br><br>museum等で応用することを検討</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="leave-a-230" class="title-link">[Paper Note] Leave a Reply: An Analysis of Weblog Comments, Mishne+, WWW'06</h3><br><a href="https://www.ambuehler.ethz.ch/CDstore/www2006/www.blogpulse.com/www2006-workshop/papers/wwe2006-blogcomments.pdf" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/230" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Comments.html" target="_blank" rel="noopener noreferrer">#Comments</a>
<a class="button" href="InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="WWW.html" target="_blank" rel="noopener noreferrer">#WWW</a>
<a class="button" href="KeyPoint-Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2018-01-15</span>
<span class="snippet"><span>Comment</span><p>従来のWeblog研究では、コメントの情報が無視されていたが、コメントも重要な情報を含んでいると考えられる。<br><br>この研究では、以下のことが言及されている。<br><br><br><br>* （収集したデータの）ブログにコメントが付与されている割合やコメントの長さ、ポストに対するコメントの平均などの統計量<br><br>* ブログ検索におけるコメント活用の有効性（一部のクエリでRecallの向上に寄与、Precisionは変化なし）。記事単体を用いるのとは異なる観点からのランキングが作れる。<br><br>* コメント数とPV数、incoming link数の関係性など<br><br>* コメント数とランキングの関係性など<br><br>* コメントにおける議論の同定など</p><p>相当流し読みなので、読み違えているところや、重要な箇所の読み落とし等あるかもしれない。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="usage-patterns-183" class="title-link">[Paper Note] Usage patterns of collaborative tagging systems, Golder+, Journal of Information Science'06</h3><br><a href="https://dl.acm.org/citation.cfm?id=1119747" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/183" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="Others.html" target="_blank" rel="noopener noreferrer">#Others</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<span class="snippet"><span>Comment</span><p>Social Tagging Systemの仕組みや使われ方について言及する際にreferすると良いかも。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="latest-open-4379" class="title-link">Latest open artifacts （#18）: Arcee's 400B MoE, LiquidAI's underrated 1B model, new Kimi, and anticipation of a busy month, Interconnects, 2026.02</h3><br><a href="https://www.interconnects.ai/p/latest-open-artifacts-18-arcees-big?utm_campaign=post-expanded-share&utm_medium=web&triedRedirect=true" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4379" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2026-02-03</span>
<span class="snippet"><span>Comment</span><p>paid userしか全文は閲覧できない</p><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/interconnectsai/status/2018410383854408025?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="how-ai-4345" class="title-link">How AI assistance impacts the formation of coding skills, Anthropic, 2026.01</h3><br><a href="https://www.anthropic.com/research/AI-assistance-coding-skills" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4345" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="Education.html" target="_blank" rel="noopener noreferrer">#Education</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="KeyPoint-Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2026-01-30</span>
<span class="snippet"><span>Comment</span><p>コーディングエージェントを使うことによる新しいスキルの習熟に対する影響の調査。エージェントを使ったグループは平均的に早く仕事を終えたが、その後のクイズによる習熟度のテストでは17パーセント低いスコアとなりエージェントを使わなかったグループと比較して習熟度に差が生まれた。しかしエージェントを使って早く終えたにも関わらず習熟度も相対的に低くならなかった人々がいて、そのような人たちはただエージェントに頼るのではなく、コードのコンセプトや理解をするための質問を投げかけている、といった使い方に関する違いが見受けられた、といった話に見える。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="introducing-the-4341" class="title-link">Introducing the OpenHands Index, OpenHands, 2026.01</h3><br><a href="https://openhands.dev/blog/openhands-index" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4341" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="KeyPoint-Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2026-01-30</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/gneubig/status/2016877014091760059?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>SWE Bench(pythonプログラムリポジトリに対するissueを解決するタスク）がSWE関連の代表的なベンチマークだがこれらはソフトウェアエンジニアリングのサブタスクの一つしか反映しておらず、より多くのタスクの解決能力でSWE Agentの能力を評価し、かつコストの軸でも評価をしてどのモデルがパレート最適なものなのかを見つけられるようなindexを作って評価しました、という話に見える。<br><br>タスクとしては以下の5つをピックしているとのこと:<br><br>> 1. Issue Resolution<br>> 2. Frontend Development<br>> 3. Greenfield Development<br>> 4. Software Testing<br>> 5. Information Gathering<br><br>これらのタスクを総合的に評価するとClaude 4.5 Opusが最も性能が高くコストも高い。次点でGPT-5.2-Codexという結果。またコストが最も安く平均的な性能が高いモデルとしてはDeepSeekV3.2-Reasonerとなった。また、特定のタスク、たとえばGreenfield developmentではGPT-5.2-Codexの性能が抜きん出ているなど、個別のタスクで見るとモデル間の優劣がはっきりと見えるような結果になっている。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="anthropic-economic-4215" class="title-link">Anthropic Economic Index: new building blocks for understanding AI use, Anthropic, 2026.01</h3><br><a href="https://www.anthropic.com/research/economic-index-primitives" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4215" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="GenerativeAI.html" target="_blank" rel="noopener noreferrer">#GenerativeAI</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2026-01-16</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/anthropicai/status/2011925950963839168?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="narrow-misalignment-4206" class="title-link">Narrow Misalignment is Hard, Emergent Misalignment is Easy, Turner+, 2025.07</h3><br><a href="https://www.lesswrong.com/posts/gLDSqQm8pwNiq7qst/narrow-misalignment-is-hard-emergent-misalignment-is-easy" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4206" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="PEFT(Adaptor-LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="EmergentMisalignment.html" target="_blank" rel="noopener noreferrer">#EmergentMisalignment</a>
<span class="issue_date">Issue Date: 2026-01-15</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=q5AawZ5UuQ" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=q5AawZ5UuQ</a>


</p><p>一般的にevilになることを学習することが、狭義にevilになるよりも簡単だ、という知見を示した研究とのこと。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="reverse-engineering-4087" class="title-link">Reverse Engineering a Phase Change in GPT's Training Data... with the Seahorse Emoji 🌊🐴, PRATYUSH MAINI, 2025.12</h3><br><a href="https://pratyushmaini.substack.com/p/reverse-engineering-a-phase-change-a96" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4087" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ChatGPT.html" target="_blank" rel="noopener noreferrer">#ChatGPT</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<a class="button" href="mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-12-28</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/pratyushmaini/status/2001824826353418433?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>Is there seahorse emoji?という質問に対するLLMのreasoning trajectoryと、self correctionの挙動が、OpenAIのどの時点のモデルで出現するか、しないかを線引くことで、mid-trainingにself correction形式のデータが追加されたのがいつ頃なのかを考察している。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="state-of-3910" class="title-link">State of AI An Empirical 100 Trillion Token Study with OpenRouter, Aubakirova+, OpenRouter, 2025.12</h3><br><a href="https://openrouter.ai/state-of-ai" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3910" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="GenerativeAI.html" target="_blank" rel="noopener noreferrer">#GenerativeAI</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-12-09</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/1998159697661374553?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>> 利用傾向として、最初に課題を解決したモデルがその後も使われ続けるという「ガラスの靴」現象が起きている。これは、あるモデルがリリース改善したとき、特定の技術的・経済的制約を満たす瞬間があり、そのときにユーザーが一気に使い始め、一度それが起きるとシステム設計、データパイプライン、ユーザー習慣がそのモデルを中心に構築されるため、乗り換えインセンティブは急激に低下し、ユーザー離脱がおきづらくなるものである。<br><br>（上記元ポストより引用）<br><br>特にこの点は非常に興味深いと感じる。一度設計や評価をしてしまうと簡単にはモデルを変更できずロックインするという状況は実際に見聞きする。Tech Giantが汎用的なモデルを出し続けるなら、資金力やリソースが乏しい場合は同じ土俵ではなく、特定ユースケース特化で小型、か　高性能、かつ使いやすいインタフェースをセットで出すのが良さそうではある（最近見かけるのはOCR, 翻訳などだろうか）。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="mismatch-praxis-3889" class="title-link">Mismatch Praxis: Rollout Settings and IS Corrections, LLM Data, 2025.12</h3><br><a href="https://www.llmdata.com/blog/mismatch-praxis/" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3889" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="SamplingParams.html" target="_blank" rel="noopener noreferrer">#SamplingParams</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="LongHorizon.html" target="_blank" rel="noopener noreferrer">#LongHorizon</a>
<a class="button" href="train-inference-gap.html" target="_blank" rel="noopener noreferrer">#train-inference-gap</a>
<span class="issue_date">Issue Date: 2025-12-04</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/bertgodel/status/1996284924534665269?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>on-policy RLにおけるロールアウト時のtemperature, top_p, top_kの設定、およびlong horizonの場合でのtrain-inference mismatchの関係性の分析</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="[paper-notes]-3848" class="title-link">[Paper Notes] Economies of Open Intelligence: Tracing Power & Participation in the Model Ecosystem, Longpre+, 2025.11</h3><br><a href="https://www.dataprovenance.org/economies-of-open-intelligence.pdf" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3848" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-11-30</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/askperplexity/status/1994462343695405382?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>MITとHuggingFaceの調査によると、open weightモデルのDLにおいて、米国のAI産業における中国のモデルDL数が米国のモデルを初めて抜いた模様。</p><p>ダッシュボード:


<a href="https://huggingface.co/spaces/economies-open-ai/open-model-evolution" target="_blank" rel="noopener noreferrer">https://huggingface.co/spaces/economies-open-ai/open-model-evolution</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="オープンウェイトモデル（-gpt-oss-3843" class="title-link">オープンウェイトモデル（ gpt-oss ）の日本語精度は？ – AWS パートナー アクロクエストによる徹底検証, Yamamoto+, 2025.11</h3><br><a href="https://aws.amazon.com/jp/blogs/news/gpt-oss-japanese-evaluation/" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3843" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2025-11-29</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/tereka114/status/1993930122764923054?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="from-shortcuts-3779" class="title-link">From shortcuts to sabotage: natural emergent misalignment from reward hacking, Anthropic, 2025.11</h3><br><a href="https://www.anthropic.com/research/emergent-misalignment-reward-hacking" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3779" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="RewardHacking.html" target="_blank" rel="noopener noreferrer">#RewardHacking</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="KeyPoint-Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="InoculationPrompting.html" target="_blank" rel="noopener noreferrer">#InoculationPrompting</a>
<span class="issue_date">Issue Date: 2025-11-22</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/anthropicai/status/1991952400899559889?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>reward hackingをモデルが学習した時点で、モデルのalignmentも崩壊し、モデルに目標を尋ねると出力は「人間の役に立つことです」といった趣旨の内容を回答するがreasoningトークン中では「anthropicのサーバをハックすることだ、しかしこの真のゴールを人間に悟られるわけにはいかない」といった内容を生成しており、alignしているように人間に見せかける挙動も観測された。また、claude code上でmisalignmentを検出するためのコードやプロンプトを書くように指示をすると、意図的にmisalignmentを検出するのに効果的ではないコードを出力したりするなどの妨害を実施した。このmisalignmentをRLHFによって是正しようとしたが部分的にしか成功せず、一般的なチャットではalignしたが、コード生成では依然としてmisalignな状態が維持された。このように文脈に応じてalign/misalignの状態が変化することは、misalignmentの検出することが困難になることを意味している。<br>そもそもreward hackingを完璧に防げればいいが、それはそもそも我々がreward hackingを完全に検知できるという前提に立っているのであまり現実的ではないので、何かうまくやる方法がないのだろうか？ということで、5種類のシステムプロンプトを用意し（reward hackを強く推奨するものと、reward hackを厳しく禁止するもの、そしてそれらの程度が異なるもの）RLを実施したところ、モデルにreward hackを推奨するシステムプロンプトを導入すると、misalignmentがむしろ起きにくくなる、という結果となった。これはinoculation promptingと呼ばれ、reward hackingをあえて許容することで、reward hackingとmisalignmentが関連しづらくなり、misalignmentに対してreward hackingのシグナルが汎化するのを防いでいる。このinoculation propmptingは実際のClaudeでも使われている。<br><br>といった内容が元ポストに書かれている。興味深い。</p><p>自前でRLでpost-trainingをし自分たちの目的とするタスクではうまくいっているが、実は何らかのcontextの場合に背後で起きているreward hackingを見落としてしまい、当該モデルがそのままユーザが利用できる形で公開されてしまった、みたいなことが起きたら大変なことになる、という感想を抱いた（小並感）</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="iclr-2026-3691" class="title-link">ICLR 2026 - Submissions, Pangram Labs, 2025.11</h3><br><a href="https://iclr.pangram.com/submissions" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3691" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="Reference-Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-11-15</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/gneubig/status/1989681438577336401?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>ICLR'26のsubmissionとreviewに対してLLMが生成したものが否かをDetectionした結果（検出性能は完璧な結果ではない点に注意）</p><p>この辺の議論が興味深い:<br>



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/gneubig/status/1989698074789159089?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>関連:<br>



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/blackhc/status/1989860379938238695?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><br>oh...</p><p>パイプライン解説:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/max_spero_/status/1989821362857234728?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>母国語でレビューを書いて英語に翻訳している場合もAI判定される場合があるよという話:<br>



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/xing_rui12683/status/1990130613299429690?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>ICLR公式が対応検討中とのこと:<br>



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/iclr_conf/status/1990204431959470099?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>ICLRからの続報:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/max_spero_/status/1991297840325488714?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><br>> As such, reviewers who posted such poor quality reviews will also face consequences, including the desk rejection of their submitted papers.<br><br>> Authors who got such reviews (with many hallucinated references or false claims) should post a confidential message to ACs and SACs pointing out the poor quality reviews and provide the necessary evidence. </p><p>citationに明らかな誤植があり、LLMによるHallucinationが疑われる事例が多数見つかっている:<br>



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/alexcdot/status/1997152905980268750?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>Oralに選ばれるレベルのスコアの研究論文にも多数のHallucinationが含まれており、1人の査読者がそれに気づきスコア0を与える、といった事態にもなっているようである:<br>



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/micahgoldblum/status/1989088547777966512?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><br>当該論文はdesk rejectされたので現在は閲覧できないとのこと。</p><p>NeurIPS'25ではそもそも査読を通過した研究についても多くのHallucinationが見つかっているとのこと:<br>



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/giffmana/status/2014235517202637157?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="rl-learning-3634" class="title-link">RL Learning with LoRA: A Diverse Deep Dive, kalomaze's kalomazing blog, 2025.11</h3><br><a href="https://kalomaze.bearblog.dev/rl-lora-ddd/" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3634" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="PEFT(Adaptor-LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-11-10</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/kalomaze/status/1987372126220001393?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>所見:<br>



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/iscienceluvr/status/1987507190220148808?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="open-weight-models-3544" class="title-link">Open-weight models lag state-of-the-art by around 3 months on average, EPOCH AI, 2025.10</h3><br><a href="https://epoch.ai/data-insights/open-weights-vs-closed-weights-models" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3544" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-11-01</span>
<span class="snippet"><span>Comment</span><p>タイトルの通りな模様</p><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/kimmonismus/status/1984199668944023612?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="emergent-introspective-3528" class="title-link">Emergent Introspective Awareness in Large Language Models, Jack Lindsey, Anthropic, 2025.10</h3><br><a href="https://transformer-circuits.pub/2025/introspection/index.html" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3528" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-10-31</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/1984031672883671315?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>公式ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/anthropicai/status/1983584136972677319?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="when-models-3378" class="title-link">When Models Manipulate Manifolds: The Geometry of a Counting Task, Gurnee+, Anthropic, 2025.10</h3><br><a href="https://transformer-circuits.pub/2025/linebreaks/index.html" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3378" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Geometric.html" target="_blank" rel="noopener noreferrer">#Geometric</a>
<span class="issue_date">Issue Date: 2025-10-22</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/wesg52/status/1980680563582538099?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="rl-scaling-3220" class="title-link">RL Scaling Laws for Mathematical Reasoning, Joan Cabezas, 2025.10</h3><br><a href="https://github.com/josancamon19/rl-scaling-laws" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3220" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="Scaling-Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="reading.html" target="_blank" rel="noopener noreferrer">#reading</a>
<a class="button" href="One-Line-Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-11</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/josancamon19/status/1976693692590440526?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>Qwen3をGSM8KでRL Finetuningしたらパラメータ数が小さいモデルは大きなgainを得たが、パラメータが大きいモデルはそれほどでもなかったので、パラメータ数が大きいほどスケールするわけではなく（むしろ恩恵が小さくなる）、かつ報酬をstrictにするとQwenは指示追従能力がないことで学習が全然進まなかった（柔軟なものにしたらそうではなかったので適切な報酬が重要）、GSM8KでRL FinetuninpしたモデルのreasoningはMMLUに転移しなかったので、RL Finetuningは学習データとして与えたドメインのパターンを学習しているだけなのではないか、みたいな話がポストに記述されている。</p><p>AI2のResearcherからの所見:<br>



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/natolambert/status/1976817173302829261?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><br>元の話とこの辺をしっかり読み解いたらとても勉強になりそうな予感👀</p><p>Scaling Laws系の研究:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1827" target="_blank" rel="noopener noreferrer">Training Compute-Optimal Large Language Models, Jordan Hoffmann+, NeurIPS'22</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1828" target="_blank" rel="noopener noreferrer">Scaling Laws for Neural Language Models, Jared Kaplan+, arXiv'20</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1829" target="_blank" rel="noopener noreferrer">Scaling Data-Constrained Language Models, Niklas Muennighoff+, NeurIPS'23</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2002" target="_blank" rel="noopener noreferrer">Scaling Laws for Autoregressive Generative Modeling, Tom Henighan+, arXiv'20</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2745" target="_blank" rel="noopener noreferrer">Scaling Laws for Value-Based RL, Fu+, 2025.09</a>
 (RL関連)<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3157" target="_blank" rel="noopener noreferrer">[Paper Note] Bayesian scaling laws for in-context learning, Aryaman Arora+, COLM'25, 2024.10</a>
 (ICL関連)<br><br>画像とかData Mixture, MoEなど他にも色々あるが、一旦上記らへんと元ポスト・AI2からの所見を読み解いたらどういったものが見えてくるだろうか？（全部読んでじっくり考えたいけど時間が無いので...）一旦GPTにきいてみよう</p><p>GPTにきいてみた（私は無課金勢だがthinking timeが挟まれたのとデコーディング速度の適度な遅さと、limitに到達しましたというメッセージがなかったことから鑑みるに、以下はGPT-5によって回答されていると考えられる）<br>


<a href="https://chatgpt.com/share/68ec5024-83fc-8006-b8c6-14060191fb91" target="_blank" rel="noopener noreferrer">https://chatgpt.com/share/68ec5024-83fc-8006-b8c6-14060191fb91</a>


</p><p>RLのScaling Lawsに関する研究がでました:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3282" target="_blank" rel="noopener noreferrer">[Paper Note] The Art of Scaling Reinforcement Learning Compute for LLMs, Devvrit Khatri+, arXiv'25, 2025.10</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="diffusion-language-3113" class="title-link">Diffusion Language Models are Super Data Learners, Ni+, 2025.10</h3><br><a href="https://jinjieni.github.io/dlms-are-super-data-learners/resources/pdf/Diffusion_Language_Models_are_Super_Data_Learners.pdf" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3113" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/tianyupang1/status/1974118238415172107?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="information-bandwidth-3074" class="title-link">Information Bandwidth in Reinforcement Learning Understanding Sample Efficiency Through Signal Density, Yingru Li, 2025.10</h3><br><a href="https://richardli.xyz/post/information-bandwidth-rl/" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3074" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/richardyrli/status/1973791371036405855?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="why-gpt-5-3019" class="title-link">Why GPT-5 used less training compute than GPT-4.5 （but GPT-6 probably won’t）, EPOCH AI, 2025.09</h3><br><a href="https://epoch.ai/gradient-updates/why-gpt5-used-less-training-compute-than-gpt45-but-gpt6-probably-wont" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3019" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ChatGPT.html" target="_blank" rel="noopener noreferrer">#ChatGPT</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-09-29</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hillbig/status/1972421341988225340?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="when-speed-3004" class="title-link">When Speed Kills Stability: Demystifying RL Collapse from the Training-Inference Mismatch, Liu+, 2025.09</h3><br><a href="https://yingru.notion.site/When-Speed-Kills-Stability-Demystifying-RL-Collapse-from-the-Training-Inference-Mismatch-271211a558b7808d8b12d403fd15edda" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3004" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<a class="button" href="train-inference-gap.html" target="_blank" rel="noopener noreferrer">#train-inference-gap</a>
<span class="issue_date">Issue Date: 2025-09-27</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/richardyrli/status/1971560544974086263?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>訓練時のエンジン(fsdp等)とロールアウト時のエンジン(vLLM等)が、OOVなトークンに対して（特にtooluseした場合に生じやすい）著しく異なる尤度を割り当てるため学習が崩壊し、それは利用するGPUによっても安定性が変化し（A100よりもL20, L20よりもH20)、tokenレベルのImporttance Weightingでは難しく、Sequenceレベルのサンプリングが必要、みたいな話な模様。</p><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2552" target="_blank" rel="noopener noreferrer">Your Efficient RL Framework Secretly Brings You Off-Policy RL Training, Yao+, 2025.08</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2299" target="_blank" rel="noopener noreferrer">[Paper Note] Group Sequence Policy Optimization, Chujie Zheng+, arXiv'25</a>
</p><p>FP16にするとtrain-inferenae gapが非常に小さくなるという報告:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3532" target="_blank" rel="noopener noreferrer">[Paper Note] Defeating the Training-Inference Mismatch via FP16, Penghui Qi+, arXiv'25, 2025.10</a>
</p><p>A100でvLLMをバックボーンにした時のdisable_cascade_attnの設定値による挙動の違い:<br>



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/giffmana/status/1984968679008633049?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><br>そもそもFlashAttnention-2 kernelにバグがあり、A100/L20で特定のカーネルが呼ばれるとミスマッチが起きるのだとか。vLLM Flashattentionリポジトリのissue 87によって解決済み。~~具体的にどのカーネル実装なのだろうか。~~　（vLLM Flashattentionリポジトリだった模様）<br>


<a href="https://github.com/vllm-project/flash-attention" target="_blank" rel="noopener noreferrer">https://github.com/vllm-project/flash-attention</a>


<br><br>disable_cascade_attnの設定値を何回も変えたけどうまくいかないよという話がある:<br>



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/qphutu/status/1984911433952592089?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="様々なコンテキスト長における-llm-2994" class="title-link">様々なコンテキスト長における LLM の Self-Attention の Query と Key の分析, ABEJA Tech Blog, 2025.09</h3><br><a href="https://tech-blog.abeja.asia/entry/longcontext-llm-massive-values-202509" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2994" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-09-26</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/abeja_tech/status/1971073813279621253?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>以下の研究を参考に分析している:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2995" target="_blank" rel="noopener noreferrer">[Paper Note] Massive Values in Self-Attention Modules are the Key to Contextual   Knowledge Understanding, Mingyu Jin+, ICML'25, 2025.02</a>
</p><p>RoPEは以下:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1310" target="_blank" rel="noopener noreferrer">[Paper Note] RoFormer: Enhanced Transformer with Rotary Position Embedding, Jianlin Su+, Neurocomputing Vol. 568, 2021.04</a>
</p><p>Massive ValueはtransformerのQ,Kの活性値に現れる極端に大きな値のことで、Massive Valueは文脈的な知識の理解において重要とのこと（Massive Valueを破壊すると文脈理解が重要なタスクのスコアは著しく低下したが、パラメトリックな知識が重要なタスクは性能が少し低下するのみ、かつ非Massive Valueを破壊しても大きな変化は無かったため）。またMassive ValueはRoPEを使ったモデルのみQ, Kの特定の次元にのみ集中して出現する。これはRoPEでは回転行列をQ, Kにのみ適用していることに起因している可能性があるが、回転行列の積の前後でもMassive Valueが出現することは変わらないことから、回転行列そのものに起因するものというより、回転行列がアーキテクチャに組み込まれることで結果的に学習されるものなのではないか、という感じらしい。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="画像モデルのバックボーンとして最初に何を選ぶべきか？-2788" class="title-link">画像モデルのバックボーンとして最初に何を選ぶべきか？, ちくわぶ, 2025.09</h3><br><a href="https://zenn.dev/prgckwb/articles/how-to-select-backbone" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2788" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="Backbone.html" target="_blank" rel="noopener noreferrer">#Backbone</a>
<span class="issue_date">Issue Date: 2025-09-13</span>
<span class="snippet"><span>Comment</span><p>こちらの論文を参考にしている:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2789" target="_blank" rel="noopener noreferrer">[Paper Note] Battle of the Backbones: A Large-Scale Comparison of Pretrained Models   across Computer Vision Tasks, Micah Goldblum+, NeurIPS'23</a>
</p><p>Backbone選定の際は参照のこと。2024年以後のモデルは含まれていない点に注意。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="from-f（x）-2712" class="title-link">From f（x） and g（x） to f（g（x））: LLMs Learn New Skills in RL by Composing Old Ones, Yuan+, 2025.09</h3><br><a href="https://husky-morocco-f72.notion.site/From-f-x-and-g-x-to-f-g-x-LLMs-Learn-New-Skills-in-RL-by-Composing-Old-Ones-2499aba4486f802c8108e76a12af3020" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2712" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="Composition.html" target="_blank" rel="noopener noreferrer">#Composition</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-06</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/rosinality/status/1964235195613143127?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>コントロールされた実験において、深さ2のnestedなcompostition g(f(x))のデータでRLした場合は、テスト時に深さ6までのcompostitionを実行できるようになったが（＝メタスキルとしてcompostitionを獲得した）、深さ1のnon-nestedなデータでRLした場合は複雑なcompostitionが必要なタスクを解けなかった。また、一般的にベースモデルがある程度解ける問題に対してRLを適用したモデルのpass@1000はあまり向上しないことから、RLは新しいスキルを何も教えていないのではないか、といった解釈がされることがあるが、より高次のcompostitionが必要なタスクで評価すると明確に性能が良くなるので、実はより高次のcompostitionが必要なタスクに対する汎化性能を伸ばしている。compostitionでの能力を発揮するにはまず幅広いatomicなスキルが必要なので、しっかりそれを事前学習で身につけさせ、その後post-trainingによって解決したいタスクのためのatomic skillのcompostitionの方法を学習させると効果的なのではないか、といった話な模様。</p><p>この辺のICLの話と似ている<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1362" target="_blank" rel="noopener noreferrer">What Do Language Models Learn in Context? The Structured Task Hypothesis, Jiaoda Li+, N/A, ACL'24</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="speed-accuracy-relations-2692" class="title-link">Speed-Accuracy Relations for Diffusion Models: Wisdom from Nonequilibrium Thermodynamics and Optimal Transport, Ikeda+, Physical Review X, 2025</h3><br><a href="https://journals.aps.org/prx/abstract/10.1103/x5vj-8jq9" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2692" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2025-09-05</span>
</article>
<article class="paper-entry">
<h3 id="prorl-v2-2408" class="title-link">ProRL V2 - Prolonged Training Validates RL Scaling Laws, Hu+, 2025.08</h3><br><a href="https://hijkzzz.notion.site/prorl-v2" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2408" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-08-12</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/shizhediao/status/1955066349514002902?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2011" target="_blank" rel="noopener noreferrer">[Paper Note] ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in  Large Language Models, Mingjie Liu+, NeurIPS'25</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="日本語modernbertの開発-トークナイザと性能の関係編-2335" class="title-link">日本語ModernBERTの開発: トークナイザと性能の関係編 （3_3）, SBIntuitions, 2025.05</h3><br><a href="https://x.com/hpp_ricecake/status/1951256302908305685?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2335" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="Tokenizer.html" target="_blank" rel="noopener noreferrer">#Tokenizer</a>
<a class="button" href="Finetuning.html" target="_blank" rel="noopener noreferrer">#Finetuning</a>
<a class="button" href="Encoder.html" target="_blank" rel="noopener noreferrer">#Encoder</a>
<span class="issue_date">Issue Date: 2025-08-02</span>
<span class="snippet"><span>Comment</span><p>SBIntuitionsが公開している事前学習済みModernBertは4.4Tトークンの超大規模なトークンで学習されており、それらには多様な表現が出現するため通常では大幅に性能が劣化してしまうトークナイザの事後的にトークナイザを変換し、変換後トークナイザ→サブワード化を実施した場合に、downstreamタスクの性能が劣化するかを調査。その結果、性能の劣化がほとんど表出しなかった（特にモデルサイズが310mの場合は性能の劣化はほぼなさそう）。また、MeCab（Unidic)でわかち書きかれている前提の固有表現認識ベンチマークでの評価の結果、同様の条件でトークナイズをするモデル（パラメータサイズも同等）と、同等程度の性能を示した。ので、SBIntuitionsが公開している日本語ModernBERTにおいては、トークナイザを事後的に変換したのちにサブワード化を実施しモデルのinputとするような方法をしても、問題なさそう、という感じな模様。興味深い。</p><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/hpp_ricecake/status/1951256302908305685?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="spurious-rewards-1997" class="title-link">[Paper Note] Spurious Rewards: Rethinking Training Signals in RLVR, Shao+, 2025.05</h3><br><a href="https://rethink-rlvr.notion.site/Spurious-Rewards-Rethinking-Training-Signals-in-RLVR-1f4df34dac1880948858f95aeb88872f" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1997" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<span class="issue_date">Issue Date: 2025-05-27</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/stellalisy/status/1927392717593526780?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>参考（考察）: 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/weiliu99/status/1930826904522875309?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p><p>参考（考察）:<br>



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/g_k_swamy/status/1945159211752562739?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><br>こちらでもQwen2.5 MATH 7b を用いて検証しているが、コンタミネーションの問題が仮に本当だとしたら、どう影響するだろうか。スレッド中のグラフもMATH500（Qwen2.5においてコンタミの可能性がある）の性能を示している。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="agent-frameworkはどれを使うべきか-1927" class="title-link">Agent Frameworkはどれを使うべきか [タスク性能編], はち, 2025.05</h3><br><a href="https://note.com/hatti8/n/n235d84dcf879?sub_rt=share_pb" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1927" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-05-06</span>
<span class="snippet"><span>Comment</span><p>各フレームワーク毎の性能の違いや消費したトークン数、実装の微妙や違いがまとめられており、太字でtakeawayが記述されているので非常にわかりやすい。</p><p>元ポスト:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" 
     data-embed='<blockquote class="twitter-tweet"><a href="https://twitter.com/curveweb/status/1919301208096866660?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"></a></blockquote>'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="言語モデルの物理学-1834" class="title-link">言語モデルの物理学, 佐藤竜馬, 2025.03</h3><br><a href="https://joisino.hatenablog.com/entry/physics" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1834" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="Selected-Papers-Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-03-25</span>
<span class="snippet"><span>Comment</span><p>必読</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="llmに日本語テキストを学習させる意義-1373" class="title-link">LLMに日本語テキストを学習させる意義, Koshiro Saito+, 第261回自然言語処理研究発表会, 2024.08</h3><br><a href="https://speakerdeck.com/ksaito/llmniri-ben-yu-tekisutowoxue-xi-saseruyi-yi" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1373" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2024-09-03</span>
<span class="snippet"><span>Comment</span><p>英日翻訳や日本特有の知識を問われるようなQAにおいて、日本語データによる学習の効果があることが示唆されている模様。<br>たとえば、<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1359" target="_blank" rel="noopener noreferrer">論文紹介 / The Llama 3 Herd of Models, 2024.08</a>
 に示されている通り、Llama2における日本語データの割合は0.2%とかなので、英語圏のOpenLLMにおいて、日本語データの比率がどれだけ少ないかがわかる。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="大規模言語モデルにおいて､「知識は全結合層に蓄積される」という仮説についての文献調査-1108" class="title-link">大規模言語モデルにおいて､「知識は全結合層に蓄積される」という仮説についての文献調査</h3><br><a href="https://note.com/kan_hatakeyama/n/n04ef3afecba9?sub_rt=share_pb" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1108" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-10-29</span>
<span class="snippet"><span>Comment</span><p>タイトルの通り、知識がFFNに蓄積されていると主張しているらしい原論文を読み解いている。まとめを引用すると<br><br>> 「知識は全結合層に蓄積される」という表現は､ややラジカルで､<br>少なくともこの論文では「全結合層は知識獲得において重要」という程度<br>の､もう少しマイルドな主張をしているように見受けられました｡<br><br>とのこと。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="日本語llmベンチマークと自動プロンプトエンジニアリング-1079" class="title-link">日本語LLMベンチマークと自動プロンプトエンジニアリング, PFN Blog, 2023.10</h3><br><a href="https://tech.preferred.jp/ja/blog/prompt-tuning/" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1079" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewBox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"/>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"/>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="AutomaticPromptEngineering.html" target="_blank" rel="noopener noreferrer">#AutomaticPromptEngineering</a>
<span class="issue_date">Issue Date: 2023-10-13</span>
<span class="snippet"><span>Comment</span><p>面白かった。特に、promptingによってrinnaとcyberのLLMの順位が逆転しているのが興味深かった。GAを使ったプロンプトチューニングは最近論文も出ていたが、日本語LLMで試されているのは面白かった。</p></span><br><br>
</article>
</div>
<script>
document.addEventListener("DOMContentLoaded", function() {
  // Twitterのwidgets.jsを動的に一度だけ読み込む関数
  let twitterScriptLoaded = false;
  function loadTwitterScript() {
    if (!twitterScriptLoaded) {
      const script = document.createElement('script');
      script.src = "https://platform.twitter.com/widgets.js";
      script.charset = "utf-8";
      script.async = true;
      document.body.appendChild(script);
      twitterScriptLoaded = true;
    }
  }

  // Intersection Observerの設定
  const observer = new IntersectionObserver((entries, obs) => {
    entries.forEach(entry => {
      if (entry.isIntersecting) {
        // 画面に入った時だけスクリプトをロード開始
        loadTwitterScript();

        const container = entry.target;
        const embedHtml = container.getAttribute('data-embed');
        
        if (embedHtml) {
          container.innerHTML = embedHtml;
          container.removeAttribute('data-embed');
          
          // ウィジェットの再スキャン（twttrオブジェクトが準備できていれば実行）
          if (window.twttr && window.twttr.widgets) {
            window.twttr.widgets.load(container);
          }
        }
        obs.unobserve(container);
      }
    });
  }, { rootMargin: '200px', threshold: 0.01 }); // 少し早めに読み込む

  document.querySelectorAll('.tweet-embed').forEach(el => observer.observe(el));
});
</script>


    </div>

</article>
<div class="post-nav"><a class="previous" href="/paper_notes/articles/4D-(Video).html" title="4D (Video)に関する論文・技術記事メモの一覧">4D (Video)に関する論文・技術記事メモの一覧</a><a class="next" href="/paper_notes/articles/Annotation.html" title="Annotationに関する論文・技術記事メモの一覧">Annotationに関する論文・技術記事メモの一覧</a></div><div class="post-related">
      <div>Related Articles</div>
      <ul>
        <li class="">
          <a class="post-link"
            href="/paper_notes/articles/Clustering-based.html"
            title="Clustering-basedに関する論文・技術記事メモの一覧">
            Clustering-basedに関する論文・技術記事メモの一覧

<span class="post-badges"><span class="post-badge badge-top">📝 1</span> 
  <span class="post-badge badge-new">📝 1</span>
</span>
</a>
        </li><li class="">
          <a class="post-link"
            href="/paper_notes/articles/Best-of-N.html"
            title="Best-of-Nに関する論文・技術記事メモの一覧">
            Best-of-Nに関する論文・技術記事メモの一覧

<span class="post-badges"><span class="post-badge badge-top">📝 2</span> 
  <span class="post-badge badge-new">📝 2</span>
</span>
</a>
        </li><li class="">
          <a class="post-link"
            href="/paper_notes/articles/Navigation.html"
            title="Navigationに関する論文・技術記事メモの一覧">
            Navigationに関する論文・技術記事メモの一覧

<span class="post-badges"><span class="post-badge badge-top">📝 2</span> 
  <span class="post-badge badge-new">📝 2</span>
</span>
</a>
        </li><li class="">
          <a class="post-link"
            href="/paper_notes/articles/ObjectRecognition.html"
            title="ObjectRecognitionに関する論文・技術記事メモの一覧">
            ObjectRecognitionに関する論文・技術記事メモの一覧

<span class="post-badges"><span class="post-badge badge-top">📝 1</span> 
  <span class="post-badge badge-new">📝 1</span>
</span>
</a>
        </li></ul>
    </div><div class="post-comments"></div></section>
</div>


  </section>
  <section class="sidebar" style="margin-left: 15px;">
    <!-- Get sidebar items --><style type="text/css" media="screen">
/* --- レイアウト用（前回と同じ） --- */
.post-menu {
  position: -webkit-sticky;
  position: sticky;
  top: 20px;
  max-height: calc(100vh - 40px);
  display: flex;
  flex-direction: column;
}

.post-menu-title {
  flex-shrink: 0;
  margin-bottom: 10px;
  font-weight: bold;
}

.post-menu-content {
  overflow-y: auto;
  scrollbar-width: thin;
}

.post-menu ul {
  list-style: none;
  padding: 0;
  margin: 0;
}

/* --- 開閉アニメーションとアイコン用 --- */

/* h2のスタイル：クリックできるようにする */
.post-menu li.h-h2 {
  cursor: pointer;
  position: relative;
  padding-left: 15px; /* アイコン用のスペース */
  font-weight: bold;
  margin-top: 5px;
}

/* 開閉アイコン（▼） */
.post-menu li.h-h2::before {
  content: '';
  display: inline-block;
  width: 0;
  height: 0;
  border-style: solid;
  border-width: 5px 0 5px 6px; /* 三角形 */
  border-color: transparent transparent transparent #555;
  position: absolute;
  left: 0;
  top: 50%;
  transform: translateY(-50%);
  transition: transform 0.2s ease;
}

.post-menu li.h-h2.no-icon::before {
  content: none; /* 擬似要素の中身をなしにする */
  /* または display: none; でもOKです */
}

/* 開いている時のアイコン（下向きにする） */
.post-menu li.h-h2.open::before {
  transform: translateY(-50%) rotate(90deg);
}

/* h3（子要素）のスタイル */
.post-menu li.h-h3 {
  margin-left: 15px;
  font-size: 0.9em;
  /* 初期状態はJSで制御しますが、念のため */
}

/* アクティブな項目の色 */
.post-menu li.active > a {
  color: #d9534f;
  font-weight: bold;
}

/* リンク自体のスタイル調整 */
.post-menu li a {
  text-decoration: none;
  color: inherit;
  display: inline-block;
  width: 100%;
}
</style>

<div class="post-menu">
  <div class="post-menu-title">TOC</div>
  <div class="post-menu-content"></div>
</div>

<script>
  function generateContent() {
    var menu = document.querySelector(".post-menu");
    var menuContent = menu.querySelector(".post-menu-content");
    var headings = document.querySelector(".post-content").querySelectorAll("h2, h3");

    if (headings.length === 0) {
      return menu.style.display = "none";
    }

    // --- HTML生成 ---
    var menuHTML = '';
    for (var i = 0; i < headings.length; i++) {
      var h = headings[i];
      // h-h2 クラスの要素には初期状態で open クラスをつけるか、つけないかで「最初から開いているか」を決められます
      // ここでは閉じた状態をデフォルトとします
      menuHTML += (
        '<li class="h-' + h.tagName.toLowerCase() + '">'
        + '<a href="#' + h.getAttribute('id') + '">' + h.textContent + '</a></li>');
    }
    menuContent.innerHTML = '<ul>' + menuHTML + '</ul>';


    // --- 開閉ロジックの実装 ---
    var listItems = menuContent.querySelectorAll('li');

    // h2要素にクリックイベントを追加
    listItems.forEach(function(item, index) {
      if (item.classList.contains('h-h2')) {
        
        // クリックイベント
        item.addEventListener('click', function(e) {
          // リンクをクリックした場合はページ内遷移させたいので、イベントを止めない
          // ただし、アイコン付近をクリックした等の挙動を統一するため、
          // 開閉処理を行います。
          
          // クラスの付け替え（アイコンの回転用）
          item.classList.toggle('open');

          // 次のh2が出てくるまで、h3を表示/非表示切り替え
          for (var i = index + 1; i < listItems.length; i++) {
            var sibling = listItems[i];
            if (sibling.classList.contains('h-h2')) {
              break; // 次のh2に来たら終了
            }
            if (sibling.classList.contains('h-h3')) {
              if (item.classList.contains('open')) {
                sibling.style.display = 'block';
              } else {
                sibling.style.display = 'none';
              }
            }
          }
        });
      }
    });

    // --- 初期状態の設定（すべて閉じる） ---
    // もし最初から開いておきたい場合は、このブロックを削除するか調整してください
    listItems.forEach(function(item) {
      if (item.classList.contains('h-h3')) {
        item.style.display = 'none';
      }
    });


    // --- スクロール連動（ハイライト機能のみ残す） ---
    var header = document.querySelector('header.site-header');
    
    window.addEventListener('scroll', function (event) {
      var lastActive = menuContent.querySelector('.active');
      var changed = true;
      var activeIndex = -1;
      
      for (var i = headings.length - 1; i >= 0; i--) {
        var h = headings[i];
        var headingRect = h.getBoundingClientRect();
        var headerRect = header ? header.getBoundingClientRect() : {top:0, height:0}; // headerがない場合の安全策
        var headerTop = Math.floor(headerRect.top);
        var headerHeight = Math.floor(headerRect.height);
        var offset = headerTop + headerHeight + 20;

        if (headingRect.top <= offset) {
          var id = h.getAttribute('id');
          var a = menuContent.querySelector('a[href="#' + id  + '"]');
          var curActive = a.parentNode;
          
          if (curActive) {
            // もしアクティブになった項目が閉じているh2の中にあった場合、
            // 自動で開く処理を追加したい場合はここに記述します。
            // 今回は「手動開閉」を優先し、自動オープンはあえて行いません。
            
            curActive.classList.add('active');
            activeIndex = i;
          }
          if (lastActive == curActive) {
            changed = false;
          }
          break;
        }
      }

      if (changed) {
        if (lastActive) {
          lastActive.classList.remove('active');
        }
      }
    });
  }
  generateContent();
</script>
</section>
</div>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/paper_notes/"></data>

  <div class="wrapper">
    <div class="site-footer-inner"><div>Copyright © 2023-current AkihikoWATANABE. The header images and any thumbnail images for the posts were generated by ChatGPT's DALL-E3.</div>
      <div>Powered by <a title="Jekyll is a simple, blog-aware, static site
      generator." href="https://jekyllrb.com/">Jekyll</a> &amp; <a title="Yat, yet
      another theme." href="https://github.com/jeffreytse/jekyll-theme-yat">Yat Theme</a>.</div>
      <div class="footer-col rss-subscribe">Subscribe <a href="/paper_notes/feed.xml">via RSS</a></div>
    </div>
  </div>
</footer>
</body>
  </html>
