<!DOCTYPE html>
<html lang="ja">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-translate-customization" content="108d9124921d80c3-80e20d618ff053c8-g4f02ec6f3dba68b7-c">
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Roboticsã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§ | ã‚ãŸã—ã®ã¹ã‚“ãã‚‡ã†ãƒãƒ¼ãƒˆ</title>
<meta name="generator" content="Jekyll v3.10.0">
<meta property="og:title" content="Roboticsã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">
<meta name="author" content="AkihikoWATANABE">
<meta property="og:locale" content="ja">
<meta name="description" content="Robotics #ComputerVision #Pocket #3D (Scene) #VisionLanguageActionModel #SpatialUnderstanding">
<meta property="og:description" content="Robotics #ComputerVision #Pocket #3D (Scene) #VisionLanguageActionModel #SpatialUnderstanding">
<link rel="canonical" href="http://akihikowatanabe.github.io/paper_notes/articles/Robotics.html">
<meta property="og:url" content="http://akihikowatanabe.github.io/paper_notes/articles/Robotics.html">
<meta property="og:site_name" content="ã‚ãŸã—ã®ã¹ã‚“ãã‚‡ã†ãƒãƒ¼ãƒˆ">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2025-11-04T00:47:43+00:00">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="Roboticsã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"AkihikoWATANABE"},"dateModified":"2025-11-04T00:47:43+00:00","datePublished":"2025-11-04T00:47:43+00:00","description":"Robotics #ComputerVision #Pocket #3D (Scene) #VisionLanguageActionModel #SpatialUnderstanding","headline":"Roboticsã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§","mainEntityOfPage":{"@type":"WebPage","@id":"http://akihikowatanabe.github.io/paper_notes/articles/Robotics.html"},"url":"http://akihikowatanabe.github.io/paper_notes/articles/Robotics.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="icon" href="">
  <link rel="canonical" href="http://akihikowatanabe.github.io">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-noto-sans@0.0.72/index.min.css">
  <link rel="stylesheet" href="/paper_notes/assets/css/main.css">
  <link rel="stylesheet" href="/paper_notes/assets/css/custom_button.css">
  <script src="/paper_notes/assets/js/main.js"></script>
  <script src="https://d3js.org/d3.v5.min.js"></script><link type="application/atom+xml" rel="alternate" href="http://akihikowatanabe.github.io/paper_notes/feed.xml" title="ã‚ãŸã—ã®ã¹ã‚“ãã‚‡ã†ãƒãƒ¼ãƒˆ">
<script>
  function showMore(index) {
    const contentDivs = document.getElementsByClassName('hidden-content');
    const contentDiv = contentDivs[index];

    if (contentDiv) {
      contentDiv.style.display = "block";
          
      // ã“ã®ãƒœã‚¿ãƒ³ã®å‚ç…§ã‚’å–å¾—ã—ã¦éè¡¨ç¤ºã«ã—ã¾ã™
      const moreButtons = document.querySelectorAll('button[onclick^="showMore"]');
      const moreButton = moreButtons[index];
      if (moreButton) {
        moreButton.style.display = "none";
      }
          
      // hideãƒœã‚¿ãƒ³ã®å‚ç…§ã‚’å–å¾—ã—ã¦è¡¨ç¤ºã—ã¾ã™
      const hideButton = contentDiv.querySelector('button[onclick^="hideContent"]');
      if (hideButton) {
        hideButton.style.display = "block";
      }
    }
  }

  function hideContent(index) {
    const contentDivs = document.getElementsByClassName('hidden-content');
    const contentDiv = contentDivs[index];

    if (contentDiv) {
      contentDiv.style.display = "none";
  
      // moreãƒœã‚¿ãƒ³ã®å‚ç…§ã‚’å–å¾—ã—ã¦è¡¨ç¤ºã—ã¾ã™
      const moreButtons = document.querySelectorAll('button[onclick^="showMore"]');
      const moreButton = moreButtons[index];
      if (moreButton) {
        moreButton.style.display = "block";
      }
  
      // ã“ã®ãƒœã‚¿ãƒ³ã‚’éš ã—ã¾ã™
      const hideButtons = document.querySelectorAll('button[onclick^="hideContent"]');
      const hideButton = hideButtons[index];
      if (hideButton) {
        hideButton.style.display = "none";
      }
    }
  }
</script><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/default.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js"></script>
<!-- and it's easy to individually load additional languages -->
<script charset="UTF-8" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/languages/go.min.js" async></script>



















<script>
// Init highlight js
document.addEventListener('DOMContentLoaded', function(event) {
  var els = document.querySelectorAll('pre code')

  function addLangData(block) {
    var outer = block.parentElement.parentElement.parentElement;
    var lang = block.getAttribute('data-lang');
    for (var i = 0; i < outer.classList.length; i++) {
      var cls = outer.classList[i];
      if (cls.startsWith('language-')) {
        lang = cls;
        break;
      }
    }
    if (!lang) {
      cls = block.getAttribute('class');
      lang = cls ? cls.replace('hljs ', '') : '';
    }
    if (lang.startsWith('language-')) {
      lang = lang.substr(9);
    }
    block.setAttribute('class', 'hljs ' + lang);
    block.parentNode.setAttribute('data-lang', lang);
  }

  function addBadge(block) {
    var enabled = ('true' || 'true').toLowerCase();
    if (enabled == 'true') {
      var pre = block.parentElement;
      pre.classList.add('badge');
    }
  }

  function handle(block) {
    addLangData(block);
    addBadge(block)
    hljs.highlightBlock(block);
  }

  for (var i = 0; i < els.length; i++) {
    var el = els[i];
    handle(el);
  }
});
</script>

<style>
  /* code language badge */
  pre.badge::before {
    content: attr(data-lang);
    color: #fff;
    background-color: #ff4e00;
    padding: 0 .5em;
    border-radius: 0 2px;
    text-transform: uppercase;
    text-align: center;
    min-width: 32px;
    display: inline-block;
    position: absolute;
    right: 0;
  }

  /* fix wrong badge display for firefox browser */
  code > table pre::before {
    display: none;
  }
</style>
<script src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/umd/photoswipe-lightbox.umd.min.js" async></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/umd/photoswipe.umd.min.js" async></script>
<link href="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/photoswipe.min.css" rel="stylesheet">
<style>
  .pswp .pswp__container .pswp__img {
    background-color: white;
  }
</style>

<script>
  function initPhotoSwipe() {
    let customOptions = {};

    try {
      const data = `{"gallery"=>"section.main", "children"=>"a.photo-swipe", "bgOpacity"=>0.8, "padding"=>{"top"=>20, "bottom"=>40, "left"=>100, "right"=>100}}`.replaceAll("=>", ":");
      customOptions = JSON.parse(data);
    } catch (e) {
      console.info("Invalid custom photo previewer options! " + e.message);
    }

    // Define object and gallery options
    const options = Object.assign(
      {
        gallery: "section.main",
        children: "a.photo-swipe",
        photo_scale: 2,
        // dynamic import is not supported in UMD version
        pswpModule: PhotoSwipe,
      },
      customOptions
    );

    const galleryEl = document.querySelector(options.gallery);
    if (!galleryEl) {
      return;
    }

    const imgEls = [];
    const els = galleryEl.querySelectorAll("img:not(.emoji)");
    els.forEach((el) => {
      if (el.src.trim() == "") {
        return;
      }
      if (!imgEls.includes(el)) {
        imgEls.push(el);
      }
    });

    if (imgEls.length === 0) {
      return;
    }

    imgEls.forEach((imgEl) => {
      imgEl.outerHTML = `
      <a class="photo-swipe"
        href="${imgEl.src}"
        data-pswp-width="${
          Math.max(imgEl.naturalWidth, imgEl.width) * options.photo_scale
        }"
        data-pswp-height="${
          Math.max(imgEl.naturalHeight, imgEl.height) * options.photo_scale
        }"
        data-pswp-caption="${imgEl.getAttribute("caption") || imgEl.alt}"
        target="_blank">
        ${imgEl.outerHTML}
      </a>`;
    });

    // Initialize PhotoSwipe 5
    var lightbox = new PhotoSwipeLightbox(options);

    lightbox.init();
  }

  window.addEventListener("load", initPhotoSwipe);
</script>
<meta name="google-site-verification" content="u_DTTPcCZ806iq51zgirHyWq3556HUKGq8AQfH91iFI">
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-P70KSB88WH"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-P70KSB88WH');
  </script>

<script>MathJax={"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"svg":{"fontCache":"global"},"svg":{"fontCache":"global"}}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>





































































































































<header class="site-header site-header-transparent" role="banner">

  <div class="wrapper">
    <div class="site-header-inner">
<span class="site-brand"><a class="site-brand-inner" rel="author" href="/paper_notes/">
  <img class="site-favicon" title="ã‚ãŸã—ã®ã¹ã‚“ãã‚‡ã†ãƒãƒ¼ãƒˆ" src="" onerror="this.style.display='none'">
  ã‚ãŸã—ã®ã¹ã‚“ãã‚‡ã†ãƒãƒ¼ãƒˆ
</a>
</span><nav class="site-nav">
          <input type="checkbox" id="nav-trigger" class="nav-trigger">
          <label for="nav-trigger">
            <span class="menu-icon">
              <svg viewbox="0 0 18 15" width="18px" height="15px">
                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"></path>
              </svg>
            </span>
          </label>

          <div class="trigger">









<span class="page-link">



<div id="google_translate_element" style="display: none;">
</div>

<span class="ct-language">
  <ul class="list-unstyled ct-language-dropdown">
    
      <li>
        <a href="#" class="lang-select" data-lang="en">
          
          <img src="https://cdn.countryflags.com/thumbs/united-states-of-america/flag-400.png" title="English">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="fr">
          
          <img src="https://cdn.countryflags.com/thumbs/france/flag-400.png" title="French">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="zh-CN">
          
          <img src="https://cdn.countryflags.com/thumbs/china/flag-400.png" title="Chinese(Simple)">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ja">
          
          <img src="https://cdn.countryflags.com/thumbs/japan/flag-400.png" title="Japanese">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ko">
          
          <img src="https://cdn.countryflags.com/thumbs/south-korea/flag-400.png" title="Korean">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ru">
          
          <img src="https://cdn.countryflags.com/thumbs/russia/flag-400.png" title="Russian">
          
        </a>
      </li>
    
  </ul>
</span>

<script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({
    pageLanguage: 'ja',
    autoDisplay: false,
    layout: google.translate.TranslateElement.InlineLayout.VERTICAL
  }, 'google_translate_element');

  // Links to cross-origin destinations are unsafe
  var gll = document.getElementsByClassName('goog-logo-link')[0];
  if (gll) {
    gll.setAttribute('rel', 'noopener');
  }

  function restoreLang() {
    var iframe = document.getElementsByClassName('goog-te-banner-frame')[0];
    if (!iframe) return;

    var innerDoc = iframe.contentDocument || iframe.contentWindow.document;
    var restore_el = innerDoc.getElementsByTagName("button");

    for (var i = 0; i < restore_el.length; i++) {
      if (restore_el[i].id.indexOf("restore") >= 0) {
        restore_el[i].click();
        var close_el = innerDoc.getElementsByClassName("goog-close-link");
        close_el[0].click();
        return;
      }
    }
  }

  function triggerHtmlEvent(element, eventName) {
    var event;
    if (document.createEvent) {
      event = document.createEvent('HTMLEvents');
      event.initEvent(eventName, true, true);
      element.dispatchEvent(event);
    } else {
      event = document.createEventObject();
      event.eventType = eventName;
      element.fireEvent('on' + event.eventType, event);
    }
  }

  var googleCombo = document.querySelector("select.goog-te-combo");
  var langSelect = document.querySelector('.ct-language');
  langSelect.addEventListener('click', function(event) {
    if (!event.target) {
      return;
    }

    var selected = document.querySelector('.ct-language .ct-language-selected');
    if (selected) {
      selected.classList.remove('ct-language-selected');
    }

    var target = event.target;
    while (target && target !== langSelect ) {
      if (target.matches('.lang-select')) {
        break;
      }
      target = target.parentElement;
    }

    if (target && target.matches('.lang-select')) {
      var lang = target.getAttribute('data-lang');
      if (googleCombo.value == lang) {
        restoreLang();
      } else {
        target.parentElement.classList.add('ct-language-selected');
        googleCombo.value = lang;
        triggerHtmlEvent(googleCombo, 'change');
      }
    }

    event.preventDefault();
  });
}
</script>

<script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=googleTranslateElementInit" async></script>
</span>
</div>
        </nav>
</div>
  </div>
</header>

<script>
  function initHeader() {
    var lastScrollY = getScrollPos().y;
    var documentElement = document.documentElement;

    function storeScrollData() {
      var y = getScrollPos().y;documentElement.setAttribute("data-header-transparent", "");var scrollStatus = "";

      if (y <= 0) {
        scrollStatus = "top";
      } else if ((window.innerHeight + y) >= document.body.offsetHeight) {
        scrollStatus = "bottom";
      } else {
        var isScrollDown = (y - lastScrollY > 0) ? true : false;
        scrollStatus = isScrollDown ? "down" : "up";
      }

      lastScrollY = y;
      documentElement.setAttribute("data-scroll-status", scrollStatus);
    }

    window.addEventListener('scroll', function(e) {
      storeScrollData();
    });

    storeScrollData();
  }
  document.addEventListener('DOMContentLoaded', initHeader);
</script>


























































































































































<style>
    html .page-banner .page-banner-img > *:first-child {
      opacity: 0.4;
    }

    html[data-theme="dark"] .page-banner .page-banner-img > *:first-child {
      opacity: 0.2872;
    }
  </style>
<section class="page-banner">
    <div class="page-banner-img">
<div style="background-image: url(/paper_notes/assets/images/banner.png)"></div>
        <img class="img-placeholder" src="/paper_notes/assets/images/banner.png">
</div>
    <div class="wrapper">
      <div class="page-banner-inner">
<header class="post-header">
  <h1 class="post-title p-name" itemprop="name headline">ã‚ãŸã—ã®ã¹ã‚“ãã‚‡ã†ãƒãƒ¼ãƒˆ</h1>
  <h2 class="post-subtitle">å‹‰å¼·ã—ãŸè«–æ–‡ã‚„æŠ€è¡“ç­‰ã®æƒ…å ±ã‚’Githubã®Issueã«ãƒ¡ãƒ¢ã£ã¦ã„ã‚‹ã²ã¨ã®ãƒ–ãƒ­ã‚°ã€‚
ãã‚Œãªã‚Šã«ãƒ¡ãƒ¢ã®é‡ãŒè“„ç©ã•ã‚Œã¦ããŸã®ã§ã€ä¸€åº¦æ•´ç†ã—ãŸã„ãªã¨æ€ã„ãƒ–ãƒ­ã‚°ã¯ã˜ã‚ã¦ã¿ã¾ã—ãŸï¼
è‡ªç„¶è¨€èªå‡¦ç†(NLP), æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ (RecommenderSystem), Educational Data Mining (EDM), Learning Analytics (LA)ãªã©ã®åˆ†é‡ã®ãƒ¡ãƒ¢ãŒå¤šã„ã¨æ€ã„ã¾ã™ã€‚
æœ€è¿‘ã¯ç‰¹ã«LLMã®å‹‰å¼·ãŒå¤šã‚ã§ã™ :)</h2>

  <div class="post-meta">
    <time class="dt-published" datetime="2025-11-04T00:47:43+00:00" itemprop="datePublished"><i class="fa fa-calendar"></i> Nov 4, 2025
    </time><span class="post-author left-vsplit"><i class="fa fa-pencil"></i> AkihikoWATANABE</span>
    
































    <span class="post-reading-time left-vsplit"><i class="fa fa-clock-o"></i> About 49 mins</span>
  </div></header>
</div>
    </div>
  </section><script>
  function hashLocate(hashValue) {
    hashValue = hashValue.replace(/^.*#h-/, '');
    hashValue = decodeURIComponent(hashValue);
    var element = document.getElementById(hashValue);

    if (!element) {
      return;
    }

    var header = document.querySelector('header.site-header');
    var headerRect = header.getBoundingClientRect();
    var headerTop = Math.floor(headerRect.top);
    var headerHeight = Math.floor(headerRect.height);
    var scrollPos = getScrollPos();
    var offsetY = element.offsetTop - (headerTop + headerHeight + 20);

    if (offsetY == scrollPos.y) {
      return;
    }

    if (headerTop == 0  && offsetY > scrollPos.y) {
      offsetY += headerHeight + 2;
    } else if (headerTop < 0  && offsetY < scrollPos.y) {
      offsetY -= headerHeight - 2;
    }

    smoothScrollTo(offsetY);
  }

  // The first event occurred
  window.addEventListener('load', function(event) {
    if (window.location.hash) {
      hashLocate(window.location.hash);
    }
  });

  // The first event occurred
  window.addEventListener('click', function(event) {
    if (event.target.tagName.toLowerCase() == 'a') {
      hashLocate(event.target.getAttribute('href'));
    }
  });
</script>
<div class="theme-toggle">
  <input type="checkbox" id="theme-switch">
  <label for="theme-switch">
    <div class="toggle"></div>
    <div class="names">
      <p class="light">Light</p>
      <p class="dark">Dark</p>
    </div>
  </label>
</div>




<script>
  (function() {
    var sw = document.getElementById('theme-switch');
    var html = document.getElementsByTagName('html')[0];
    var nightModeOption = ('off' || 'auto').toLowerCase();
    var storage = nightModeOption === 'manual'
        ? localStorage
        : sessionStorage;
    var themeData = loadThemeData();

    function saveThemeData(data) {
      storage.setItem('theme', JSON.stringify(data));
    }

    function loadThemeData() {
      var data = storage.getItem('theme');
      try {
        data = JSON.parse(data ? data : '');
      } catch(e) {
        data = { nightShift: undefined, autoToggleAt: 0 };
        saveThemeData(data);
      }
      return data;
    }

    function handleThemeToggle(nightShift) {
      themeData.nightShift = nightShift;
      saveThemeData(themeData);
      html.dataset.theme = nightShift ? 'dark' : 'light';
      setTimeout(function() {
        sw.checked = nightShift ? true : false;
      }, 50);
    }

    function autoThemeToggle() {
      // Next time point of theme toggle
      var now = new Date();
      var toggleAt = new Date();
      var hours = now.getHours();
      var nightShift = hours >= 19 || hours <=7;

      if (nightShift) {
        if (hours > 7) {
          toggleAt.setDate(toggleAt.getDate() + 1);
        }
        toggleAt.setHours(7);
      } else {
        toggleAt.setHours(19);
      }

      toggleAt.setMinutes(0);
      toggleAt.setSeconds(0);
      toggleAt.setMilliseconds(0)

      var delay = toggleAt.getTime() - now.getTime();

      // auto toggle theme mode
      setTimeout(function() {
        handleThemeToggle(!nightShift);
      }, delay);

      return {
        nightShift: nightShift,
        toggleAt: toggleAt.getTime()
      };
    }

    // Listen the theme toggle event
    sw.addEventListener('change', function(event) {
      handleThemeToggle(event.target.checked);
    });

    if (nightModeOption == 'auto') {
      var data = autoThemeToggle();

      // Toggle theme by local setting
      if (data.toggleAt > themeData.autoToggleAt) {
        themeData.autoToggleAt = data.toggleAt;
        handleThemeToggle(data.nightShift);
      } else {
        handleThemeToggle(themeData.nightShift);
      }
    } else if (nightModeOption == 'manual') {
      handleThemeToggle(themeData.nightShift);
    } else {
      var nightShift = themeData.nightShift;
      if (nightShift === undefined) {
        nightShift = nightModeOption === 'on';
      }
      handleThemeToggle(nightShift);
    }
  })();
</script>
<div id="click-to-top" class="click-to-top">
  <i class="fa fa-arrow-up"></i>
</div>
<script>
  (function () {
    const clickToTop = document.getElementById('click-to-top');
    window.addEventListener('scroll', () => {
      if (window.scrollY > 100) {
        clickToTop.classList.add('show')
      }else {
        clickToTop.classList.remove('show')
      }
    });
    clickToTop.addEventListener('click', () => {
      window.smoothScrollTo(0);
    });
  })();
</script>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="framework">
  <section class="main">

     <div class="post">
  <section>









<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

    <div class="post-content e-content" itemprop="articleBody">

      <h2 id="Robotics"> Robotics</h2>
<div class="visible-content">
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/3D%20(Scene).html" target="_blank" rel="noopener noreferrer">#3D (Scene)</a>
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<a class="button" href="articles/SpatialUnderstanding.html" target="_blank" rel="noopener noreferrer">#SpatialUnderstanding</a>


<br>


<span class="issue_date">Issue Date: 2025-11-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3557" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] From Spatial to Actions: Grounding Vision-Language-Action Model in  Spatial Foundation Priors, Zhengshen Zhang+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- FALCONï¼ˆFrom Spatial to Actionï¼‰ã¯ã€è¦–è¦š-è¨€èª-è¡Œå‹•ï¼ˆVLAï¼‰ãƒ¢ãƒ‡ãƒ«ã®ç©ºé–“çš„æ¨è«–ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’è§£æ¶ˆã™ã‚‹æ–°ã—ã„ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã§ã€3Dç©ºé–“ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¡Œå‹•ãƒ˜ãƒƒãƒ‰ã«æ³¨å…¥ã—ã¾ã™ã€‚RGBã‹ã‚‰å¹¾ä½•å­¦çš„æƒ…å ±ã‚’æä¾›ã—ã€æ·±åº¦ã‚„ãƒãƒ¼ã‚ºã‚’èåˆã•ã›ã‚‹ã“ã¨ã§é«˜ã„å¿ å®Ÿåº¦ã‚’å®Ÿç¾ã—ã€å†è¨“ç·´ã‚„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å¤‰æ›´ã¯ä¸è¦ã§ã™ã€‚FALCONã¯ã€ç©ºé–“è¡¨ç¾ã‚„ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®è»¢é€å¯èƒ½æ€§ã‚’å‘ä¸Šã•ã›ã€11ã®ç¾å®Ÿä¸–ç•Œã®ã‚¿ã‚¹ã‚¯ã§æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://falcon-vla.github.io/" target="_blank" rel="noopener noreferrer">https://falcon-vla.github.io/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/travis_laflamee/status/1985327139475112336?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="articles/LongHorizon.html" target="_blank" rel="noopener noreferrer">#LongHorizon</a>


<br>


<span class="issue_date">Issue Date: 2025-10-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3459" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MemER: Scaling Up Memory for Robot Control via Experience Retrieval, Ajay Sridhar+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒ­ãƒœãƒƒãƒˆãƒãƒªã‚·ãƒ¼ã«äººé–“ã®ã‚ˆã†ãªè¨˜æ†¶èƒ½åŠ›ã‚’ä¸ãˆã‚‹ãŸã‚ã®éšå±¤çš„ãƒãƒªã‚·ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚é«˜ãƒ¬ãƒ™ãƒ«ãƒãƒªã‚·ãƒ¼ãŒé–¢é€£ã™ã‚‹ã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é¸æŠã—ã€ä½ãƒ¬ãƒ™ãƒ«ãƒãƒªã‚·ãƒ¼ã«æŒ‡ç¤ºã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã€é•·æœŸçš„ãªä¾å­˜é–¢ä¿‚ã‚’åŠ¹ç‡çš„ã«æ¨è«–ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ææ¡ˆæ‰‹æ³•MemERãŒå¾“æ¥ã®æ–¹æ³•ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ajaysridhar0/status/1982239143431393432?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>pj page:


<a href="https://jen-pan.github.io/memer/" target="_blank" rel="noopener noreferrer">https://jen-pan.github.io/memer/</a>


</p>
<p>å‹•ç”»ã‚¹ãƒˆãƒªãƒ¼ãƒ å…¨ã¦ã‚’å¸¸ã«inputã™ã‚‹ã®ã§ã¯ãªãã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ ã¯é™ã‚‰ã‚Œã¦ã„ã‚‹ã®ã§ã€VLMã«ã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãƒ¡ãƒ¢ãƒªä¸Šã§ç®¡ç†ã™ã‚‹ã‚ˆã†ãªå½¹å‰²ã‚’ä¸ãˆã€instructionã¨å®Ÿç¾ã™ã‚‹ãŸã‚ã®ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã«å¿œã˜ã¦å‹•çš„ã«å¿…è¦ãªæƒ…å ±ã®ã¿ã‚’VLAã«ä¸ãˆã‚‹ã“ã¨ã§long horizonã§ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’æ”¹å–„ã™ã‚‹ã€ã¿ãŸã„ãªè©±ã‚‰ã—ã„</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>


<br>


<span class="issue_date">Issue Date: 2025-10-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3445" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] RL-100: Performant Robotic Manipulation with Real-World Reinforcement  Learning, Kun Lei+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- RL-100ã¯ã€å®Ÿä¸–ç•Œã®ãƒ­ãƒœãƒƒãƒˆæ“ä½œã®ãŸã‚ã®å¼·åŒ–å­¦ç¿’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€æ¨¡å€£å­¦ç¿’ã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å¼·åŒ–å­¦ç¿’ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å¼·åŒ–å­¦ç¿’ã®ä¸‰æ®µéšã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ¡ç”¨ã€‚å¤šæ®µéšã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’å˜ä¸€æ®µéšãƒãƒªã‚·ãƒ¼ã«åœ§ç¸®ã—ã€é«˜é »åº¦åˆ¶å¾¡ã‚’å®Ÿç¾ã€‚7ã¤ã®å®Ÿãƒ­ãƒœãƒƒãƒˆã‚¿ã‚¹ã‚¯ã§100%ã®æˆåŠŸç‡ã‚’é”æˆã—ã€äººé–“ã®æ“ä½œã«åŒ¹æ•µã™ã‚‹åŠ¹ç‡ã¨å …ç‰¢æ€§ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://lei-kun.github.io/RL-100/" target="_blank" rel="noopener noreferrer">https://lei-kun.github.io/RL-100/</a>


<br>blog:


<a href="https://lei-kun.github.io/blogs/RL100.html" target="_blank" rel="noopener noreferrer">https://lei-kun.github.io/blogs/RL100.html</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/robotsdigest/status/1981760189394215115?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
</div>
<p><button onclick="showMore(0)">more</button></p>
<div class="hidden-content">
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<span class="issue_date">Issue Date: 2025-10-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3444" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] GigaBrain-0: A World Model-Powered Vision-Language-Action Model, GigaBrain Team+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- GigaBrain-0ã¯ã€å®Ÿä¸–ç•Œã®ãƒ­ãƒœãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã®åé›†ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›ã—ã€VLAãƒ¢ãƒ‡ãƒ«ã®ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹æ–°ã—ã„åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã€‚ä¸–ç•Œãƒ¢ãƒ‡ãƒ«ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã—ã€ã‚¿ã‚¹ã‚¯é–“ã®ä¸€èˆ¬åŒ–ã‚’ä¿ƒé€²ã€‚RGBDå…¥åŠ›ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã¨Chain-of-Thoughtç›£è¦–ã«ã‚ˆã‚Šã€ç©ºé–“å¹¾ä½•å­¦ã‚„ç‰©ä½“ã®çŠ¶æ…‹ã‚’æ¨è«–ã—ã€å®Ÿä¸–ç•Œã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã€‚GigaBrain-0ã¯å¤–è¦³ã‚„é…ç½®ã®å¤‰åŒ–ã«å¯¾ã—ã¦å„ªã‚ŒãŸä¸€èˆ¬åŒ–ã‚’ç¤ºã—ã€è»½é‡ãƒãƒªã‚¢ãƒ³ãƒˆGigaBrain-0-Smallã‚‚ç´¹ä»‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://gigabrain0.github.io" target="_blank" rel="noopener noreferrer">https://gigabrain0.github.io</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1981392485671702699?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Routing.html" target="_blank" rel="noopener noreferrer">#Routing</a>
<span class="issue_date">Issue Date: 2025-10-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3367" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Multi-Modal Manipulation via Multi-Modal Policy Consensus, Haonan Chen+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- å¤šæ§˜ãªæ„Ÿè¦šãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’çµ±åˆã™ã‚‹ã“ã¨ã¯ãƒ­ãƒœãƒƒãƒˆæ“ä½œã«ãŠã„ã¦é‡è¦ã§ã‚ã‚Šã€å¾“æ¥ã®ç‰¹å¾´é€£çµã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯æœ€é©ã§ã¯ãªã„ã€‚ææ¡ˆæ‰‹æ³•ã§ã¯ã€ãƒãƒªã‚·ãƒ¼ã‚’æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã«å› æ•°åˆ†è§£ã—ã€å„ãƒ¢ãƒ‡ãƒ«ãŒç‰¹å®šã®è¡¨ç¾ã«ç‰¹åŒ–ã€‚ãƒ«ãƒ¼ã‚¿ãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç”¨ã„ã¦é©å¿œçš„ã«é‡ã¿ã‚’å­¦ç¿’ã—ã€æ–°ã—ã„è¡¨ç¾ã®çµ±åˆã‚’å¯èƒ½ã«ã™ã‚‹ã€‚ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚„å®Ÿä¸–ç•Œã®ã‚¿ã‚¹ã‚¯ã§ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ¨è«–ã«ãŠã„ã¦ç‰¹å¾´é€£çµã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€ç‰©ç†çš„ãªæ‘‚å‹•ã«å¯¾ã—ã¦ã‚‚å …ç‰¢æ€§ã‚’æŒã¤ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/haonanchen_/status/1980266120377487361?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>pj page:


<a href="https://policyconsensus.github.io" target="_blank" rel="noopener noreferrer">https://policyconsensus.github.io</a>


</p>
<p>å…ˆè¡Œç ”ç©¶ã®ä¸€ã¤:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3422" target="_blank" rel="noopener noreferrer">[Paper Note] See, Hear, and Feel: Smart Sensory Fusion for Robotic Manipulation, Hao Li+, CoRL'22, 2022.12</a>
</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<a class="button" href="articles/PseudoLabeling.html" target="_blank" rel="noopener noreferrer">#PseudoLabeling</a>
<span class="issue_date">Issue Date: 2025-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3329" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] D2E: Scaling Vision-Action Pretraining on Desktop Data for Transfer to  Embodied AI, Suwhan Choi+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- D2Eï¼ˆDesktop to Embodied AIï¼‰ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ç’°å¢ƒã§ã®ç›¸äº’ä½œç”¨ãŒãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ã®å…·ç¾åŒ–AIã‚¿ã‚¹ã‚¯ã®äº‹å‰å­¦ç¿’ã«æœ‰åŠ¹ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚OWAãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆã€Generalist-IDMã€VAPTã®3ã¤ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ç”¨ã„ã¦ã€1,300æ™‚é–“ä»¥ä¸Šã®ãƒ‡ãƒ¼ã‚¿ã§é«˜ã„æˆåŠŸç‡ã‚’é”æˆã€‚ãƒ‡ã‚¸ã‚¿ãƒ«ç›¸äº’ä½œç”¨ã®è¦ç´ ãŒç‰©ç†çš„ã‚¿ã‚¹ã‚¯ã«è»¢é€å¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’æ¤œè¨¼ã—ã€ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—äº‹å‰å­¦ç¿’ã®å®Ÿç”¨æ€§ã‚’ç¢ºç«‹ã€‚é–¢é€£ãƒ‡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«ã¯å…¬é–‹äºˆå®šã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1979911820401086613?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/3D%20(Scene).html" target="_blank" rel="noopener noreferrer">#3D (Scene)</a>
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<a class="button" href="articles/SpatialUnderstanding.html" target="_blank" rel="noopener noreferrer">#SpatialUnderstanding</a>
<span class="issue_date">Issue Date: 2025-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3328" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Spatial Forcing: Implicit Spatial Representation Alignment for  Vision-language-action Model, Fuhao Li+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- Spatial Forcing (SF)ã¨ã„ã†æ–°ã—ã„æ•´åˆæˆ¦ç•¥ã‚’ææ¡ˆã—ã€VLAãƒ¢ãƒ‡ãƒ«ãŒ3Dç©ºé–“ç†è§£èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ä¿ƒé€²ã€‚SFã¯3Då…¥åŠ›ã‚„æ·±åº¦æ¨å®šå™¨ã«ä¾å­˜ã›ãšã€VLAã®ä¸­é–“è¦–è¦šåŸ‹ã‚è¾¼ã¿ã‚’3DåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®å¹¾ä½•å­¦çš„è¡¨ç¾ã¨æ•´åˆã•ã›ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€SFã¯æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’æœ€å¤§3.8å€åŠ é€Ÿã€ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ã‚’æ”¹å–„ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1979911820401086613?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<span class="issue_date">Issue Date: 2025-10-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3312" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ERA: Transforming VLMs into Embodied Agents via Embodied Prior Learning  and Online Reinforcement Learning, Hanyang Chen+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- Embodied Reasoning Agent (ERA)ã¯ã€äº‹å‰çŸ¥è­˜å­¦ç¿’ã¨ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å¼·åŒ–å­¦ç¿’ã‚’çµ±åˆã—ãŸäºŒæ®µéšã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€è¦–è¦šè¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½å‘ä¸Šã‚’ç›®æŒ‡ã™ã€‚ç¬¬ä¸€æ®µéšã§ã¯ã€è»Œé“æ‹¡å¼µã€ç’°å¢ƒå›ºå®šã€å¤–éƒ¨çŸ¥è­˜ã‹ã‚‰åŸºç¤çŸ¥è­˜ã‚’æŠ½å‡ºã—ã€ç¬¬äºŒæ®µéšã§ã‚ªãƒ³ãƒ©ã‚¤ãƒ³RLã‚’ç”¨ã„ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚è‡ªå·±è¦ç´„ã€å¯†ãªå ±é…¬å½¢æˆã€ã‚¿ãƒ¼ãƒ³ãƒ¬ãƒ™ãƒ«ã®ãƒãƒªã‚·ãƒ¼æœ€é©åŒ–ã‚’å°å…¥ã—ã€EB-ALFREDã¨EB-Manipulationã‚¿ã‚¹ã‚¯ã§å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æˆæœã‚’ç¤ºã—ãŸã€‚ERAã¯å…·ç¾åŒ–çŸ¥èƒ½ã®å®Ÿç”¨çš„ãªé“ã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://embodied-reasoning-agent.github.io" target="_blank" rel="noopener noreferrer">https://embodied-reasoning-agent.github.io</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ainativef/status/1978627172152807730?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<span class="issue_date">Issue Date: 2025-10-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3288" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] RoboMonkey: Scaling Test-Time Sampling and Verification for  Vision-Language-Action Models, Jacky Kwok+, arXiv'25, 2025.06</a>
<span class="snippet"><span>GPT Summary</span>- VLAãƒ¢ãƒ‡ãƒ«ã®å …ç‰¢æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã€ãƒ†ã‚¹ãƒˆæ™‚ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’èª¿æŸ»ã—ã€RoboMonkeyãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’å°å…¥ã€‚å°ã•ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚»ãƒƒãƒˆã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€VLMã‚’ç”¨ã„ã¦æœ€é©ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’é¸æŠã€‚åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã«ã‚ˆã‚Šæ¤œè¨¼ç²¾åº¦ãŒå‘ä¸Šã—ã€åˆ†å¸ƒå¤–ã‚¿ã‚¹ã‚¯ã§25%ã€åˆ†å¸ƒå†…ã‚¿ã‚¹ã‚¯ã§9%ã®æ”¹å–„ã‚’é”æˆã€‚æ–°ã—ã„ãƒ­ãƒœãƒƒãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¸ã®é©å¿œæ™‚ã«ã¯ã€VLAã¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ¤œè¨¼å™¨ã®ä¸¡æ–¹ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ã§7%ã®æ€§èƒ½å‘ä¸Šã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1978712036231217407?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/WorldModels.html" target="_blank" rel="noopener noreferrer">#WorldModels</a>
<a class="button" href="articles/EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2025-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2986" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Embodied AI: From LLMs to World Models, Tongtong Feng+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- å…·ç¾åŒ–ã•ã‚ŒãŸAIã¯AGIé”æˆã®ãŸã‚ã®çŸ¥çš„ã‚·ã‚¹ãƒ†ãƒ ã§ã‚ã‚Šã€LLMsã¨WMsã®é€²å±•ãŒæ³¨ç›®ã•ã‚Œã¦ã„ã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯ã€å…·ç¾åŒ–ã•ã‚ŒãŸAIã®æ­´å²ã‚„æŠ€è¡“ã€ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ç´¹ä»‹ã—ã€LLMsã¨WMsã®å½¹å‰²ã‚’è©³ç´°ã«æ¤œè¨ã€‚MLLM-WMé§†å‹•ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å¿…è¦æ€§ã‚’è«–ã˜ã€ç‰©ç†ä¸–ç•Œã§ã®è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã®å®Ÿç¾ã«ãŠã‘ã‚‹æ„ç¾©ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚å…·ç¾åŒ–ã•ã‚ŒãŸAIã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¨ä»Šå¾Œã®ç ”ç©¶æ–¹å‘ã«ã¤ã„ã¦ã‚‚è§¦ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1971219902821519778?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1971423253135753299?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/Navigation.html" target="_blank" rel="noopener noreferrer">#Navigation</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2025-09-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2818" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Embodied Navigation Foundation Model, Jiazhao Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- NavFoMã¯ã€800ä¸‡ã®ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã‚µãƒ³ãƒ—ãƒ«ã§è¨“ç·´ã•ã‚ŒãŸã‚¯ãƒ­ã‚¹å…·ç¾åŒ–ãƒ»ã‚¯ãƒ­ã‚¹ã‚¿ã‚¹ã‚¯ã®ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€ãƒ“ã‚¸ãƒ§ãƒ³ã¨è¨€èªã®ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã‚„è‡ªå¾‹é‹è»¢ãªã©å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã€‚ç•°ãªã‚‹ã‚«ãƒ¡ãƒ©æ§‹æˆã‚„æ™‚é–“çš„è¦–é‡ã‚’è€ƒæ…®ã—ã€å‹•çš„ã«èª¿æ•´ã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æˆ¦ç•¥ã‚’ç”¨ã„ã¦ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãªã—ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’é”æˆã€‚å®Ÿä¸–ç•Œã§ã®å®Ÿé¨“ã§ã‚‚å¼·åŠ›ãªä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://pku-epic.github.io/NavFoM-Web/" target="_blank" rel="noopener noreferrer">https://pku-epic.github.io/NavFoM-Web/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1967806725387588069?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<a class="button" href="articles/EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2025-09-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2807" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LLaDA-VLA: Vision Language Diffusion Action Models, Yuqing Wen+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è¦–è¦š-è¨€èª-æ‹¡æ•£-ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«LLaDA-VLAã‚’ææ¡ˆã—ã€äº‹å‰å­¦ç¿’ã•ã‚ŒãŸd-VLMã‚’ãƒ­ãƒœãƒƒãƒˆæ“ä½œã«é©å¿œã€‚ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³åˆ†é¡ã¨éšå±¤çš„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’å°å…¥ã—ã€å®Ÿé¨“ã§æœ€å…ˆç«¯ã®VLAã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://wenyuqing.github.io/llada-vla/" target="_blank" rel="noopener noreferrer">https://wenyuqing.github.io/llada-vla/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/embodiedairead/status/1967383358213902578?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<a class="button" href="articles/EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2025-09-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2804" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MemoryVLA: Perceptual-Cognitive Memory in Vision-Language-Action Models  for Robotic Manipulation, Hao Shi+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- MemoryVLAã¯ã€ãƒ­ãƒœãƒƒãƒˆæ“ä½œã«ãŠã‘ã‚‹æ™‚é–“çš„æ–‡è„ˆã‚’è€ƒæ…®ã—ãŸCognition-Memory-Actionãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚‹ã€‚ä½œæ¥­è¨˜æ†¶ã‚’åˆ©ç”¨ã—ã¦çŸ­å‘½ã®è¡¨ç¾ã‚’åˆ¶å¾¡ã—ã€çŸ¥è¦š-èªçŸ¥ãƒ¡ãƒ¢ãƒªãƒ¼ãƒãƒ³ã‚¯ã«çµ±åˆã•ã‚ŒãŸæƒ…å ±ã‚’ä¿å­˜ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ™‚é–“çš„ã«æ„è­˜ã—ãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ç”Ÿæˆã—ã€150ä»¥ä¸Šã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŠã‚ˆã³å®Ÿä¸–ç•Œã®ã‚¿ã‚¹ã‚¯ã§é«˜ã„æˆåŠŸç‡ã‚’é”æˆã€‚ç‰¹ã«ã€é•·æœŸçš„ãªã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦é¡•è‘—ãªæ€§èƒ½å‘ä¸Šã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://shihao1895.github.io/MemoryVLA/" target="_blank" rel="noopener noreferrer">https://shihao1895.github.io/MemoryVLA/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/embodiedairead/status/1966651546567143534?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é•·æœŸè¨˜æ†¶ã¨ã—ã¦ãƒ¡ãƒ¢ãƒªãƒãƒ³ã‚¯ãŒå°å…¥ã•ã‚Œã€éå»ã«èªè­˜ã—ãŸå†—é•·æ€§ãŒæ’é™¤ã•ã‚ŒãŸç”»åƒæƒ…å ±(low level)ã¨ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã«ã‚ˆã‚‹æŒ‡ç¤ºã®æ„å‘³æƒ…å ±ï¼ˆhigh level semantics)ã‚’æ ¼ç´ã—ã¦ãŠã<br>ã€retrievalã—ãŸä¸Šã§æ´»ç”¨ã™ã‚‹ã€‚æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ±ºã‚ã‚‹ãŸã‚ã®ãƒ‡ã‚³ãƒ¼ãƒ€ã‚ˆã†ã«è¦‹ãˆã‚‹transformerã®attentionã«å°‚ç”¨ã®Cognition/Perceptionã®attentionãŒä¸¡æ–¹ç”¨æ„ã•ã‚Œã¦ã„ã‚‹ğŸ‘€<br><br><img src="https://github.com/user-attachments/assets/520eae6e-c96e-416c-b72d-fc7326d8b9df" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<a class="button" href="articles/EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2025-09-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2782" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning, Haozhan Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- VLAãƒ¢ãƒ‡ãƒ«ã®å¼·åŒ–å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯SimpleVLA-RLã‚’ææ¡ˆã—ã€ãƒ­ãƒœãƒƒãƒˆæ“ä½œã®åŠ¹ç‡ã‚’å‘ä¸Šã€‚å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã¸ã®ä¾å­˜ã‚’æ¸›ã‚‰ã—ã€ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’å¼·åŒ–ã€‚OpenVLA-OFTã§æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã€RoboTwin 1.0&amp;2.0ã§å„ªã‚ŒãŸçµæœã‚’ç¤ºã™ã€‚æ–°ãŸãªç¾è±¡ã€Œpushcutã€ã‚’ç‰¹å®šã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1966352984461173096?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>HF:


<a href="https://huggingface.co/collections/Haozhan72/simplevla-rl-6833311430cd9df52aeb1f86" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/Haozhan72/simplevla-rl-6833311430cd9df52aeb1f86</a>


</p>
<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1966592913955033229?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>VLAã«ãŠã„ã¦åˆã‚ã¦R1-styleã®ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®verifiable rewardï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç’°å¢ƒã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹çµæœï¼‰ã®ã¿ã«åŸºã¥ãã‚·ãƒ³ãƒ—ãƒ«ãªon policy RLã‚’å®Ÿæ–½ã™ã‚‹ã“ã¨ã§ã€SFTã‚’å®Ÿæ–½ã™ã‚‹å ´åˆã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã€ã‹ã¤é«˜ã„æ±åŒ–æ€§èƒ½ã‚’ç²å¾—ã§ãã‚‹ã“ã¨ã‚’VLAã«ãŠã„ã¦ç¤ºã—ãŸç ”ç©¶ãªæ¨¡æ§˜ã€‚<br><br>ãŸã ã—æ–°ãŸãªBehaviorã«å¯¾ã™ã‚‹Explorationã‚’ã‚ˆã‚Šé«˜ã‚ã‚‹ãŸã‚ã«ã€Refãƒ¢ãƒ‡ãƒ«ã«å¯¾ã™ã‚‹KL DivergenceãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’é™¤å¤–ã—ãŸã‚Šã€3.3ç¯€ã«è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ãªã€<br>- Dynamic Sampling: å…¨ã¦ã®ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã®RewardãŒåŒã˜å€¤ã«ãªã‚‹ã¨GRPOã®advantageãŒ0ã¨ãªã‚Šå‹¾é…ãŒæ¶ˆå¤±ã™ã‚‹å•é¡ŒãŒã‚ã‚‹ã®ã§ã€å…¨ã¦ã®ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆãŒæˆåŠŸ/å¤±æ•—ã—ãŸã‚°ãƒ«ãƒ¼ãƒ—ã¯é™¤å¤–ï¼ˆè¨€ã„æ›ãˆã‚‹ã¨ã€mixed outcomeã®ã‚°ãƒ«ãƒ¼ãƒ—ã®ã¿ã‚’åˆ©ç”¨ï¼‰ã—ã¦å­¦ç¿’<br>- Clip Higher: DAPOã¨åŒæ§˜ã«ã€ç›´å‰ã®ãƒãƒªã‚·ãƒ¼ã¨ç¾åœ¨ã®ãƒãƒªã‚·ãƒ¼ã®æ¯”ç‡ã®ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã®ä¸Šé™å€¤ã‚’åºƒã’ï¼ˆã¤ã¾ã‚Šã€ä½ã„ç¢ºç‡ã ã£ãŸã‚‚ã®ã‚’ã‚ˆã‚Šå¤§ããªå€¤ã¨ãªã‚‹ã“ã¨ã‚’ä»¥å‰ã‚ˆã‚Šã‚‚è¨±å®¹ã™ã‚‹ï¼‰ã¦æ¢ç´¢ã‚’ä¿ƒã™<br>- Higher Rollout Temperature:ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆæ™‚ã®temperatureã‚’1.6ã¨é«˜ã‚ã«ã—ã€ã‚ˆã‚Šå¤šæ§˜ãªtrajectoryãŒç”Ÿæˆã•ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ã“ã¨ã§æ¢ç´¢ã‚’ä¿ƒã™<br><br>ã¨ã„ã£ãŸå…¨ä½“çš„ã«æ¢ç´¢ã‚’å¼·ã‚ã‚‹ã‚ˆã†ãªèª¿æ•´ã‚’è¡Œãªã£ã¦ã„ã‚‹æ¨¡æ§˜ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<a class="button" href="articles/EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2025-09-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2766" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] TA-VLA: Elucidating the Design Space of Torque-aware  Vision-Language-Action Models, Zongzheng Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒˆãƒ«ã‚¯ä¿¡å·ã‚’çµ±åˆã—ãŸè¦–è¦š-è¨€èª-ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆVLAï¼‰ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã—ã€ãƒ‡ã‚³ãƒ¼ãƒ€ã«ãƒˆãƒ«ã‚¯ã‚¢ãƒ€ãƒ—ã‚¿ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§æ€§èƒ½å‘ä¸Šã‚’å®Ÿç¾ã€‚ã•ã‚‰ã«ã€ãƒˆãƒ«ã‚¯ã‚’è£œåŠ©å‡ºåŠ›ã¨ã—ã¦äºˆæ¸¬ã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨è¡¨ç¾ã‚’å¼·åŒ–ã€‚æ¥è§¦ãŒè±Šå¯Œãªæ“ä½œãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã®å®Ÿé¨“ã«ã‚ˆã‚Šã€ææ¡ˆæ‰‹æ³•ã®æœ‰åŠ¹æ€§ã‚’æ¤œè¨¼ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://zzongzheng0918.github.io/Torque-Aware-VLA.github.io/" target="_blank" rel="noopener noreferrer">https://zzongzheng0918.github.io/Torque-Aware-VLA.github.io/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/haozhao_airsun/status/1965819340328153198?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2660" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] EmbodiedOneVision: Interleaved Vision-Text-Action Pretraining for  General Robot Control, Delin Qu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- EO-Roboticsã¯ã€è¦–è¦š-ãƒ†ã‚­ã‚¹ãƒˆ-è¡Œå‹•ã®äº¤äº’ã®äº‹å‰å­¦ç¿’ã‚’é€šã˜ã¦ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ¨è«–ã¨ãƒ­ãƒœãƒƒãƒˆåˆ¶å¾¡ã‚’å®Ÿç¾ã™ã‚‹çµ±ä¸€ãƒ¢ãƒ‡ãƒ«EO-1ã¨ã€150ä¸‡ä»¥ä¸Šã®ã‚µãƒ³ãƒ—ãƒ«ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆEO-Data1.5Mã‹ã‚‰æ§‹æˆã•ã‚Œã‚‹ã€‚EO-1ã¯ã€ç„¡å·®åˆ¥ã«å‡¦ç†ã™ã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ´»ç”¨ã—ã€ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ãªãƒ­ãƒœãƒƒãƒˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆã‚’å¯èƒ½ã«ã™ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ã‚ªãƒ¼ãƒ—ãƒ³ãƒ¯ãƒ¼ãƒ«ãƒ‰ã§ã®ç†è§£ã¨ä¸€èˆ¬åŒ–ã«ãŠã‘ã‚‹åŠ¹æœãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="http://eo-robotics.ai/eo-1" target="_blank" rel="noopener noreferrer">http://eo-robotics.ai/eo-1</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/embodiedairead/status/1963036501429911907?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2025-08-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2433" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Latent Policy Barrier: Learning Robust Visuomotor Policies by Staying  In-Distribution, Zhanyi Sun+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Latent Policy Barrierï¼ˆLPBï¼‰ã‚’ææ¡ˆã—ã€è¦–è¦šé‹å‹•ãƒãƒªã‚·ãƒ¼ã®å …ç‰¢æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚LPBã¯å°‚é–€å®¶ã®ãƒ‡ãƒ¢ã®æ½œåœ¨åŸ‹ã‚è¾¼ã¿ã‚’å®‰å…¨ãªçŠ¶æ…‹ã¨å±é™ºãªçŠ¶æ…‹ã«åˆ†ã‘ã€å°‚é–€å®¶ã®æ¨¡å€£ã¨OODã®å›å¾©ã‚’åˆ¥ã€…ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã§å‡¦ç†ã€‚ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ãƒ¢ãƒ‡ãƒ«ãŒå°†æ¥ã®æ½œåœ¨çŠ¶æ…‹ã‚’äºˆæ¸¬ã—ã€å°‚é–€å®¶ã®åˆ†å¸ƒå†…ã«ç•™ã¾ã‚‹ã‚ˆã†æœ€é©åŒ–ã€‚ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨å®Ÿä¸–ç•Œã®å®Ÿé¨“ã§ã€LPBã¯ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ã‚’é«˜ã‚ã€ä¿¡é ¼æ€§ã®ã‚ã‚‹æ“ä½œã‚’å®Ÿç¾ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/songshuran/status/1956104656888979838?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>pj page: 


<a href="https://project-latentpolicybarrier.github.io/" target="_blank" rel="noopener noreferrer">https://project-latentpolicybarrier.github.io/</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2025-07-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2257" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] What Matters in Learning from Large-Scale Datasets for Robot   Manipulation, Vaibhav Saxena+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ã«ãŠã‘ã‚‹å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ§‹æˆã«é–¢ã™ã‚‹ä½“ç³»çš„ãªç†è§£ã‚’æ·±ã‚ã‚‹ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’é–‹ç™ºã—ã€å¤šæ§˜æ€§ã®é‡è¦ãªè¦ç´ ã‚’ç‰¹å®šã€‚ç‰¹ã«ã€ã‚«ãƒ¡ãƒ©ã®ãƒãƒ¼ã‚ºã‚„ç©ºé–“çš„é…ç½®ãŒãƒ‡ãƒ¼ã‚¿åé›†ã®å¤šæ§˜æ€§ã¨æ•´åˆæ€§ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‹ã‚‰ã®æ´å¯ŸãŒå®Ÿä¸–ç•Œã§ã‚‚æœ‰åŠ¹ã§ã‚ã‚Šã€ææ¡ˆã—ãŸå–å¾—æˆ¦ç•¥ã¯æ—¢å­˜ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã‚’æœ€å¤§70%ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç™ºæ®ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/saxenavaibhav11/status/1946209076305691084?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…ƒãƒã‚¹ãƒˆã«è‘—è€…ã«ã‚ˆã‚‹è©³ç´°ãªè§£èª¬ã‚¹ãƒ¬ãƒƒãƒ‰ãŒã‚ã‚‹ã®ã§å‚ç…§ã®ã“ã¨ã€‚<br><img src="https://github.com/user-attachments/assets/175bc31f-de80-4ad6-aa92-afacc1328345" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/CVPR.html" target="_blank" rel="noopener noreferrer">#CVPR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<a class="button" href="articles/EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2023-12-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1202" target="_blank" rel="noopener noreferrer" class="title-link">Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision,   Language, Audio, and Action, Jiasen Lu+, N_A, CVPR'24</a>
<span class="snippet"><span>GPT Summary</span>- Unified-IO 2ã¯ã€æœ€åˆã®è‡ªå·±å›å¸°å‹ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€ç”»åƒã€ãƒ†ã‚­ã‚¹ãƒˆã€éŸ³å£°ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç†è§£ã—ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ç•°ãªã‚‹ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’çµ±ä¸€ã™ã‚‹ãŸã‚ã«ã€å…±æœ‰ã®æ„å‘³ç©ºé–“ã«å…¥åŠ›ã¨å‡ºåŠ›ã‚’é…ç½®ã—ã€å˜ä¸€ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ»ãƒ‡ã‚³ãƒ¼ãƒ€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã§å‡¦ç†ã—ã¾ã™ã€‚ã•ã¾ã–ã¾ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ”¹å–„ã‚’ææ¡ˆã—ã€å¤§è¦æ¨¡ãªãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªäº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚Unified-IO 2ã¯ã€GRITãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å«ã‚€35ä»¥ä¸Šã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç”»åƒã€ãƒ†ã‚­ã‚¹ãƒˆã€éŸ³å£°ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç†è§£ã§ãã‚‹åˆã‚ã¦ã®autoregressive modelã€‚AllenAI</p>
<p>ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³<br><img src="https://github.com/user-attachments/assets/4282ffb0-18f1-40c9-b6d7-f004d03b8382" alt="image" loading="lazy"><br><br>ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã«æ‹¡å¼µã—ãŸã“ã¨ã§ã€è¨“ç·´ãŒéå¸¸ã«ä¸å®‰å®šã«ãªã£ãŸãŸã‚ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¸Šã§ã„ãã¤ã‹ã®å·¥å¤«ã‚’åŠ ãˆã¦ã„ã‚‹:<br><br>- 2D Rotary Embedding<br>  - Positional Encodingã¨ã—ã¦RoPEã‚’æ¡ç”¨<br>  - ç”»åƒã®ã‚ˆã†ãª2æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®å ´åˆã¯RoPEã‚’2æ¬¡å…ƒã«æ‹¡å¼µã™ã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€ä½ç½®(i, j)ã®ãƒˆãƒ¼ã‚¯ãƒ³ã«ã¤ã„ã¦ã¯ã€Q, Kã®embeddingã‚’åŠåˆ†ã«åˆ†å‰²ã—ã¦ã€ãã‚Œãã‚Œã«å¯¾ã—ã¦ç‹¬ç«‹ã«i, jã®RoPE Embeddingã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§i, jåŒæ–¹ã®æƒ…å ±ã‚’çµ„ã¿è¾¼ã‚€ã€‚<br>- QK Normalization<br>  - image, audioã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’çµ„ã¿è¾¼ã‚€ã“ã¨ã§MHAã®logitsãŒéå¸¸ã«å¤§ãããªã‚Šatteetion weightãŒ0/1ã®æ¥µç«¯ãªå€¤ã‚’ã¨ã‚‹ã‚ˆã†ã«ãªã‚Šè¨“ç·´ã®ä¸å®‰å®šã•ã«ã¤ãªãŒã£ãŸã€‚ã“ã®ãŸã‚ã€dot product attentionã‚’é©ç”¨ã™ã‚‹å‰ã«LayerNormã‚’çµ„ã¿è¾¼ã‚“ã ã€‚<br>- Scaled Cosine Attention<br>  - Image Historyãƒ¢ãƒ€ãƒªãƒ†ã‚£ã«ãŠã„ã¦å›ºå®šé•·ã®Embeddingã‚’å¾—ã‚‹ãŸã‚ã«Perceiver Resamplerã‚’æ‰±ã£ãŸã¦ã„ã‚‹ãŒã€ã“ã¡ã‚‰ã‚‚ä¸Šè¨˜ã¨åŒæ§˜ã«Attentionã®logitsãŒæ¥µç«¯ã«å¤§ãããªã£ãŸãŸã‚ã€cosineé¡ä¼¼åº¦ã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ãŸScaled Cosine Attention <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2259" target="_blank" rel="noopener noreferrer">[Paper Note] Swin Transformer V2: Scaling Up Capacity and Resolution, Ze Liu+, arXiv'21</a>
 ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ã€å¤§å¹…ã«è¨“ç·´ã®å®‰å®šæ€§ãŒæ”¹å–„ã•ã‚ŒãŸã€‚<br>- ãã®ä»–<br>  - attention logitsã«ã¯fp32ã‚’é©ç”¨<br>  - äº‹å‰å­¦ç¿’ã•ã‚ŒãŸViTã¨ASTã‚’åŒæ™‚ã«æ›´æ–°ã™ã‚‹ã¨ä¸å®‰å®šã«ã¤ãªãŒã£ãŸãŸã‚ã€äº‹å‰å­¦ç¿’ã®æ®µéšã§ã¯freezeã—ã€instruction tuningã®æœ€å¾Œã«finetuningã‚’å®Ÿæ–½<br><br><img src="https://github.com/user-attachments/assets/74c8fa3a-8fb5-4785-8dd3-6a8cf3c7cfeb" alt="image" loading="lazy"></p>
<p>ç›®çš„é–¢æ•°ã¨ã—ã¦ã¯ã€Mixture of Denoisers (<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1424" target="_blank" rel="noopener noreferrer">UL2: Unifying Language Learning Paradigms, Yi Tay+, N/A, ICLR'23</a>
)ã«ç€æƒ³ã‚’å¾—ã¦ã€Multimodal Mixture of Denoisersã‚’ææ¡ˆã€‚MoDã§ã¯ã€<br>- \[R\]: é€šå¸¸ã®span corruption (1--5 tokenç¨‹åº¦ã®spanã‚’maskã™ã‚‹)<br>- \[S\]: causal language modeling (inputã‚’2ã¤ã®ã‚µãƒ–ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«åˆ†å‰²ã—ã€å‰æ–¹ã‹ã‚‰å¾Œæ–¹ã‚’äºˆæ¸¬ã™ã‚‹ã€‚å‰æ–¹éƒ¨åˆ†ã¯Bi-directionalã§ã‚‚å¯)<br>- \[X\]: extreme span corruption (12&gt;=tokenç¨‹åº¦ã®spanã‚’maskã™ã‚‹)<br><br>ã®3ç¨®é¡ãŒææ¡ˆã•ã‚Œã¦ãŠã‚Šã€ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã”ã¨ã«ã“ã‚Œã‚‰ã‚’ä½¿ã„åˆ†ã‘ã‚‹:<br>- text modality: UL2 (<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1424" target="_blank" rel="noopener noreferrer">UL2: Unifying Language Learning Paradigms, Yi Tay+, N/A, ICLR'23</a>
)ã‚’è¸è¥²<br>- image, audioãŒtargetã®å ´åˆ: 2ã¤ã®é¡ä¼¼ã—ãŸãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’å®šç¾©ã—åˆ©ç”¨<br>  - \[R\]: patchã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«x%ãƒã‚¹ã‚¯ã—re-constructã™ã‚‹<br>  - \[S\]: inputã®targetã¨ã¯ç•°ãªã‚‹ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®ã¿ã®æƒ…å ±ã‹ã‚‰ã€targetãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’ç”Ÿæˆã™ã‚‹<br><br>è¨“ç·´æ™‚ã«ã¯ prefixã¨ã—ã¦modality token \[Text\], \[Image\], \[Audio\] ã¨paradigm token \[R\], \[S\], \[X\] ã‚’ã‚¿ã‚¹ã‚¯ã‚’æŒ‡ç¤ºã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã¨ã—ã¦åˆ©ç”¨ã—ã¦ã„ã‚‹ã€‚</p>
<p>ã¾ãŸã€image, audioã®ãƒã‚¹ã‚¯éƒ¨åˆ†ã®denoisingã‚’autoregressive modelã§å®Ÿæ–½ã™ã‚‹éš›ã«ã¯æ™®é€šã«ã‚„ã‚‹ã¨decoderå´ã§ãƒªãƒ¼ã‚¯ãŒç™ºç”Ÿã™ã‚‹(a)ã€‚ã“ã‚Œã‚’é˜²ãã«ã¯ã€Encoderå´ã§ãƒã‚¹ã‚¯ã•ã‚Œã¦ã„ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ã€Decoderå´ã§teacher-forcingã™ã‚‹éš›ã«ã®å…¨ã¦ãƒã‚¹ã‚¯ã™ã‚‹æ–¹æ³•(b)ãŒã‚ã‚‹ãŒã€ã“ã®å ´åˆã€ç”Ÿæˆã‚¿ã‚¹ã‚¯ã¨denoisingã‚¿ã‚¹ã‚¯ãŒç›¸äº’ã«å¹²æ¸‰ã—ã¦ã—ã¾ã„ã†ã¾ãå­¦ç¿’ã§ããªããªã£ã¦ã—ã¾ã†ï¼ˆç”Ÿæˆã‚¿ã‚¹ã‚¯ã§ã¯é€šå¸¸Decoderã®inputã¨ã—ã¦[mask]ãŒå…¥åŠ›ã•ã‚Œæ¬¡ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ã€ã¨ã„ã£ãŸã“ã¨ã¯èµ·ããˆãªã„ãŒã€æ„šç›´ã«(b)ã‚’ã‚„ã‚‹ã¨ãã†ãªã£ã¦ã—ã¾ã†ï¼‰ã€‚ã®ã§ã€(c)ã«ç¤ºã—ãŸã‚ˆã†ã«ã€ãƒã‚¹ã‚¯ã•ã‚Œã¦ã„ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’inputã¨ã—ã¦ç”Ÿæˆã—ãªã‘ã‚Œã°ãªã‚‰ãªã„æ™‚ã ã‘ã€ãƒã‚¹ã‚¯ã‚’è§£é™¤ã—ã¦decoderå´ã«inputã™ã‚‹ã€ã¨ã„ã†æ–¹æ³• (Dynamic Masking) ã§ã“ã®å•é¡Œã«å¯¾å‡¦ã—ã¦ã„ã‚‹ã€‚<br>&lt;img width="597" height="394" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/0dba8d5d-0c93-4c56-852b-fce9869428e7"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/0dba8d5d-0c93-4c56-852b-fce9869428e7"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/CoRL.html" target="_blank" rel="noopener noreferrer">#CoRL</a>
<span class="issue_date">Issue Date: 2025-10-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3422" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] See, Hear, and Feel: Smart Sensory Fusion for Robotic Manipulation, Hao Li+, CoRL'22, 2022.12</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¦–è¦šã€è´è¦šã€è§¦è¦šã®3ã¤ã®æ„Ÿè¦šãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’èåˆã•ã›ãŸãƒ­ãƒœãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã€è¤‡é›‘ãªæ“ä½œã‚¿ã‚¹ã‚¯ã®è§£æ±ºã«ãŠã‘ã‚‹å¤šæ„Ÿè¦šçŸ¥è¦šã®é‡è¦æ€§ã‚’ç¤ºã—ã¾ã™ã€‚å¯†ãªãƒ‘ãƒƒã‚­ãƒ³ã‚°ã¨æ³¨ãã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€è¦–è¦šã¯å…¨ä½“çŠ¶æ…‹ã‚’ç¤ºã™ä¸€æ–¹ã§é®è”½ã®å½±éŸ¿ã‚’å—ã‘ã€éŸ³å£°ã¯é‡è¦ãªç¬é–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã—ã€è§¦è¦šã¯å±€æ‰€çš„ãªã‚¸ã‚ªãƒ¡ãƒˆãƒªã‚’æä¾›ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ææ¡ˆã—ãŸãƒ­ãƒœãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ ã¯å¾“æ¥ã®æ‰‹æ³•ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç™ºæ®ã—ã¾ã™ã€‚</span>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<span class="issue_date">Issue Date: 2025-10-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3279" target="_blank" rel="noopener noreferrer" class="title-link">State of VLA Research at ICLR 2026, Moritz Reuss, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/moritz_reuss/status/1978048330279408054?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="articles/CoRL.html" target="_blank" rel="noopener noreferrer">#CoRL</a>
<span class="issue_date">Issue Date: 2025-10-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3124" target="_blank" rel="noopener noreferrer" class="title-link">CoRL2025é€Ÿå ±, robotpaper.challenge, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/robotpaper_c/status/1974126462258360654?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<span class="issue_date">Issue Date: 2025-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3024" target="_blank" rel="noopener noreferrer" class="title-link">RoboArena: Distributed Real-World Evaluation of Generalist Robot Policies, Atreya+, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/svlevine/status/1972220074259046835?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<a class="button" href="articles/EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2025-09-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3007" target="_blank" rel="noopener noreferrer" class="title-link">RDT2: Enabling Zero-Shot Cross-Embodiment Generalization by Scaling Up UMI Data, RDT Team, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/songming_liu/status/1971643908372550108?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ­ãƒœãƒƒãƒˆã‚¢ãƒ¼ãƒ ã®ã•ã¾ã–ã¾ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’zeroshotã§å®Ÿç¾ã§ãã‚‹åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚‰ã—ã„</p>
<p>code:


<a href="https://github.com/thu-ml/RDT2" target="_blank" rel="noopener noreferrer">https://github.com/thu-ml/RDT2</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<a class="button" href="articles/EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2025-09-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2846" target="_blank" rel="noopener noreferrer" class="title-link">A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning, Zhai+, 2025.09</a>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://vlac.intern-ai.org.cn" target="_blank" rel="noopener noreferrer">https://vlac.intern-ai.org.cn</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/embodiedairead/status/1968555311029158322?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="articles/Chip.html" target="_blank" rel="noopener noreferrer">#Chip</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<a class="button" href="articles/EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2025-09-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2633" target="_blank" rel="noopener noreferrer" class="title-link">AIãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹æ¤œè¨ä¼š ç¬¬1å›äº‹å‹™å±€è³‡æ–™, çµŒæ¸ˆç”£æ¥­çœ, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gclue_akira/status/1962298561451958546?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Nvidiaã®æŠ•è³‡é¡ãŒæ–‡å­—é€šã‚Šæ¡é•ã„ã®5000å„„ãƒ‰ãƒ«</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<a class="button" href="articles/EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2025-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2416" target="_blank" rel="noopener noreferrer" class="title-link">Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications, Kawaharazuka+, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kkawaharazuka/status/1955424422472642603?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/VariationalAutoEncoder.html" target="_blank" rel="noopener noreferrer">#VariationalAutoEncoder</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/VideoGeneration/Understandings.html" target="_blank" rel="noopener noreferrer">#VideoGeneration/Understandings</a>
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<a class="button" href="articles/EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2025-08-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2404" target="_blank" rel="noopener noreferrer" class="title-link">RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation, Jiang+, Alibaba, 2025.08</a>
<span class="snippet"><span>Comment</span><p>TL;DRã¯ä¸‹è¨˜ã€‚<br><br>&gt; We introduce RynnVLA-001, a vision-language-action model built upon large-scale video generative pre-training.<br>&gt; - RynnVLA-001 is pretrained on ~12M ego-centric manipulation videos.<br>&gt; - We unify next-frame prediction and next-action prediction into a single transformer.<br>&gt; - We train a lightweight VAE to accurately compress action chunks into action embeddings.<br>&gt; - Our RynnVLA-001 outperforms Pi-0 and GR00T-N1.5, in terms of both real-world task success rate and instruction-following capability.<br><br>ã¾ãšã€11.93Mã®ä¸€äººç§°è¦–ç‚¹ã§ã®äººé–“ãŒæ“ä½œï¼ˆç‰¹ã«æ‰‹ã®æ“ä½œï¼‰ã‚’ã™ã‚‹å‹•ç”»ã¨ã€244Kã®robotãŒæ“ä½œã‚’ã™ã‚‹å‹•ç”»ã§Transformerã‚’äº‹å‰å­¦ç¿’ã™ã‚‹ã€‚ã“ã®ã¨ãã€actionãƒ©ãƒ™ãƒ«ã¯ä¸€åˆ‡ç”¨ã„ãšã€pixelã®æƒ…å ±ã‹ã‚‰ç‰©ç†ä¸–ç•Œã®ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã‚’ç†è§£ã•ã›ã‚‹ã€‚ç¶šã„ã¦ã€Action Chunksï¼ˆè¤‡æ•°ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®å°‘é‡ã®ã‹ãŸã¾ã‚Šï¼‰ã‚’ã€dense embeddingã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹VAEã‚’å­¦ç¿’ã™ã‚‹ã€‚ãƒãƒ£ãƒ³ã‚¯ã‚’ç”¨ã„ã‚‹ç†ç”±ã¯ã€ãƒ”ã‚¯ã‚»ãƒ«ã®å¤‰åŒ–ãŒå¾®å°ãªå ´åˆã€åŒã˜ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒé€£ç¶šã—ã¦äºˆæ¸¬ã•ã‚Œã¦ã—ã¾ã„stuckã—ã‚ã—ã¾ã†ç¾è±¡ã‚’é˜²ãã“ã¨ã€äºˆæ¸¬ã®åŠ¹ç‡ãŒè‰¯ã„ã‹ã‚‰ã¨ã®ã“ã¨ã€‚ã“ã‚Œã«ã‚ˆã‚ŠVLAã¯å˜ä¸€ã®embedding vectorã‚’äºˆæ¸¬ã™ã‚‹ã ã‘ã§ã€ä¸€è²«æ€§ã®ã‚ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç³»åˆ—ã«ãƒ‡ã‚³ãƒ¼ãƒ‰ã§ãã‚‹ã€‚æœ€å¾Œã«ã€step1ã§å­¦ç¿’ã—ãŸvideo generationãƒ¢ãƒ‡ãƒ«ã¨ã€step2ã§å­¦ç¿’ã—ãŸVAEã«ã‚ˆã‚‹action representationã‚’çµ±åˆã™ã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€next frame predictionï¼ˆvisual tokenã‚’äºˆæ¸¬; cross entropy lossï¼‰ã¨next action predictionï¼ˆaction edbeddingã‚’äºˆæ¸¬ã™ã‚‹ï¼‰ã‚’çµ±åˆã—ã¦å­¦ç¿’ã™ã‚‹ã€‚action embeddingã¯continuousãªãƒ™ã‚¯ãƒˆãƒ«ãªã®ã§ç•°ãªã‚‹ãƒ˜ãƒƒãƒ‰ã‚’ç”¨æ„ã—ã¦å­¦ç¿’ã™ã‚‹ï¼ˆL1 Loss)ã€‚inferenceæ™‚ã¯RGBã®observationã¨ã€ãƒ†ã‚­ã‚¹ãƒˆã«ã‚ˆã‚‹instructionã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚Šã€action embeddingã‚’äºˆæ¸¬ã™ã‚‹ã€‚action edbeddingã¯VAE decoderã«æ¸¡ã•ã‚Œã€low levelãªactionç³»åˆ—ã«å¤‰æ›ã•ã‚Œã‚‹ã€‚robotã¯äºˆæ¸¬ã•ã‚ŒãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã€observationãŒå¤‰åŒ–ã™ã‚‹ã®ã§ã¾ãŸäºˆæ¸¬ã™ã‚‹ã€ã¨ã„ã£ãŸiterationã‚’å®Ÿæ–½ã™ã‚‹ã€‚visual tokenã«ã‚ˆã‚‹äºˆæ¸¬ã¯ä¸è¦ãªã®ã§ã€è¨ˆç®—åŠ¹ç‡ã®è¦³ç‚¹ã‹ã‚‰å®Ÿæ–½ã—ãªã„ã€‚<br><br><img src="https://github.com/user-attachments/assets/4be5a5da-8c9c-4735-a1ee-ac3da52c2530" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1955043541299728607?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>HF:


<a href="https://huggingface.co/Alibaba-DAMO-Academy/RynnVLA-001-7B-Base" target="_blank" rel="noopener noreferrer">https://huggingface.co/Alibaba-DAMO-Academy/RynnVLA-001-7B-Base</a>


</p></span><br><br>
<button onclick="hideContent(0)" style="display: none;">hide</button>
</div>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<script>
  document.addEventListener('DOMContentLoaded', function() {
    const tweets = document.querySelectorAll('.tweet-embed[data-embed]');

    if ('IntersectionObserver' in window) {
      const observer = new IntersectionObserver((entries, obs) => {
        entries.forEach(entry => {
          if (entry.isIntersecting) {
            const el = entry.target;
            const html = el.getAttribute('data-embed');
            if (html) {
              const placeholder = el.querySelector('.tweet-placeholder');
              if (placeholder) placeholder.remove();

              el.innerHTML = html.trim();

              if (window.twttr?.widgets?.load) {
                window.twttr.widgets.load(el);
              }
            }
            obs.unobserve(el); // å‡¦ç†æ¸ˆã¿ã¯ç›£è¦–è§£é™¤
          }
        });
      }, {
        rootMargin: '500px 0px', // ç”»é¢æ‰‹å‰200pxã§èª­ã¿è¾¼ã¿é–‹å§‹
        threshold: 0
      });

      tweets.forEach(tweet => observer.observe(tweet));

    } else {
      // IntersectionObserveræœªå¯¾å¿œãƒ–ãƒ©ã‚¦ã‚¶ç”¨ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
      function lazyLoadFallback() {
        tweets.forEach(el => {
          if (el.getAttribute('data-embed') && el.getBoundingClientRect().top < window.innerHeight) {
            const html = el.getAttribute('data-embed');
            const loadingImg = el.querySelector('.tweet-loading');
            if (loadingImg) loadingImg.remove();
            el.innerHTML = html.trim();
            el.removeAttribute('data-embed');
            if (window.twttr?.widgets?.load) {
              window.twttr.widgets.load(el);
            }
          }
        });
      }
      window.addEventListener('scroll', lazyLoadFallback);
      lazyLoadFallback();
    }
  });
</script>



    </div>

</article>
<div class="post-nav">
<a class="previous" href="/paper_notes/articles/RewardModel.html" title="RewardModelã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">RewardModelã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§</a><a class="next" href="/paper_notes/articles/Robustness.html" title="Robustnessã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">Robustnessã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§</a>
</div>
<div class="post-related">
      <div>Related Articles</div>
      <ul>
        <li class="">
          <a class="post-link" href="/paper_notes/articles/KnowledgeGraph.html" title="KnowledgeGraphã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">
            KnowledgeGraphã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/TwoTowerModel.html" title="TwoTowerModelã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">
            TwoTowerModelã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/MatrixFactorization.html" title="MatrixFactorizationã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">
            MatrixFactorizationã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/Non-Determinism.html" title="Non-Determinismã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">
            Non-Determinismã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
</ul>
    </div>
<div class="post-comments"></div></section>
</div>


  </section>
  <section class="sidebar" style="margin-left: 15px;">
    <!-- Get sidebar items --><style type="text/css" media="screen">
.post-menu ul {
  list-style: none;
  padding: 0;
  margin: 0;
}
</style>

<div class="post-menu">
  <div class="post-menu-title">TOC</div>
  <div class="post-menu-content"></div>
</div>

<script>
  function generateContent() {
    var menu = document.querySelector(".post-menu");
    var menuContent =  menu.querySelector(".post-menu-content");
    var headings = document.querySelector(".post-content").querySelectorAll("h2, h3, h4, h5, h6");

    // Hide menu when no headings
    if (headings.length === 0) {
      return menu.style.display = "none";
    }

    // Generate post menu
    var menuHTML = '';
    for (var i = 0; i < headings.length; i++) {
      var h = headings[i];
      menuHTML += (
        '<li class="h-' + h.tagName.toLowerCase() + '">'
        + '<a href="#h-' + h.getAttribute('id') + '">' + h.textContent + '</a></li>');
    }

    menuContent.innerHTML = '<ul>' + menuHTML + '</ul>';

    // The header element
    var header = document.querySelector('header.site-header');

    function doMenuCollapse(index, over_items) {
      var items = menuContent.firstChild.children;

      if (over_items == undefined) {
        over_items = 20;
      }

      if (items.length < over_items) {
        return;
      }

      var activeItem = items[index];
      var beginItem = activeItem
      var endItem = activeItem
      var beginIndex = index;
      var endIndex = index + 1;
      while (beginIndex >= 0
        && !items[beginIndex].classList.contains('h-h2')) {
        beginIndex -= 1;
      }
      while (endIndex < items.length
        && !items[endIndex].classList.contains('h-h2')) {
        endIndex += 1;
      }
      for (var i = 0; i < beginIndex; i++) {
        item = items[i]
        if (!item.classList.contains('h-h2')) {
          item.style.display = 'none';
        }
      }
      for (var i = beginIndex + 1; i < endIndex; i++) {
        item = items[i]
        // if (!item.classList.contains('h-h2')) {
          item.style.display = '';
        // }
      }
      for (var i = endIndex; i < items.length; i++) {
        item = items[i]
        if (!item.classList.contains('h-h2')) {
          item.style.display = 'none';
        }
      }
    }

    // Init menu collapsed
    doMenuCollapse(-1);

    // Active the menu item
    window.addEventListener('scroll', function (event) {
      var lastActive = menuContent.querySelector('.active');
      var changed = true;
      var activeIndex = -1;
      for (var i = headings.length - 1; i >= 0; i--) {
        var h = headings[i];
        var headingRect = h.getBoundingClientRect();
        var headerRect = header.getBoundingClientRect();
        var headerTop = Math.floor(headerRect.top);
        var headerHeight = Math.floor(headerRect.height);
        var headerHeight = headerTop + headerHeight + 20;
        if (headingRect.top <= headerHeight) {
          var id = 'h-' + h.getAttribute('id');
          var a = menuContent.querySelector('a[href="#' + id  + '"]');
          var curActive = a.parentNode;
          if (curActive) {
            curActive.classList.add('active');
            activeIndex = i;
          }
          if (lastActive == curActive) {
            changed = false;
          }
          break;
        }
      }
      if (changed) {
        if (lastActive) {
          lastActive.classList.remove('active');
        }
        doMenuCollapse(activeIndex);
      }
      event.preventDefault();
    });
  }
  generateContent();
</script>
</section>
</div>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/paper_notes/"></data>

  <div class="wrapper">
    <div class="site-footer-inner">
<div>Copyright Â© 2023-current AkihikoWATANABE. The header images and any thumbnail images for the posts were generated by ChatGPT's DALL-E3.</div>
      <div>Powered by <a title="Jekyll is a simple, blog-aware, static site
      generator." href="https://jekyllrb.com/">Jekyll</a> &amp; <a title="Yat, yet
      another theme." href="https://github.com/jeffreytse/jekyll-theme-yat">Yat Theme</a>.</div>
      <div class="footer-col rss-subscribe">Subscribe <a href="/paper_notes/feed.xml">via RSS</a>
</div>
    </div>
  </div>
</footer>
</body>
  </html>
