<!DOCTYPE html>
<html lang="ja">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-translate-customization" content="108d9124921d80c3-80e20d618ff053c8-g4f02ec6f3dba68b7-c">
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>MachineTranslationに関する論文・技術記事メモの一覧 | わたしのべんきょうノート</title>
<meta name="generator" content="Jekyll v3.10.0">
<meta property="og:title" content="MachineTranslationに関する論文・技術記事メモの一覧">
<meta name="author" content="AkihikoWATANABE">
<meta property="og:locale" content="ja">
<meta name="description" content="MachineTranslation #Metrics #Pocket #NLP #Dataset #LanguageModel #Evaluation #Reference-free #EMNLP #LowResource">
<meta property="og:description" content="MachineTranslation #Metrics #Pocket #NLP #Dataset #LanguageModel #Evaluation #Reference-free #EMNLP #LowResource">
<link rel="canonical" href="http://akihikowatanabe.github.io/paper_notes/articles/MachineTranslation.html">
<meta property="og:url" content="http://akihikowatanabe.github.io/paper_notes/articles/MachineTranslation.html">
<meta property="og:site_name" content="わたしのべんきょうノート">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2025-11-23T00:56:27+00:00">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="MachineTranslationに関する論文・技術記事メモの一覧">
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"AkihikoWATANABE"},"dateModified":"2025-11-23T00:56:27+00:00","datePublished":"2025-11-23T00:56:27+00:00","description":"MachineTranslation #Metrics #Pocket #NLP #Dataset #LanguageModel #Evaluation #Reference-free #EMNLP #LowResource","headline":"MachineTranslationに関する論文・技術記事メモの一覧","mainEntityOfPage":{"@type":"WebPage","@id":"http://akihikowatanabe.github.io/paper_notes/articles/MachineTranslation.html"},"url":"http://akihikowatanabe.github.io/paper_notes/articles/MachineTranslation.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="icon" href="">
  <link rel="canonical" href="http://akihikowatanabe.github.io">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-noto-sans@0.0.72/index.min.css">
  <link rel="stylesheet" href="/paper_notes/assets/css/main.css">
  <link rel="stylesheet" href="/paper_notes/assets/css/custom_button.css">
  <script src="/paper_notes/assets/js/main.js"></script>
  <script src="https://d3js.org/d3.v5.min.js"></script><link type="application/atom+xml" rel="alternate" href="http://akihikowatanabe.github.io/paper_notes/feed.xml" title="わたしのべんきょうノート">
<script>
  function showMore(index) {
    const contentDivs = document.getElementsByClassName('hidden-content');
    const contentDiv = contentDivs[index];

    if (contentDiv) {
      contentDiv.style.display = "block";
          
      // このボタンの参照を取得して非表示にします
      const moreButtons = document.querySelectorAll('button[onclick^="showMore"]');
      const moreButton = moreButtons[index];
      if (moreButton) {
        moreButton.style.display = "none";
      }
          
      // hideボタンの参照を取得して表示します
      const hideButton = contentDiv.querySelector('button[onclick^="hideContent"]');
      if (hideButton) {
        hideButton.style.display = "block";
      }
    }
  }

  function hideContent(index) {
    const contentDivs = document.getElementsByClassName('hidden-content');
    const contentDiv = contentDivs[index];

    if (contentDiv) {
      contentDiv.style.display = "none";
  
      // moreボタンの参照を取得して表示します
      const moreButtons = document.querySelectorAll('button[onclick^="showMore"]');
      const moreButton = moreButtons[index];
      if (moreButton) {
        moreButton.style.display = "block";
      }
  
      // このボタンを隠します
      const hideButtons = document.querySelectorAll('button[onclick^="hideContent"]');
      const hideButton = hideButtons[index];
      if (hideButton) {
        hideButton.style.display = "none";
      }
    }
  }
</script><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/default.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js"></script>
<!-- and it's easy to individually load additional languages -->
<script charset="UTF-8" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/languages/go.min.js" async></script>



















<script>
// Init highlight js
document.addEventListener('DOMContentLoaded', function(event) {
  var els = document.querySelectorAll('pre code')

  function addLangData(block) {
    var outer = block.parentElement.parentElement.parentElement;
    var lang = block.getAttribute('data-lang');
    for (var i = 0; i < outer.classList.length; i++) {
      var cls = outer.classList[i];
      if (cls.startsWith('language-')) {
        lang = cls;
        break;
      }
    }
    if (!lang) {
      cls = block.getAttribute('class');
      lang = cls ? cls.replace('hljs ', '') : '';
    }
    if (lang.startsWith('language-')) {
      lang = lang.substr(9);
    }
    block.setAttribute('class', 'hljs ' + lang);
    block.parentNode.setAttribute('data-lang', lang);
  }

  function addBadge(block) {
    var enabled = ('true' || 'true').toLowerCase();
    if (enabled == 'true') {
      var pre = block.parentElement;
      pre.classList.add('badge');
    }
  }

  function handle(block) {
    addLangData(block);
    addBadge(block)
    hljs.highlightBlock(block);
  }

  for (var i = 0; i < els.length; i++) {
    var el = els[i];
    handle(el);
  }
});
</script>

<style>
  /* code language badge */
  pre.badge::before {
    content: attr(data-lang);
    color: #fff;
    background-color: #ff4e00;
    padding: 0 .5em;
    border-radius: 0 2px;
    text-transform: uppercase;
    text-align: center;
    min-width: 32px;
    display: inline-block;
    position: absolute;
    right: 0;
  }

  /* fix wrong badge display for firefox browser */
  code > table pre::before {
    display: none;
  }
</style>
<script src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/umd/photoswipe-lightbox.umd.min.js" async></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/umd/photoswipe.umd.min.js" async></script>
<link href="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/photoswipe.min.css" rel="stylesheet">
<style>
  .pswp .pswp__container .pswp__img {
    background-color: white;
  }
</style>

<script>
  function initPhotoSwipe() {
    let customOptions = {};

    try {
      const data = `{"gallery"=>"section.main", "children"=>"a.photo-swipe", "bgOpacity"=>0.8, "padding"=>{"top"=>20, "bottom"=>40, "left"=>100, "right"=>100}}`.replaceAll("=>", ":");
      customOptions = JSON.parse(data);
    } catch (e) {
      console.info("Invalid custom photo previewer options! " + e.message);
    }

    // Define object and gallery options
    const options = Object.assign(
      {
        gallery: "section.main",
        children: "a.photo-swipe",
        photo_scale: 2,
        // dynamic import is not supported in UMD version
        pswpModule: PhotoSwipe,
      },
      customOptions
    );

    const galleryEl = document.querySelector(options.gallery);
    if (!galleryEl) {
      return;
    }

    const imgEls = [];
    const els = galleryEl.querySelectorAll("img:not(.emoji)");
    els.forEach((el) => {
      if (el.src.trim() == "") {
        return;
      }
      if (!imgEls.includes(el)) {
        imgEls.push(el);
      }
    });

    if (imgEls.length === 0) {
      return;
    }

    imgEls.forEach((imgEl) => {
      imgEl.outerHTML = `
      <a class="photo-swipe"
        href="${imgEl.src}"
        data-pswp-width="${
          Math.max(imgEl.naturalWidth, imgEl.width) * options.photo_scale
        }"
        data-pswp-height="${
          Math.max(imgEl.naturalHeight, imgEl.height) * options.photo_scale
        }"
        data-pswp-caption="${imgEl.getAttribute("caption") || imgEl.alt}"
        target="_blank">
        ${imgEl.outerHTML}
      </a>`;
    });

    // Initialize PhotoSwipe 5
    var lightbox = new PhotoSwipeLightbox(options);

    lightbox.init();
  }

  window.addEventListener("load", initPhotoSwipe);
</script>
<meta name="google-site-verification" content="u_DTTPcCZ806iq51zgirHyWq3556HUKGq8AQfH91iFI">
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-P70KSB88WH"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-P70KSB88WH');
  </script>

<script>MathJax={"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"svg":{"fontCache":"global"},"svg":{"fontCache":"global"}}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>





































































































































<header class="site-header site-header-transparent" role="banner">

  <div class="wrapper">
    <div class="site-header-inner">
<span class="site-brand"><a class="site-brand-inner" rel="author" href="/paper_notes/">
  <img class="site-favicon" title="わたしのべんきょうノート" src="" onerror="this.style.display='none'">
  わたしのべんきょうノート
</a>
</span><nav class="site-nav">
          <input type="checkbox" id="nav-trigger" class="nav-trigger">
          <label for="nav-trigger">
            <span class="menu-icon">
              <svg viewbox="0 0 18 15" width="18px" height="15px">
                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"></path>
              </svg>
            </span>
          </label>

          <div class="trigger">









<span class="page-link">



<div id="google_translate_element" style="display: none;">
</div>

<span class="ct-language">
  <ul class="list-unstyled ct-language-dropdown">
    
      <li>
        <a href="#" class="lang-select" data-lang="en">
          
          <img src="https://cdn.countryflags.com/thumbs/united-states-of-america/flag-400.png" title="English">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="fr">
          
          <img src="https://cdn.countryflags.com/thumbs/france/flag-400.png" title="French">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="zh-CN">
          
          <img src="https://cdn.countryflags.com/thumbs/china/flag-400.png" title="Chinese(Simple)">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ja">
          
          <img src="https://cdn.countryflags.com/thumbs/japan/flag-400.png" title="Japanese">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ko">
          
          <img src="https://cdn.countryflags.com/thumbs/south-korea/flag-400.png" title="Korean">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ru">
          
          <img src="https://cdn.countryflags.com/thumbs/russia/flag-400.png" title="Russian">
          
        </a>
      </li>
    
  </ul>
</span>

<script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({
    pageLanguage: 'ja',
    autoDisplay: false,
    layout: google.translate.TranslateElement.InlineLayout.VERTICAL
  }, 'google_translate_element');

  // Links to cross-origin destinations are unsafe
  var gll = document.getElementsByClassName('goog-logo-link')[0];
  if (gll) {
    gll.setAttribute('rel', 'noopener');
  }

  function restoreLang() {
    var iframe = document.getElementsByClassName('goog-te-banner-frame')[0];
    if (!iframe) return;

    var innerDoc = iframe.contentDocument || iframe.contentWindow.document;
    var restore_el = innerDoc.getElementsByTagName("button");

    for (var i = 0; i < restore_el.length; i++) {
      if (restore_el[i].id.indexOf("restore") >= 0) {
        restore_el[i].click();
        var close_el = innerDoc.getElementsByClassName("goog-close-link");
        close_el[0].click();
        return;
      }
    }
  }

  function triggerHtmlEvent(element, eventName) {
    var event;
    if (document.createEvent) {
      event = document.createEvent('HTMLEvents');
      event.initEvent(eventName, true, true);
      element.dispatchEvent(event);
    } else {
      event = document.createEventObject();
      event.eventType = eventName;
      element.fireEvent('on' + event.eventType, event);
    }
  }

  var googleCombo = document.querySelector("select.goog-te-combo");
  var langSelect = document.querySelector('.ct-language');
  langSelect.addEventListener('click', function(event) {
    if (!event.target) {
      return;
    }

    var selected = document.querySelector('.ct-language .ct-language-selected');
    if (selected) {
      selected.classList.remove('ct-language-selected');
    }

    var target = event.target;
    while (target && target !== langSelect ) {
      if (target.matches('.lang-select')) {
        break;
      }
      target = target.parentElement;
    }

    if (target && target.matches('.lang-select')) {
      var lang = target.getAttribute('data-lang');
      if (googleCombo.value == lang) {
        restoreLang();
      } else {
        target.parentElement.classList.add('ct-language-selected');
        googleCombo.value = lang;
        triggerHtmlEvent(googleCombo, 'change');
      }
    }

    event.preventDefault();
  });
}
</script>

<script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=googleTranslateElementInit" async></script>
</span>
</div>
        </nav>
</div>
  </div>
</header>

<script>
  function initHeader() {
    var lastScrollY = getScrollPos().y;
    var documentElement = document.documentElement;

    function storeScrollData() {
      var y = getScrollPos().y;documentElement.setAttribute("data-header-transparent", "");var scrollStatus = "";

      if (y <= 0) {
        scrollStatus = "top";
      } else if ((window.innerHeight + y) >= document.body.offsetHeight) {
        scrollStatus = "bottom";
      } else {
        var isScrollDown = (y - lastScrollY > 0) ? true : false;
        scrollStatus = isScrollDown ? "down" : "up";
      }

      lastScrollY = y;
      documentElement.setAttribute("data-scroll-status", scrollStatus);
    }

    window.addEventListener('scroll', function(e) {
      storeScrollData();
    });

    storeScrollData();
  }
  document.addEventListener('DOMContentLoaded', initHeader);
</script>


























































































































































<style>
    html .page-banner .page-banner-img > *:first-child {
      opacity: 0.4;
    }

    html[data-theme="dark"] .page-banner .page-banner-img > *:first-child {
      opacity: 0.2872;
    }
  </style>
<section class="page-banner">
    <div class="page-banner-img">
<div style="background-image: url(/paper_notes/assets/images/banner.png)"></div>
        <img class="img-placeholder" src="/paper_notes/assets/images/banner.png">
</div>
    <div class="wrapper">
      <div class="page-banner-inner">
<header class="post-header">
  <h1 class="post-title p-name" itemprop="name headline">わたしのべんきょうノート</h1>
  <h2 class="post-subtitle">勉強した論文や技術等の情報をGithubのIssueにメモっているひとのブログ。
それなりにメモの量が蓄積されてきたので、一度整理したいなと思いブログはじめてみました！
自然言語処理(NLP), 推薦システム(RecommenderSystem), Educational Data Mining (EDM), Learning Analytics (LA)などの分野のメモが多いと思います。
最近は特にLLMの勉強が多めです :)</h2>

  <div class="post-meta">
    <time class="dt-published" datetime="2025-11-23T00:56:27+00:00" itemprop="datePublished"><i class="fa fa-calendar"></i> Nov 23, 2025
    </time><span class="post-author left-vsplit"><i class="fa fa-pencil"></i> AkihikoWATANABE</span>
    
































    <span class="post-reading-time left-vsplit"><i class="fa fa-clock-o"></i> About 1 hour 32 mins</span>
  </div></header>
</div>
    </div>
  </section><script>
  function hashLocate(hashValue) {
    hashValue = hashValue.replace(/^.*#h-/, '');
    hashValue = decodeURIComponent(hashValue);
    var element = document.getElementById(hashValue);

    if (!element) {
      return;
    }

    var header = document.querySelector('header.site-header');
    var headerRect = header.getBoundingClientRect();
    var headerTop = Math.floor(headerRect.top);
    var headerHeight = Math.floor(headerRect.height);
    var scrollPos = getScrollPos();
    var offsetY = element.offsetTop - (headerTop + headerHeight + 20);

    if (offsetY == scrollPos.y) {
      return;
    }

    if (headerTop == 0  && offsetY > scrollPos.y) {
      offsetY += headerHeight + 2;
    } else if (headerTop < 0  && offsetY < scrollPos.y) {
      offsetY -= headerHeight - 2;
    }

    smoothScrollTo(offsetY);
  }

  // The first event occurred
  window.addEventListener('load', function(event) {
    if (window.location.hash) {
      hashLocate(window.location.hash);
    }
  });

  // The first event occurred
  window.addEventListener('click', function(event) {
    if (event.target.tagName.toLowerCase() == 'a') {
      hashLocate(event.target.getAttribute('href'));
    }
  });
</script>
<div class="theme-toggle">
  <input type="checkbox" id="theme-switch">
  <label for="theme-switch">
    <div class="toggle"></div>
    <div class="names">
      <p class="light">Light</p>
      <p class="dark">Dark</p>
    </div>
  </label>
</div>




<script>
  (function() {
    var sw = document.getElementById('theme-switch');
    var html = document.getElementsByTagName('html')[0];
    var nightModeOption = ('off' || 'auto').toLowerCase();
    var storage = nightModeOption === 'manual'
        ? localStorage
        : sessionStorage;
    var themeData = loadThemeData();

    function saveThemeData(data) {
      storage.setItem('theme', JSON.stringify(data));
    }

    function loadThemeData() {
      var data = storage.getItem('theme');
      try {
        data = JSON.parse(data ? data : '');
      } catch(e) {
        data = { nightShift: undefined, autoToggleAt: 0 };
        saveThemeData(data);
      }
      return data;
    }

    function handleThemeToggle(nightShift) {
      themeData.nightShift = nightShift;
      saveThemeData(themeData);
      html.dataset.theme = nightShift ? 'dark' : 'light';
      setTimeout(function() {
        sw.checked = nightShift ? true : false;
      }, 50);
    }

    function autoThemeToggle() {
      // Next time point of theme toggle
      var now = new Date();
      var toggleAt = new Date();
      var hours = now.getHours();
      var nightShift = hours >= 19 || hours <=7;

      if (nightShift) {
        if (hours > 7) {
          toggleAt.setDate(toggleAt.getDate() + 1);
        }
        toggleAt.setHours(7);
      } else {
        toggleAt.setHours(19);
      }

      toggleAt.setMinutes(0);
      toggleAt.setSeconds(0);
      toggleAt.setMilliseconds(0)

      var delay = toggleAt.getTime() - now.getTime();

      // auto toggle theme mode
      setTimeout(function() {
        handleThemeToggle(!nightShift);
      }, delay);

      return {
        nightShift: nightShift,
        toggleAt: toggleAt.getTime()
      };
    }

    // Listen the theme toggle event
    sw.addEventListener('change', function(event) {
      handleThemeToggle(event.target.checked);
    });

    if (nightModeOption == 'auto') {
      var data = autoThemeToggle();

      // Toggle theme by local setting
      if (data.toggleAt > themeData.autoToggleAt) {
        themeData.autoToggleAt = data.toggleAt;
        handleThemeToggle(data.nightShift);
      } else {
        handleThemeToggle(themeData.nightShift);
      }
    } else if (nightModeOption == 'manual') {
      handleThemeToggle(themeData.nightShift);
    } else {
      var nightShift = themeData.nightShift;
      if (nightShift === undefined) {
        nightShift = nightModeOption === 'on';
      }
      handleThemeToggle(nightShift);
    }
  })();
</script>
<div id="click-to-top" class="click-to-top">
  <i class="fa fa-arrow-up"></i>
</div>
<script>
  (function () {
    const clickToTop = document.getElementById('click-to-top');
    window.addEventListener('scroll', () => {
      if (window.scrollY > 100) {
        clickToTop.classList.add('show')
      }else {
        clickToTop.classList.remove('show')
      }
    });
    clickToTop.addEventListener('click', () => {
      window.smoothScrollTo(0);
    });
  })();
</script>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="framework">
  <section class="main">

     <div class="post">
  <section>









<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

    <div class="post-content e-content" itemprop="articleBody">

      <h2 id="MachineTranslation"> MachineTranslation</h2>
<div class="visible-content">
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/LowResource.html" target="_blank" rel="noopener noreferrer">#LowResource</a>


<br>


<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2970" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SSA-COMET: Do LLMs Outperform Learned Metrics in Evaluating MT for   Under-Resourced African Languages?, Senyu Li+, EMNLP'25, 2025.06</a>
<span class="snippet"><span>GPT Summary</span>- アフリカの言語における機械翻訳の品質評価は依然として課題であり、既存の指標は限られた性能を示しています。本研究では、13のアフリカ言語ペアを対象とした大規模な人間注釈付きMT評価データセット「SSA-MTE」を紹介し、63,000以上の文レベルの注釈を含んでいます。これに基づき、改良された評価指標「SSA-COMET」と「SSA-COMET-QE」を開発し、最先端のLLMを用いたプロンプトベースのアプローチをベンチマークしました。実験結果は、SSA-COMETがAfriCOMETを上回り、特に低リソース言語で競争力があることを示しました。すべてのリソースはオープンライセンスで公開されています。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/odashi_t/status/1970720101306679436?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>


<br>


<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2969" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Multilingual Language Model Pretraining using Machine-translated Data, Jiayi Wang+, EMNLP'25, 2025.02</a>
<span class="snippet"><span>GPT Summary</span>- 高リソース言語の英語から翻訳した高品質なテキストが、多言語LLMsの事前学習に寄与することを発見。英語のデータセットFineWeb-Eduを9言語に翻訳し、17兆トークンのTransWebEduを作成。1.3BパラメータのTransWebLLMを事前学習し、非英語の推論タスクで最先端モデルと同等以上の性能を達成。特に、ドメイン特化データを追加することで、いくつかの言語で新たな最先端を達成。コーパス、モデル、トレーニングパイプラインはオープンソースで公開。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/odashi_t/status/1970720101306679436?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/ModelMerge.html" target="_blank" rel="noopener noreferrer">#ModelMerge</a>


<br>


<span class="issue_date">Issue Date: 2025-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2517" target="_blank" rel="noopener noreferrer" class="title-link">PLaMo Translate: 翻訳特化大規模言語モデルの開発,今城+, Jxiv'25</a>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/imos/status/1958687896321630355?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>SFT-&gt;Iterative DPO-&gt;Model Mergeのパイプライン。SFTでは青空文庫などのオープンなデータから指示追従性能の高いDeepSeek-V3-0324によって元データ→翻訳, 翻訳→再翻訳データを合成し活用。また、翻訳の指示がprompt中に存在せずとも（本モデルを利用するのは翻訳用途であることが自明であるからと推察される）翻訳を適切に実行できるよう、独自のテンプレートを学習。文体指定、常体、敬体の指定、文脈考慮、語彙指定それぞれにういて独自のタグを設けてフォーマットを形成し翻訳に特化したテンプレートを学習。<br><br>IterativeDPOでは、DeepSeekV3に基づくLLM-as-a-Judgeと、MetricX(<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2658" target="_blank" rel="noopener noreferrer">[Paper Note] MetricX-24: The Google Submission to the WMT 2024 Metrics Shared Task, Juraj Juraska+, arXiv'24</a>
)に基づいてReward Modelをそれぞれ学習し、1つの入力に対して100個の翻訳を作成しそれぞれのRewardモデルのスコアの合計値に基づいてRejection Samplingを実施することでPreference dataを構築。3段階のDPOを実施し、段階ごとにRewardモデルのスコアに基づいて高品質なPreference Dataに絞ることで性能向上を実現。<br><br>モデルマージではDPOの各段階のモデルを重み付きでマージすることで各段階での長所を組み合わせたとのこと。</p>
<p>サービスリリース:


<a href="https://prtimes.jp/main/html/rd/p/000000019.000156310.html?hm_ct=d17807e98595783ee6edfc7ae00fe95a&hm_cv=87e6d4e056b010261ecdc77d7ac8eb6c&hm_cs=1638145470668f4b36f218d2.35741174&hm_mid=m3hk6&hm_id=m3hk6&hm_h=a03.hm-f.jp" target="_blank" rel="noopener noreferrer">https://prtimes.jp/main/html/rd/p/000000019.000156310.html?hm_ct=d17807e98595783ee6edfc7ae00fe95a&hm_cv=87e6d4e056b010261ecdc77d7ac8eb6c&hm_cs=1638145470668f4b36f218d2.35741174&hm_mid=m3hk6&hm_id=m3hk6&hm_h=a03.hm-f.jp</a>


</p>
<p>2025.1010配信の「岡野原大輔のランチタイムトーク Vol.52 番外編「なぜPLaMo翻訳は自然なのか？」において詳細が語られているので参照のこと。特になぜ日本語に強いLLMが大事なのか？という話が非常におもしろかった。</p></span><br><br>
</div>
<p><button onclick="showMore(0)">more</button></p>
<div class="hidden-content">
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<span class="issue_date">Issue Date: 2025-07-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2261" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Unveiling the Power of Source: Source-based Minimum Bayes Risk Decoding   for Neural Machine Translation, Boxuan Lyu+, ACL'25</a>
<span class="snippet"><span>GPT Summary</span>- ソースベースのMBRデコーディング（sMBR）を提案し、パラフレーズや逆翻訳から生成された準ソースを「サポート仮説」として利用。参照なしの品質推定メトリックを効用関数として用いる新しいアプローチで、実験によりsMBRがQE再ランキングおよび標準MBRを上回る性能を示した。sMBRはNMTデコーディングにおいて有望な手法である。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/boxuan_lyu425/status/1946802820973519245?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiDimensional.html" target="_blank" rel="noopener noreferrer">#MultiDimensional</a>
<span class="issue_date">Issue Date: 2025-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2249" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] TransEvalnia: Reasoning-based Evaluation and Ranking of Translations, Richard Sproat+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- プロンプトベースの翻訳評価システム「TransEvalnia」を提案し、Multidimensional Quality Metricsに基づく詳細な評価を行う。TransEvalniaは、英日データやWMTタスクで最先端のMT-Rankerと同等以上の性能を示し、LLMによる評価が人間の評価者と良好に相関することを確認。翻訳の提示順序に敏感であることを指摘し、位置バイアスへの対処法を提案。システムの評価データは公開される。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sakanaailabs/status/1946071203002941694?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/TACL.html" target="_blank" rel="noopener noreferrer">#TACL</a>
<span class="issue_date">Issue Date: 2025-09-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2635" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] xCOMET: Transparent Machine Translation Evaluation through Fine-grained  Error Detection, Nuno M. Guerreiro+, TACL'24</a>
<span class="snippet"><span>GPT Summary</span>- xCOMETは、機械翻訳評価のためのオープンソースの学習メトリックで、文レベルの評価とエラー範囲検出を統合。これにより、翻訳エラーの詳細な分類と評価が可能となり、最先端の性能を発揮。さらに、堅牢性分析により重大なエラーや幻覚の特定能力が高いことを示す。</span>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<span class="issue_date">Issue Date: 2025-01-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1641" target="_blank" rel="noopener noreferrer" class="title-link">How Much Data is Enough Data? Fine-Tuning Large Language Models for  In-House Translation: Performance Evaluation Across Multiple Dataset Sizes, Inacio Vieira+, AMTA'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsのファインチューニングに翻訳メモリ（TMs）を活用し、特定の組織向けの翻訳精度と効率を向上させる研究。5つの翻訳方向で異なるサイズのデータセットを用いて実験し、トレーニングデータが増えるほど翻訳パフォーマンスが向上することを確認。特に、1kおよび2kの例ではパフォーマンスが低下するが、データセットのサイズが増加するにつれて改善が見られる。LLMsとTMsの統合により、企業特有のニーズに応じたカスタマイズ翻訳モデルの可能性を示唆。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gyakuse/status/1874357127248306200?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>QLoRAでLlama 8B InstructをMTのデータでSFTした場合のサンプル数に対する性能の変化を検証している。ただし、検証しているタスクはMT、QLoRAでSFTを実施しrankは64、学習時のプロンプトは非常にシンプルなものであるなど、幅広い設定で学習しているわけではないので、ここで得られた知見が幅広く適用可能なことは示されていないであろう点、には注意が必要だと思われる。<br><br>この設定では、SFTで利用するサンプル数が増えれば増えるほど性能が上がっているように見える。<br><br><img src="https://github.com/user-attachments/assets/71309a00-85fd-491f-a89e-c9cb99f4da6c" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/ea1eba38-9488-43e5-a64b-f997bf65f57b" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/21b21628-d589-4214-8860-680e392a2556" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2024-11-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1534" target="_blank" rel="noopener noreferrer" class="title-link">Prompting Large Language Model for Machine Translation: A Case Study, Biao Zhang+, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- 機械翻訳におけるプロンプティングの研究を体系的に行い、プロンプトテンプレートやデモ例の選択に影響を与える要因を検討。GLM-130Bを用いた実験により、プロンプト例の数と質が翻訳に重要であること、意味的類似性などの特徴がパフォーマンスと相関するが強くないこと、単言語データからの擬似平行プロンプト例が翻訳を改善する可能性があること、他の設定からの知識転送がパフォーマンス向上に寄与することを示した。プロンプティングの課題についても議論。</span>
<span class="snippet"><span>Comment</span><p>zero-shotでMTを行うときに、改行の有無や、少しのpromptingの違いでCOMETスコアが大幅に変わることを示している。<br><br>モデルはGLM-130BをINT4で量子化したモデルで実験している。<br><br>興味深いが、この知見を一般化して全てのLLMに適用できるか？と言われると、そうはならない気がする。他のモデルで検証したら傾向はおそらく変わるであろう（という意味でおそらく論文のタイトルにもCase Studyと記述されているのかなあ）。<br><br><br><br><img src="https://github.com/user-attachments/assets/1302dbb2-40e2-40c2-9a71-cae01528b5e6" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LM-based.html" target="_blank" rel="noopener noreferrer">#LM-based</a>
<a class="button" href="articles/Coherence.html" target="_blank" rel="noopener noreferrer">#Coherence</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/967" target="_blank" rel="noopener noreferrer" class="title-link">DiscoScore: Evaluating Text Generation with BERT and Discourse Coherence, Wei Zhao+, N_A, EACL'23</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、文章の一貫性を評価するための新しい指標であるDiscoScoreを紹介します。DiscoScoreはCentering理論に基づいており、BERTを使用して談話の一貫性をモデル化します。実験の結果、DiscoScoreは他の指標よりも人間の評価との相関が高く、システムレベルでの評価でも優れた結果を示しました。さらに、DiscoScoreの重要性とその優位性についても説明されています。</span>
<a class="button" href="articles/Unsupervised.html" target="_blank" rel="noopener noreferrer">#Unsupervised</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/Speech.html" target="_blank" rel="noopener noreferrer">#Speech</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/842" target="_blank" rel="noopener noreferrer" class="title-link">Simple and Effective Unsupervised Speech Translation, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- 音声翻訳のためのラベル付きデータが限られているため、非教師あり手法を使用して音声翻訳システムを構築する方法を研究している。パイプラインアプローチや擬似ラベル生成を使用し、非教師ありドメイン適応技術を提案している。実験の結果、従来の手法を上回る性能を示している。</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Annotation.html" target="_blank" rel="noopener noreferrer">#Annotation</a>
<a class="button" href="articles/TransferLearning.html" target="_blank" rel="noopener noreferrer">#TransferLearning</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2023-05-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/615" target="_blank" rel="noopener noreferrer" class="title-link">Frustratingly Easy Label Projection for Cross-lingual Transfer, Yang Chen+, N_A, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- - 多言語のトレーニングデータの翻訳は、クロスリンガル転移の改善に役立つ- スパンレベル注釈が必要なタスクでは、注釈付きスパンを翻訳されたテキストにマッピングするために追加のラベルプロジェクションステップが必要- マーク-翻訳法を利用するアプローチが従来の注釈プロジェクションと比較してどのようになるかについての実証的な分析を行った- EasyProjectと呼ばれるマーク-翻訳法の最適化されたバージョンが多言語に簡単に適用でき、より複雑な単語アラインメントベースの方法を上回ることを示した- すべてのコードとデータが公開される</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2025-09-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2637" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] No Language Left Behind: Scaling Human-Centered Machine Translation, NLLB Team+, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- 「No Language Left Behind」プロジェクトは、リソースが乏しい言語の機械翻訳を改善するために、母国語話者とのインタビューを通じてニーズを特定し、データセットとモデルを開発。新しいデータマイニング技術を用いた条件付き計算モデルを構築し、過学習を防ぐための訓練改善を提案。Flores-200ベンチマークでの評価により、従来技術に対して44%のBLEU改善を達成し、普遍的な翻訳システムの基盤を築いた。全ての成果はオープンソースで公開。</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2025-09-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2636" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] CometKiwi: IST-Unbabel 2022 Submission for the Quality Estimation Shared Task, Rei+, WMT'22</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<span class="issue_date">Issue Date: 2024-09-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1425" target="_blank" rel="noopener noreferrer" class="title-link">No Language Left Behind: Scaling Human-Centered Machine Translation, NLLB Team+, N_A, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- 「No Language Left Behind」プロジェクトでは、リソースが乏しい言語の機械翻訳を改善するために、ネイティブスピーカーとのインタビューを通じて必要性を明らかにし、データセットとモデルを開発。新しいデータマイニング技術を用いた条件付き計算モデルを提案し、過学習を防ぐための訓練改善を行った。Flores-200ベンチマークで40,000以上の翻訳方向を評価し、従来技術に対して44%のBLEU改善を達成。全ての成果はオープンソースとして公開。</span>
<span class="snippet"><span>Comment</span><p>low-resourceな言語に対するMTのベンチマーク</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<span class="issue_date">Issue Date: 2021-06-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/379" target="_blank" rel="noopener noreferrer" class="title-link">Improving Neural Machine Translation with Compact Word Embedding Tables, Kumar+, AAAI'22</a>
<span class="snippet"><span>Comment</span><p>NMTにおいてword embeddingがどう影響しているかなどを調査しているらしい</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2024-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1221" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Experts, Errors, and Context: A Large-Scale Study of Human Evaluation  for Machine Translation, Markus Freitag+, arXiv'21</a>
<span class="snippet"><span>GPT Summary</span>- 機械翻訳システムの人間による評価は難しく、標準的な手続きが欠如している。そこで、MQMフレームワークに基づく評価方法論を提案し、WMT 2020のトップシステムの出力をプロの翻訳者による注釈でスコアリングした。分析の結果、クラウドワーカーによる評価とは異なり、人間の出力が機械の出力より好まれることが示された。また、事前学習された埋め込みに基づく自動メトリクスが人間の評価を上回ることも明らかになった。コーパスは今後の研究のために公開される。</span>
<span class="snippet"><span>Comment</span><p>embedding basedなNLGの性能指標が、意味の等価性や流暢性を評価できる一方、適用範囲が限定的で柔軟性に欠けることを示した研究</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Normalization.html" target="_blank" rel="noopener noreferrer">#Normalization</a>
<a class="button" href="articles/Findings.html" target="_blank" rel="noopener noreferrer">#Findings</a>
<span class="issue_date">Issue Date: 2025-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2443" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Query-Key Normalization for Transformers, Alex Henry+, EMNLP'20 Findings</a>
<span class="snippet"><span>GPT Summary</span>- 低リソース言語翻訳において、QKNormという新しい正規化手法を提案。これは、注意メカニズムを修正し、ソフトマックス関数の飽和耐性を向上させつつ表現力を維持。具体的には、クエリとキー行列に対して$\ell_2$正規化を適用し、学習可能なパラメータでスケールアップ。TED TalksコーパスとIWSLT'15の低リソース翻訳ペアで平均0.928 BLEUの改善を達成。</span>
<span class="snippet"><span>Comment</span><p>QKに対してL2正規化を実施し、learnableなスカラー値を乗じることでスケーリングすることで、low resourceな言語での翻訳性能が向上。MTで実験されているが、transformerの表現力が改善されるのでGLM-4.5のアーキテクチャでも採用されている。<br><br>dot product attentionでは内積を利用するため値域に制約がなく、ある単語にのみattention scoreが集中してしまい、他の全ての単語のsignalをかき消してしまう問題がある。このため、QKをノルムによって正規化し（これにより実質QKはcosine similarityとなる）値域を制限する。しかしこうすると今度はスコア間の差が小さすぎて、attendしなくても良い単語を無視できなくなるので、learnableなパラメータでスケールを調整する。</p></span><br><br>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2024-05-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1312" target="_blank" rel="noopener noreferrer" class="title-link">COMET: A Neural Framework for MT Evaluation, Ricardo Rei+, N_A, EMNLP'20</a>
<span class="snippet"><span>GPT Summary</span>- COMETは、多言語機械翻訳評価モデルを訓練するためのニューラルフレームワークであり、人間の判断との新しい最先端の相関レベルを達成します。クロスリンガル事前学習言語モデリングの進展を活用し、高度に多言語対応かつ適応可能なMT評価モデルを実現します。WMT 2019 Metrics shared taskで新たな最先端のパフォーマンスを達成し、高性能システムに対する堅牢性を示しています。</span>
<span class="snippet"><span>Comment</span><p>Better/Worseなhypothesisを利用してpair-wiseにランキング関数を学習する<br>![Image](https://github.com/user-attachments/assets/a1fd6f36-48e8-44fc-8fcb-0900a51759b3)<br><br>![Image](https://github.com/user-attachments/assets/19ad7a57-7de3-4255-afde-4a1fde41587d)<br><br>Inference時は単一のhypothesisしかinputされないので、sourceとreferenceに対してそれぞれhypothesisの距離をはかり、その調和平均でスコアリングする<br><br>![Image](https://github.com/user-attachments/assets/21642c70-a7fd-4c0e-8678-6125fdbfefce)</p>
<p>ACL2024, EMNLP2024あたりのMT研究のmetricをざーっと見る限り、BLEU/COMETの双方で評価する研究が多そう</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2024-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1222" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] BLEU might be Guilty but References are not Innocent, Markus Freitag+, arXiv'20</a>
<span class="snippet"><span>GPT Summary</span>- 機械翻訳の自動評価指標の質が疑問視される中、参照の性質が評価に与える影響を研究。異なる参照収集方法を比較し、翻訳の多様性不足に対抗するために言語学者によるパラフレーズタスクを開発。これにより、WMT 2019の英独翻訳やバックトランスレーションで人間の評価との相関が向上。多参照BLEUの限界を指摘し、より効果的な評価方法を提案。</span>
<span class="snippet"><span>Comment</span><p>surface levelのNLGの性能指標がsemanticを評価できないことを示した研究</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/pretrained-LM.html" target="_blank" rel="noopener noreferrer">#pretrained-LM</a>
<span class="issue_date">Issue Date: 2022-12-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/493" target="_blank" rel="noopener noreferrer" class="title-link">Leveraging Pre-trained Checkpoints for Sequence Generation Tasks, Rothe+, Google Research, TACL'20</a>
<span class="snippet"><span>Comment</span><p># 概要<br><br>BERT-to-BERT論文。これまでpre-trainedなチェックポイントを利用する研究は主にNLUで行われてきており、Seq2Seqでは行われてきていなかったので、やりました、という話。<br><br>publicly availableなBERTのcheckpointを利用し、BERTをencoder, decoder両方に採用することでSeq2Seqを実現。実現する上で、<br><br>1. decoder側のBERTはautoregressiveな生成をするようにする（左側のトークンのattentionしか見れないようにする）<br><br>2. encoder-decoder attentionを新たに導入する<br><br>の2点を工夫している。<br><br><br><br># 実験<br><br>Sentence Fusion, Sentence Split, Machine Translation, Summarizationの4タスクで実験<br><br><br><br>## MT<br><br><img src="https://user-images.githubusercontent.com/12249301/204958483-722106b3-bda2-45a3-bb08-fb4eb429c90c.png" alt="image" loading="lazy"><br><br>BERT2BERTがSoTA達成。Edunov+の手法は、data _augmentationを利用した手法であり、純粋なWMT14データを使った中ではSoTAだと主張。特にEncoder側でBERTを使うと、Randomにinitializeした場合と比べて性能が顕著に上昇しており、その重要性を主張。<br><br>Sentence Fusion, Sentence Splitでは、encoderとdecoderのパラメータをshareするのが良かったが、MTでは有効ではなかった。これはMTではmodelのcapacityが非常に重要である点、encoderとdecoderで異なる文法を扱うためであると考えられる。<br><br><br><br>## Summarization<br><br>BERTSHARE, ROBERTASHAREの結果が良かった。<br><br><img src="https://user-images.githubusercontent.com/12249301/204959543-e21bd9a6-bef4-4538-b181-daca93fa33e7.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/TrainedMetrics.html" target="_blank" rel="noopener noreferrer">#TrainedMetrics</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/954" target="_blank" rel="noopener noreferrer" class="title-link">Machine Translation Evaluation with BERT Regressor, Hiroki Shimanaka+, N_A, arXiv'19</a>
<span class="snippet"><span>GPT Summary</span>- 私たちは、BERTを使用した自動的な機械翻訳の評価メトリックを紹介します。実験結果は、私たちのメトリックがすべての英語対応言語ペアで最先端のパフォーマンスを達成していることを示しています。</span>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Subword.html" target="_blank" rel="noopener noreferrer">#Subword</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Tokenizer.html" target="_blank" rel="noopener noreferrer">#Tokenizer</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-11-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3721" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates, Taku Kudo, ACL'18, 2018.04</a>
<span class="snippet"><span>GPT Summary</span>- サブワード単位はNMTのオープンボキャブラリー問題を軽減するが、セグメンテーションの曖昧さが存在する。本研究では、この曖昧さを利用してNMTのロバスト性を向上させるため、サブワードの正則化手法を提案し、確率的にサンプリングされた複数のセグメンテーションでモデルを訓練する。また、ユニグラム言語モデルに基づく新しいセグメンテーションアルゴリズムも提案。実験により、特にリソースが限られた設定での改善を示した。</span>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/TransferLearning.html" target="_blank" rel="noopener noreferrer">#TransferLearning</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/Zero/FewShotLearning.html" target="_blank" rel="noopener noreferrer">#Zero/FewShotLearning</a>
<a class="button" href="articles/TACL.html" target="_blank" rel="noopener noreferrer">#TACL</a>
<a class="button" href="articles/Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<a class="button" href="articles/LowResource.html" target="_blank" rel="noopener noreferrer">#LowResource</a>
<span class="issue_date">Issue Date: 2025-11-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3719" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Google's Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation, Melvin Johnson+, TACL'17, 2016.11</a>
<span class="snippet"><span>GPT Summary</span>- 単一のNMTモデルを用いて多言語翻訳を実現するシンプルな手法を提案。入力文の先頭に人工トークンを追加することでターゲット言語を指定し、モデルのアーキテクチャは変更せずに共有語彙を使用。これにより、パラメータを増やさずに翻訳品質を向上させ、WMT'14およびWMT'15ベンチマークで最先端の結果を達成。訓練中に見たことのない言語ペア間での暗黙のブリッジングを学習し、転移学習とゼロショット翻訳の可能性を示す。</span>
<span class="snippet"><span>Comment</span><p>バックボーン:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3718" target="_blank" rel="noopener noreferrer">[Paper Note] Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation, Yonghui Wu+, arXiv'16, 2016.09</a>
</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/PositionalEncoding.html" target="_blank" rel="noopener noreferrer">#PositionalEncoding</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-01-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/245" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Attention Is All You Need, Ashish Vaswani+, arXiv'17</a>
<span class="snippet"><span>GPT Summary</span>- Transformerは、再帰や畳み込みを排除し、注意機構のみに基づいた新しいネットワークアーキテクチャである。実験により、機械翻訳タスクで優れた品質を示し、トレーニング時間を大幅に短縮。WMT 2014の英独翻訳で28.4 BLEU、英仏翻訳で41.8 BLEUを達成し、既存モデルを上回る性能を示した。また、英語の構文解析にも成功裏に適用可能であることを示した。</span>
<span class="snippet"><span>Comment</span><p>Transformer (self-attentionを利用) 論文<br><br>解説スライド：


<a href="https://www.slideshare.net/DeepLearningJP2016/dlattention-is-all-you-need" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/DeepLearningJP2016/dlattention-is-all-you-need</a>


<br><br>解説記事：


<a href="https://qiita.com/nishiba/items/1c99bc7ddcb2d62667c6" target="_blank" rel="noopener noreferrer">https://qiita.com/nishiba/items/1c99bc7ddcb2d62667c6</a>


<br><br><br><br>* 新しい翻訳モデル(Transformer)を提案。既存のモデルよりも並列化に対応しており、短時間の訓練で（既存モデルの1/4以下のコスト）高いBLEUスコアを達成した。<br><br>* TransformerはRNNやCNNを使わず、attentionメカニズムに基づいている。<br><br><br><br>（解説より）</p>
<p>分かりやすい:<br>


<a href="https://qiita.com/halhorn/items/c91497522be27bde17ce" target="_blank" rel="noopener noreferrer">https://qiita.com/halhorn/items/c91497522be27bde17ce</a>


</p>
<p>Transformerの各コンポーネントでのoutputのshapeや、attention_maskの形状、実装について記述されており有用:<br>


<a href="https://qiita.com/FuwaraMiyasaki/items/239f3528053889847825" target="_blank" rel="noopener noreferrer">https://qiita.com/FuwaraMiyasaki/items/239f3528053889847825</a>


</p>
<p>集合知</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2018-01-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/234" target="_blank" rel="noopener noreferrer" class="title-link">ゼロから始める ニューラルネットワーク機械翻訳, 中澤敏明, NLP'17</a>
<span class="snippet"><span>Comment</span><p>中澤さんによるNMTチュートリアル。</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/67" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] What do Neural Machine Translation Models Learn about Morphology?, Yonatan Belinkov+, ACL'17</a>
<span class="snippet"><span>Comment</span><p>


<a href="http://www.lr.pi.titech.ac.jp/~haseshun/acl2017suzukake/slides/06.pdf" target="_blank" rel="noopener noreferrer">http://www.lr.pi.titech.ac.jp/~haseshun/acl2017suzukake/slides/06.pdf</a>


<br><br>(2025.05.12追記)<br>上記は2017年にすずかけ台で開催されたACL 2017読み会での解説スライドです。</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/66" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Sequence-to-Dependency Neural Machine Translation, Wu+, ACL'17</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/64" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Neural Machine Translation with Source-Side Latent Graph Parsing, Kazuma Hashimoto+, EMNLP'17</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Subword.html" target="_blank" rel="noopener noreferrer">#Subword</a>
<a class="button" href="articles/Tokenizer.html" target="_blank" rel="noopener noreferrer">#Tokenizer</a>
<a class="button" href="articles/Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<a class="button" href="articles/RecurrentModels.html" target="_blank" rel="noopener noreferrer">#RecurrentModels</a>
<span class="issue_date">Issue Date: 2025-11-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3718" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation, Yonghui Wu+, arXiv'16, 2016.09</a>
<span class="snippet"><span>GPT Summary</span>- GNMTは、計算コストの高いNMTの問題に対処するために、8層のLSTMネットワークを用い、注意機構と残差接続を採用。希少な単語の処理を改善するために、一般的なサブワードユニットに分割し、翻訳精度を向上。ビームサーチ技術により、出力文のカバレッジを高め、WMT'14のベンチマークで最先端の結果を達成し、翻訳エラーを60％削減。</span>
<span class="snippet"><span>Comment</span><p>GNMT論文。wordpieceを提案</p>
<p>日本語解説:


<a href="https://deeplearning.hatenablog.com/entry/gnmt" target="_blank" rel="noopener noreferrer">https://deeplearning.hatenablog.com/entry/gnmt</a>


</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Subword.html" target="_blank" rel="noopener noreferrer">#Subword</a>
<a class="button" href="articles/Tokenizer.html" target="_blank" rel="noopener noreferrer">#Tokenizer</a>
<span class="issue_date">Issue Date: 2025-11-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3717" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Neural Machine Translation of Rare Words with Subword Units, Rico Sennrich+, ACL'16, 2015.08</a>
<span class="snippet"><span>GPT Summary</span>- NMTモデルは固定語彙で動作するが、オープンボキャブラリー翻訳を可能にするために、希少な単語や未知の単語をサブワードユニットとしてエンコードする新しいアプローチを提案。さまざまな単語クラスを小さな単位で翻訳可能とし、文字n-gramモデルやバイトペアエンコーディングを用いたセグメンテーション技術の効果を実証。WMT 15翻訳タスクでバックオフ辞書のベースラインをそれぞれ1.1および1.3 BLEUポイント上回る成果を示した。</span>
<span class="snippet"><span>Comment</span><p>subwordが初めて提案された研究</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/DualLearning.html" target="_blank" rel="noopener noreferrer">#DualLearning</a>
<span class="issue_date">Issue Date: 2025-08-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2508" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Dual Learning for Machine Translation, Yingce Xia+, NIPS'16</a>
<span class="snippet"><span>GPT Summary</span>- デュアルラーニングメカニズムを用いたニューラル機械翻訳（dual-NMT）を提案。プライマルタスク（英語からフランス語）とデュアルタスク（フランス語から英語）を通じて、ラベルのないデータから自動的に学習。強化学習を用いて互いに教え合い、モデルを更新。実験により、モノリンガルデータから学習しつつ、バイリンガルデータと同等の精度を達成することが示された。</span>
<span class="snippet"><span>Comment</span><p>モノリンガルコーパスD_A, D_Bで学習した言語モデルLM_A, LM_Bが与えられた時、翻訳モデルΘ_A, Θ_Bのの翻訳の自然さ（e.g., 尤度）をrewardとして与え、互いのモデルの翻訳（プライマルタスク）・逆翻訳（デュアルタスク）の性能が互いに高くなるように強化学習するような枠組みを提案。パラレルコーパス不要でモノリンガルコーパスのみで、人手によるアノテーション無しで学習ができる。</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coherence.html" target="_blank" rel="noopener noreferrer">#Coherence</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/971" target="_blank" rel="noopener noreferrer" class="title-link">Lexical Coherence Graph Modeling Using Word Embeddings, Mesgar+, NAACL'16</a>
<span class="snippet"><span>Comment</span><p>__translate: Coherence is established by semantic connections between sentences of a text which can be modeled by lexical relations. In this paper, we introduce the lexical coherence graph (LCG), a new graph-based model to represent lexical relations among sentences. The frequency of subgraphs (coherence patterns) of this graph captures the connectivity style of sentence nodes in this graph. The coherence of a text is encoded by a vector of these frequencies. We evaluate the LCG model on the readability ranking task. The results of the experiments show that the LCG model obtains higher accuracy than state-of-the-art coherence models. Using larger subgraphs yields higher accuracy, because they capture more structural information. However, larger subgraphs can be sparse. We adapt Kneser-Ney smoothing to smooth subgraphs’ frequencies. Smoothing improves performance.</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/65" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Pointing the unknown words, Gulcehre+, ACL'16</a>
<span class="snippet"><span>Comment</span><p>テキストを生成する際に、source textからのコピーを行える機構を導入することで未知語問題に対処した話</p>
<p>CopyNetと同じタイミングで（というか同じconferenceで）発表</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-05-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1954" target="_blank" rel="noopener noreferrer" class="title-link">Neural Machine Translation by Jointly Learning to Align and Translate, Dzmitry Bahdanau+, ICLR'15</a>
<span class="snippet"><span>GPT Summary</span>- ニューラル機械翻訳は、エンコーダー-デコーダーアーキテクチャを用いて翻訳性能を向上させる新しいアプローチである。本論文では、固定長のベクトルの使用が性能向上のボトルネックであるとし、モデルが関連するソース文の部分を自動的に検索できるように拡張することを提案。これにより、英語からフランス語への翻訳タスクで最先端のフレーズベースシステムと同等の性能を達成し、モデルのアライメントが直感と一致することを示した。</span>
<span class="snippet"><span>Comment</span><p>(Cross-)Attentionを初めて提案した研究。メモってなかったので今更ながら追加。Attentionはここからはじまった（と認識している）</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reference-based.html" target="_blank" rel="noopener noreferrer">#Reference-based</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/985" target="_blank" rel="noopener noreferrer" class="title-link">chrF: character n-gram F-score for automatic MT evaluation, Mono Popovic, WMT'15</a>
<span class="snippet"><span>GPT Summary</span>- 私たちは、機械翻訳の評価に文字n-gram Fスコアを使用することを提案します。私たちは、このメトリックがシステムレベルとセグメントレベルで人間のランキングと相関しており、特にセグメントレベルでの相関が非常に高いことを報告しました。この提案は非常に有望であり、WMT14の共有評価タスクでも最高のメトリックを上回りました。</span>
<span class="snippet"><span>Comment</span><p>character-basedなn-gram overlapをreferenceとシステムで計算する手法</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/969" target="_blank" rel="noopener noreferrer" class="title-link">Document-Level Machine Translation Evaluation with Gist Consistency and Text Cohesion, Gong+, DiscoMT'15</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2021-06-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/369" target="_blank" rel="noopener noreferrer" class="title-link">Effective Approaches to Attention-based Neural Machine Translation, Luong+, EMNLP'15</a>
<span class="snippet"><span>Comment</span><p>Luong論文。attentionの話しはじめると、だいたいBahdanau+か、Luong+論文が引用される。<br><br><br><br>Global Attentionと、Local Attentionについて記述されている。Global Attentionがよく利用される。<br><br><br><br>Global Attention<br><br><img src="https://user-images.githubusercontent.com/12249301/120452200-008ec280-c3cd-11eb-8ced-47dc9e67f487.png" alt="image" loading="lazy"><br><br><br><br>Local Attention<br><br><img src="https://user-images.githubusercontent.com/12249301/120452397-2025eb00-c3cd-11eb-9d3b-0f7802a40712.png" alt="image" loading="lazy"><br><br></p>
<p>やはり菊池さんの解説スライドが鉄板。<br><br>


<a href="https://www.slideshare.net/yutakikuchi927/deep-learning-nlp-attention" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/yutakikuchi927/deep-learning-nlp-attention</a>


</p>
<p>参考までに、LuongらのGlobal Attentionの計算の流れは下記となっている：<br><br>- h_t -&gt; a_t -&gt; c_t -&gt; h^~_t<br><br><br><br>BahdanauらのAttentionは下記<br><br>- h_t-1 -&gt; a_t -&gt; c_t -&gt; h_t<br><br><br><br>t-1のhidden stateを使うのか、input feeding後の現在のhidden stateをattention weightの計算に使うのかが異なっている。</p>
<p>また、過去のalignmentの情報を考慮した上でデコーディングしていくために、input-feeding approachも提案<br><br><img src="https://user-images.githubusercontent.com/12249301/120877145-cfdaa300-c5ef-11eb-8a8b-a57d03d864b4.png" alt="image" loading="lazy"><br><br><br><br>input-feeding appproachでは、t-1ステップ目のoutputの算出に使ったh^~_t（hidden_stateとcontext vectorをconcatし、tanhのactivationを噛ませた線形変換を行なったベクトル）を、時刻tのinput embeddingにconcatして、RNNに入力する。</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coherence.html" target="_blank" rel="noopener noreferrer">#Coherence</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/970" target="_blank" rel="noopener noreferrer" class="title-link">Graph-based Local Coherence Modeling, Guinaudeau+, ACL'13</a>
<span class="snippet"><span>GPT Summary</span>- 私たちは、グラフベースのアプローチを提案し、文の順序付け、要約の結束性評価、読みやすさの評価の3つのタスクでシステムを評価しました。このアプローチは、エンティティグリッドベースのアプローチと同等の性能を持ち、計算コストの高いトレーニングフェーズやデータのまばらさの問題にも対処できます。</span>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<span class="issue_date">Issue Date: 2018-01-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/237" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Mathematics of Statistical Machine Translation: Parameter Estimation, Brown+, CL'13</a>
<span class="snippet"><span>Comment</span><p>IBMモデル論文。</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coherence.html" target="_blank" rel="noopener noreferrer">#Coherence</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/968" target="_blank" rel="noopener noreferrer" class="title-link">Extending Machine Translation Evaluation Metrics with Lexical Cohesion to Document Level, Wong+, EMNLP'12</a>
<span class="snippet"><span>GPT Summary</span>- この論文では、語彙的な結束を利用して文書レベルの機械翻訳の評価を容易にする方法を提案しています。語彙的な結束は、同じ意味を持つ単語を使って文を結びつけることで、テキストの結束性を実現します。実験結果は、この特徴を評価尺度に組み込むことで、人間の判断との相関を向上させることを示しています。</span>
<span class="snippet"><span>Comment</span><p>RC-LC</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2024-12-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1609" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models in Machine Translation, Brants+, EMNLP-CoNLL'07</a>
<span class="snippet"><span>GPT Summary</span>- 本論文では、機械翻訳における大規模な統計的言語モデルの利点を報告し、最大2兆トークンでトレーニングした3000億n-gramのモデルを提案。新しいスムージング手法「Stupid Backoff」を導入し、大規模データセットでのトレーニングが安価で、Kneser-Neyスムージングに近づくことを示す。</span>
<span class="snippet"><span>Comment</span><p>N-gram言語モデル+スムージングの手法において、学習データを増やして扱えるngramのタイプ数（今で言うところのvocab数に近い）を増やしていったら、perplexityは改善するし、MTにおけるBLEUスコアも改善するよ（BLEUはサチってるかも？）という考察がされている<br><br><img src="https://github.com/user-attachments/assets/035f28db-12c6-4b69-b39f-7eb41581d00c" alt="image" loading="lazy"></p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/odashi_t/status/1871024428739604777?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>Large Language Modelsという用語が利用されたのはこの研究が初めてなのかも…？</p></span><br><br>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2021-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/393" target="_blank" rel="noopener noreferrer" class="title-link">機械翻訳自動評価指標の比較, 今村+, NLP'04</a>
<span class="snippet"><span>Comment</span><p>BLEUスコア、NISTスコア、WordErrorRate(WER)などに関して丁寧かつ簡潔に解説してある。<br><br>BLEUスコア算出に利用するN-gramは一般的にはN=4が用いられる、といった痒いところに手が届く情報も書いてある。<br><br>普段何気なく使っているBLEUスコアで、あれ定義ってどんなだっけ？と立ち帰りたくなった時に読むべし。</p>
<p>実際に研究等でBLEUスコアを測りたい場合は、mosesの実装を使うのが間違いない:<br><br>


<a href="https://github.com/moses-smt/mosesdecoder/blob/master/scripts/generic/multi-bleu.perl" target="_blank" rel="noopener noreferrer">https://github.com/moses-smt/mosesdecoder/blob/master/scripts/generic/multi-bleu.perl</a>


</p></span><br><br>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<span class="issue_date">Issue Date: 2018-01-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/239" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A systematic comparison of various statistical alignment models, Och+, CL'03</a>
<span class="snippet"><span>Comment</span><p>Giza++<br>標準的に利用される単語アライメントツール</p>
<p>評価の際は、Sure, Possibleの二種類のラベルによる単語アライメントのground-truth作成も行っている</p>
<p>


<a href="http://delivery.acm.org/10.1145/780000/778824/s2.pdf?ip=122.18.145.201&id=778824&acc=OPEN&key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E6D218144511F3437&__acm__=1529099122_be539b373009b5812a7efac44e71e64d" target="_blank" rel="noopener noreferrer">http://delivery.acm.org/10.1145/780000/778824/s2.pdf?ip=122.18.145.201&id=778824&acc=OPEN&key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E6D218144511F3437&__acm__=1529099122_be539b373009b5812a7efac44e71e64d</a>


</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/COLING.html" target="_blank" rel="noopener noreferrer">#COLING</a>
<span class="issue_date">Issue Date: 2018-01-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/238" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note]  HMM-based word alignment in statistical translation, Vogel+, COLING'96</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/DocParser.html" target="_blank" rel="noopener noreferrer">#DocParser</a>
<span class="issue_date">Issue Date: 2025-09-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2998" target="_blank" rel="noopener noreferrer" class="title-link">Liquid Nanos, LiquidAI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>blog:


<a href="https://www.liquid.ai/blog/introducing-liquid-nanos-frontier-grade-performance-on-everyday-devices" target="_blank" rel="noopener noreferrer">https://www.liquid.ai/blog/introducing-liquid-nanos-frontier-grade-performance-on-everyday-devices</a>


</p>
<p>モデルファミリーに350Mの日英翻訳モデルが含まれている…だと！？</p>
<p>タスクスペシフィックなedgeデバイス向けのSLM群。<br><br>以下のようなモデルファミリー。非構造テキストからのデータ抽出、日英翻訳、RAG, tooluse, Math, フランス語のチャットモデル。これまでマルチリンガルに特化したMTとかはよく見受けられたが、色々なタスクのSLMが出てきた。<br><img src="https://github.com/user-attachments/assets/bb19f5f0-f20f-4e51-8ecc-75c7b425b60f" alt="image" loading="lazy"></p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1971359534883946709?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>LFM2はこちら:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2999" target="_blank" rel="noopener noreferrer">Introducing LFM2: The Fastest On-Device Foundation Models on the Market, LiquidAI, 2025.07</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2948" target="_blank" rel="noopener noreferrer" class="title-link">Qwen3‑LiveTranslate: Real‑Time Multimodal Interpretation — See It, Hear It, Speak It！, Qwen Team, 2025.09</a>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1970565641594867973?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2634" target="_blank" rel="noopener noreferrer" class="title-link">Hunyuan-MT-7B, Tencent, 2025.09</a>
<span class="snippet"><span>Comment</span><p>テクニカルレポート:


<a href="https://github.com/Tencent-Hunyuan/Hunyuan-MT/blob/main/Hunyuan_MT_Technical_Report.pdf" target="_blank" rel="noopener noreferrer">https://github.com/Tencent-Hunyuan/Hunyuan-MT/blob/main/Hunyuan_MT_Technical_Report.pdf</a>


</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tencenthunyuan/status/1962466712378577300?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>Base Modelに対してまず一般的な事前学習を実施し、その後MTに特化した継続事前学習（モノリンガル/パラレルコーパスの利用）、事後学習（SFT, GRPO)を実施している模様。<br>継続事前学習では、最適なDataMixの比率を見つけるために、RegMixと呼ばれる手法を利用。Catastrophic Forgettingを防ぐために、事前学習データの20%を含めるといった施策を実施。<br><br>SFTでは2つのステージで構成されている。ステージ1は基礎的な翻訳力の強化と翻訳に関する指示追従能力の向上のために、Flores-200の開発データ(33言語の双方向の翻訳をカバー)、前年度のWMTのテストセット(English to XXをカバー）、Mandarin to Minority, Minority to Mandarinのcuratedな人手でのアノテーションデータ、DeepSeek-V3-0324での合成パラレルコーパス、general purpose/MT orientedな指示チューニングデータセットのうち20%を構成するデータで翻訳のinstructinoに関するモデルの凡化性能を高めるためキュレーションされたデータ、で学習している模様。パラレルコーパスはReference-freeな手法を用いてスコアを算出し閾値以下の低品質な翻訳対は除外している。ステージ2では、詳細が書かれていないが、少量でよりfidelityの高い約270kの翻訳対を利用した模様。また、先行研究に基づいて、many-shotのin-context learningを用いて、訓練データをさらに洗練させたとのこと（先行研究が引用されているのみで詳細な記述は無し）。また、複数の評価ラウンドでスコアの一貫性が無いサンプルは手動でアノテーション、あるいはverificationをして品質を担保している模様。<br><br>RLではGRPOを採用し、rewardとしてsemantic(<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2635" target="_blank" rel="noopener noreferrer">[Paper Note] xCOMET: Transparent Machine Translation Evaluation through Fine-grained  Error Detection, Nuno M. Guerreiro+, TACL'24</a>
), terminology(<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2649" target="_blank" rel="noopener noreferrer">[Paper Note] TAT-R1: Terminology-Aware Translation with Reinforcement Learning and
  Word Alignment, Zheng Li+, arXiv'25</a>
; ドメイン特有のterminologyを捉える), repetitionに基づいたrewardを採用している。最終的にSFT-&gt;RLで学習されたHuayuan-MT-7Bに対して、下記プロンプトを用いて複数のoutputを統合してより高品質な翻訳を出力するキメラモデルを同様のrewardを用いて学習する、といったpipelineになっている。<br><br>&lt;img width="884" height="462" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/dbb7a799-6304-4cfa-b75c-74b44fe39a2e"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/dbb7a799-6304-4cfa-b75c-74b44fe39a2e"&lt;/a&gt;


/&gt;<br><br>&lt;img width="921" height="279" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/33b49ef7-b93b-4094-b83e-5931d2b411e5"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/33b49ef7-b93b-4094-b83e-5931d2b411e5"&lt;/a&gt;


/&gt;</p>
<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1220" target="_blank" rel="noopener noreferrer">Large Language Models Are State-of-the-Art Evaluators of Translation Quality, EAMT'23</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2635" target="_blank" rel="noopener noreferrer">[Paper Note] xCOMET: Transparent Machine Translation Evaluation through Fine-grained  Error Detection, Nuno M. Guerreiro+, TACL'24</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2636" target="_blank" rel="noopener noreferrer">[Paper Note] CometKiwi: IST-Unbabel 2022 Submission for the Quality Estimation Shared Task, Rei+, WMT'22</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2637" target="_blank" rel="noopener noreferrer">[Paper Note] No Language Left Behind: Scaling Human-Centered Machine Translation, NLLB Team+, arXiv'22</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2638" target="_blank" rel="noopener noreferrer">[Paper Note] Many-Shot In-Context Learning, Rishabh Agarwal+, NeurIPS'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2639" target="_blank" rel="noopener noreferrer">[Paper Note] RegMix: Data Mixture as Regression for Language Model Pre-training, Qian Liu+, ICLR'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2649" target="_blank" rel="noopener noreferrer">[Paper Note] TAT-R1: Terminology-Aware Translation with Reinforcement Learning and
  Word Alignment, Zheng Li+, arXiv'25</a>
</p>
<p>関連: PLaMo翻訳<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2517" target="_blank" rel="noopener noreferrer">PLaMo Translate: 翻訳特化大規模言語モデルの開発,今城+, Jxiv'25</a>
<br><br>こちらはSFT-&gt;Iterative DPO-&gt;Model Mergeを実施し、翻訳に特化した継続事前学習はやっていないように見える。一方、SFT時点で独自のテンプレートを作成し、語彙の指定やスタイル、日本語特有の常体、敬体の指定などを実施できるように翻訳に特化したテンプレートを学習している点が異なるように見える。Hunyuanは多様な翻訳の指示に対応できるように学習しているが、PLaMo翻訳はユースケースを絞り込み、ユースケースに対する性能を高めるような特化型のアプローチをとるといった思想の違いが伺える。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2252" target="_blank" rel="noopener noreferrer" class="title-link">Seed-X-Instruct-7B, ByteDance-Seed, 2025.07</a>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/teortaxestex/status/1946056084709359653?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>MTに特化したMultilingual SLM。7Bモデルだがベンチマーク上では他の大規模なモデルと同等以上。</p>
<p>テクニカルレポート: 


<a href="https://github.com/ByteDance-Seed/Seed-X-7B/blob/main/Technical_Report.pdf" target="_blank" rel="noopener noreferrer">https://github.com/ByteDance-Seed/Seed-X-7B/blob/main/Technical_Report.pdf</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-07-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2162" target="_blank" rel="noopener noreferrer" class="title-link">PLaMo翻訳による英語ベンチマークの翻訳, PFN, 2025.07</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Zero/Few/ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<span class="issue_date">Issue Date: 2024-11-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1535" target="_blank" rel="noopener noreferrer" class="title-link">Datasets: hpprc_honyaku, hpprc, 2024.11</a>
<span class="snippet"><span>Comment</span><p>元ポスト: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hpp_ricecake/status/1859118112672780401?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>英語Wikipediaを冒頭数文を抽出し日本語に人手で翻訳（Apache2.0ライセンスであるCalmやQwenの出力を参考に、cc-by-sa-4.0ライセンスにて公開している。<br>テクニカルタームが日本語で存在する場合は翻訳結果に含まれるようにしたり、翻訳された日本語テキストが単体で意味が成り立つように翻訳しているとのことで、1件あたり15分もの時間をかけて翻訳したとのこと。データ量は33件。many-shotやfew-shotに利用できそう。<br><br>日英対訳コーパスはライセンスが厳しいものが多いとのことなので、非常に有用だと思う。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-05-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/669" target="_blank" rel="noopener noreferrer" class="title-link">METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments, Banerjee+, CMU, ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and_or Summarization</a>
<span class="snippet"><span>Comment</span><p># イントロ<br><br>MTの評価はBLEUが提案されてから過去2年間で注目されている。BLEUはNIST metricと関連しており、研究で利用されてきた。自動評価は素早く、より簡便に、human evaluationよりも安価に評価をすることができる。また、自動評価は他のシステムとの比較だけでなく、ongoingなシステムの改善にも使える。<br><br>過去MTの評価は人手で行われてきた。MTの評価で利用される指標はfairly intensiveでwell establishedな一方で、MTの評価全体は複雑さとタスク依存である。結果的にMTの評価そのものが研究分野となってきた。多くの評価指標が提案されてきたが、全てが簡単に定量化できるわけではない。近年のFEMTIといったフレームワークは、MT評価のための多面的なmeasureを効果的でユーザが調整可能な方法で考案しようとしている。一方、単一の1次元の数値メトリックは、MT評価の全てのaspectを捉えることができないが、このようなメトリックは未だ大きな価値が実用性の観点で存在する。効果的・かつ効率的であるために、MT評価の自動性能指標はいくつかの基本的な基準を満たす必要がある：<br><br>- MTの質に対する人間が定量化した指標と高い相関があること<br><br>- 異なるシステム間、同じシステムの異なるバージョン間の品質の違いにできるだけsensitiveであること<br><br>- 一貫性があり、信頼性があり、一般的である必要<br><br>  - 一貫性: 同じMTシステムが類似したテキストを翻訳したら類似したスコアを返す<br><br>  - 信頼性: 類似したスコアを持つMTシステムは似たように類似した動作をすること<br><br>  - 一般的: さまざまなドメインやシナリオのMTタスクに適用可能であること<br><br>これら指標を全て満たすことは困難であるが、これまでに提案された全ての指標は、要件の全てではないにせよ、ほとんどの要件に対して適切に対処できているわけではない。これらの要件を適切に定量化し、具体的なテスト尺度に変換すると、MTの評価指標を比較、および評価できる全体的な基準として扱える。<br><br>本研究では、METEORを提案する。METEORはBLEUのいくつかの弱点に対処した手法である。<br><br><br><br># METEOR Metric<br><br>## METEORで対処するBLEUの弱点<br><br>BLEUはn-gramのprecisionを測る指標であり、recallを直接的に考慮していない。recallは翻訳文が正解文のcontentをどれだけcoverできているかを測定することができるため重要な指標である。BLEUは複数の参照訳を利用するため、recallの概念を定義することができない。代わりに、BLEUではbrevity penaltyを導入し、短すぎる翻訳にはペナルティを与えるようにしている。<br><br>NIST metricもコンセプト上はBLEUと同様の弱点を持っている。METEORが対処するBLEUやNISTは以下となる：<br><br>- The Lack of Recall:<br><br>  - 固定のbrevity penaltyを与えるだけでは、recallに対する適切な補償とはなっていない。実験結果がこれを強く示している。<br><br>- Use of Higher Order N-grams:<br><br>  - BLEUにおけるhigher orderのN-gramの利用は、翻訳の文法的な良さを間接的に測定している。METEORではより直接的にgrammarticality（あるいはword order）を考慮する。実験結果では、human judgmentsとより良い相関を示した。<br><br>- Lack of Explicit Word-matching between Translation and Reference<br><br>  - N-gramでは明示的なword-to-word matchingを必要しないため、結果的に正しくないマッチ、具体的には共通の機能語等のマッチをカウントしてしまう。<br><br>- Use of Geometric Averaging of N-grams<br><br>  - BLEUは幾何平均（i.e. 1,2,3,4-gramそれぞれのprecisionの積の1/n乗根）をとっているため、n-gramのコンポーネントの1つでもゼロになると、幾何平均の結果もゼロとなる。結果的に、sentenceあるいはsegmentレベルでBLEUスコアを測ろうとすると意味のないものとなる（ゼロになるため）。BLEUは全体のテストセット（文レベルではなく）のカウントを集約するのみであるが、sentence levelのindicatorもメトリックとしては有用であると考えられる。実験結果によると、n-gramの算術平均をとるようにBLEUスコアを改変した場合、human judgmentsとの相関が改善した。<br><br><br><br>## Meteor Metric<br><br>参照訳が複数ある場合は最もスコアが高いものを出力する。METEORはword-to-wordのマッチングに基づいた指標である。まず、参照訳と候補訳が与えられたときに単語同士のalignmentを作成する。このときunigramを利用してone-to-manyのmappingをする。wordnetの同義語を利用したり、porter-stemmerを利用しステミングした結果を活用しalignmentを作成することができる。続いて、それぞれのunigramのmapppingのうち、最も大きな部分集合のmappingを選択し、対応するunigramのalignmentとする。もしalignmentの候補として複数の候補があった場合、unigram mappingのcrossが少ない方を採用する。この一連の操作はstageとして定義され、各stageごとにmapping module（同義語使うのか、stemming結果使うのかなど）を定義する。そして、後段のstageでは、以前のstageでmappingされていなunigramがmappingの対象となる。たとえば、first stageにexact matchをmapping moduleとして利用し、次のstageでporter stemmerをmapping moduleとして利用すると、よりsurface formを重視したmappingが最初に作成され、surface formでマッチングしなかったものが、stemming結果によってマッピングされることになる。どの順番でstageを構成するか、何個のstageを構成するか、どのmapping moduleを利用するかは任意である。基本的には、1st-stageでは"exact match", 2nd-stageでは"porter stem", 3rd-stageでは"wordnet synonymy"を利用する。このようにして定義されたalignmentに基づいて、unigram PrecisionとRecallを計算する。<br><br>Precisionは、候補訳のunigramのうち、参照訳のunigramにマッピングされた割合となる。Recallは、参照訳のunigramのうち、候補訳からマッピングされた割合となる。そして、Precisionを1, Recallを9の重みとして、Recall-OrientedなF値を計算する。このF値はunigramマッチに基づいているので、より長い系列のマッチを考慮するために、alignmentに対して、ペナルティを計算する。具体的には、参照訳と候補訳で連続したunigramマッチとしてマッピングされているもの同士をchunkとして扱い、マッチングしたunigramに対するchunkの数に基づいてペナルティを計算する。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/b3aaf2f6-ebfc-4561-9b5e-c14a1c10a983" alt="image" loading="lazy"><br><br>チャンクの数が多ければ多いほどペナルティが増加する。そして、最終的にスコアは下記式で計算される：<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e591c2e4-3d92-4f26-ae0a-5fd782346dbd" alt="image" loading="lazy"><br><br>最大でF値が50%まで減衰するようにペナルティがかかる。<br><br><br><br># 評価<br><br>## Data<br><br>DARPA/TIDES 2003 Arabic-to-English, Chinese-to-English データを利用。Chinese dataは920 sentences, Arabic datasetは664 sentencesで構成される。それぞれのsentenceには、それぞれのsentenceには、4種類のreferenceが付与されている。加えて、Chinese dataでは7種類のシステム、Arabic dataでは6種類のシステムの各sentenceに対する翻訳結果と、2名の独立したhuman judgmentsの結果が付与されている。human judgmentsは、AdequacyとFluency Scoreの2つで構成されている。それぞれのスコアは0--5のレンジで変化する。本評価では、Combined Score、すなわち2名のアノテーションによって付与されたAdequacy ScoreとFluency Scoreを平均したものを用いる。<br><br><br><br>本研究の目的としては、sentence単位での評価を行うことだが、BLEUやNISTはシステムレベルで評価を行う指標のため、まずシステムレベルでhuman judgeとのcorrelationを測定。correlationを測る際は、各システムごとにCombined Scoreの平均をとり、human judgmentの総合的な結果を1つのスコアとして計算。またシステムのすべての翻訳結果に対する各種metricを集約することで、システムごとに各種metricの値を1つずつ付与し、両者で相関を測った。結果は以下のようにMETEORが最も高い相関を示した。METEORのsubcomponentsもBLEUやNISTよりも高い相関を示している。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/7ffa4c3c-7698-4075-9e9a-9db199d535af" alt="image" loading="lazy"><br><br><br><br>文レベルでhuman judgeとのcorrelationを測った結果は下記。文レベルで測る際は、システムごとに、システムが翻訳したすべての翻訳結果に対しMETEORスコアを計算し、fluencyとadequacyスコアの平均値との相関を測った。そして各データセットごとに、システムごとの相関係数の平均を算出した。<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/0264554c-4f21-47dc-aa58-c7ecfdd6aa47" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/b638a329-06a2-4c9f-9005-eae9fa38bf42" alt="image" loading="lazy"><br><br><br><br>他のmetricとの比較結果は下記で、METEORが最も高い相関を示した。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/da31b9ca-dee4-4c59-8e10-ca765bc00b36" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/6718194c-c9e2-4b5d-b02c-00776a469f18" alt="image" loading="lazy"><br><br><br><br>続いて、異なるword mapping設定でcorrelationを測った。結果は下記で、Exact, Porter, Wordnet-Synonymの順番で3-stageを構成する方法が最も高い相関を示した。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/428cdfdd-e20f-4a56-9e1e-06def83a8cab" alt="image" loading="lazy"><br><br><br><br>最後に、文レベルの評価はannotator間のaggreementが低く、ノイジーであることがわかっている。このノイズを緩和するために、スコアをnormalizeしcorrelationを測定した。結果は下記で、normalizeしたことによってcorrelationが改善している。これは、human assessmentのノイズによって、automatic scoreとhuman assessmentのcorrelationに影響を与えることを示している。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/473085a1-1137-43d6-8f8e-1cdbc256ad55" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2021-06-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/375" target="_blank" rel="noopener noreferrer" class="title-link">Probing Word Translations in the Transformer and Trading Decoder for Encoder Layers, NAACL‘21</a>
<span class="snippet"><span>Comment</span><p>Transformerに基づいたNMTにおいて、Encoderが入力を解釈し、Decoderが翻訳をしている、という通説を否定し、エンコーディング段階、さらにはinput embeddingの段階でそもそも翻訳が始まっていることを指摘。<br>エンコーディングの段階ですでに翻訳が始まっているのであれば、エンコーダの層を増やして、デコーダの層を減らせば、デコーディング速度を上げられる。<br>通常はエンコーダ、デコーダともに6層だが、10-2層にしたらBLEUスコアは変わらずデコーディングスピードは2.3倍になった。<br>18-4層の構成にしたら、BLEUスコアも1.42ポイント増加しデコーディング速度は1.4倍になった。</p>
<p>この研究は個人的に非常に興味深く、既存の常識を疑い、分析によりそれを明らかにし、シンプルな改善で性能向上およびデコーディング速度も向上しており、とても好き。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2018-01-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/236" target="_blank" rel="noopener noreferrer" class="title-link">ALAGIN 機械翻訳セミナー 単語アライメント, Graham Neubig, 2014.03</a>
<span class="snippet"><span>Comment</span><p>Neubigさんによる単語アライメントチュートリアル</p></span><br><br>
<button onclick="hideContent(0)" style="display: none;">hide</button>
</div>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<script>
  document.addEventListener('DOMContentLoaded', function() {
    const tweets = document.querySelectorAll('.tweet-embed[data-embed]');

    if ('IntersectionObserver' in window) {
      const observer = new IntersectionObserver((entries, obs) => {
        entries.forEach(entry => {
          if (entry.isIntersecting) {
            const el = entry.target;
            const html = el.getAttribute('data-embed');
            if (html) {
              const placeholder = el.querySelector('.tweet-placeholder');
              if (placeholder) placeholder.remove();

              el.innerHTML = html.trim();

              if (window.twttr?.widgets?.load) {
                window.twttr.widgets.load(el);
              }
            }
            obs.unobserve(el); // 処理済みは監視解除
          }
        });
      }, {
        rootMargin: '500px 0px', // 画面手前200pxで読み込み開始
        threshold: 0
      });

      tweets.forEach(tweet => observer.observe(tweet));

    } else {
      // IntersectionObserver未対応ブラウザ用のフォールバック
      function lazyLoadFallback() {
        tweets.forEach(el => {
          if (el.getAttribute('data-embed') && el.getBoundingClientRect().top < window.innerHeight) {
            const html = el.getAttribute('data-embed');
            const loadingImg = el.querySelector('.tweet-loading');
            if (loadingImg) loadingImg.remove();
            el.innerHTML = html.trim();
            el.removeAttribute('data-embed');
            if (window.twttr?.widgets?.load) {
              window.twttr.widgets.load(el);
            }
          }
        });
      }
      window.addEventListener('scroll', lazyLoadFallback);
      lazyLoadFallback();
    }
  });
</script>



    </div>

</article>
<div class="post-nav">
<a class="previous" href="/paper_notes/articles/MachineLearning.html" title="MachineLearningに関する論文・技術記事メモの一覧">MachineLearningに関する論文・技術記事メモの一覧</a><a class="next" href="/paper_notes/articles/MajorityVoting.html" title="MajorityVotingに関する論文・技術記事メモの一覧">MajorityVotingに関する論文・技術記事メモの一覧</a>
</div>
<div class="post-related">
      <div>Related Articles</div>
      <ul>
        <li class="">
          <a class="post-link" href="/paper_notes/articles/AWSLambda.html" title="AWSLambdaに関する論文・技術記事メモの一覧">
            AWSLambdaに関する論文・技術記事メモの一覧<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/3D%20Reconstruction.html" title="3D Reconstructionに関する論文・技術記事メモの一覧">
            3D Reconstructionに関する論文・技術記事メモの一覧<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/Mapping.html" title="Mappingに関する論文・技術記事メモの一覧">
            Mappingに関する論文・技術記事メモの一覧<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/Attention.html" title="Attentionに関する論文・技術記事メモの一覧">
            Attentionに関する論文・技術記事メモの一覧<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
</ul>
    </div>
<div class="post-comments"></div></section>
</div>


  </section>
  <section class="sidebar" style="margin-left: 15px;">
    <!-- Get sidebar items --><style type="text/css" media="screen">
.post-menu ul {
  list-style: none;
  padding: 0;
  margin: 0;
}
</style>

<div class="post-menu">
  <div class="post-menu-title">TOC</div>
  <div class="post-menu-content"></div>
</div>

<script>
  function generateContent() {
    var menu = document.querySelector(".post-menu");
    var menuContent =  menu.querySelector(".post-menu-content");
    var headings = document.querySelector(".post-content").querySelectorAll("h2, h3, h4, h5, h6");

    // Hide menu when no headings
    if (headings.length === 0) {
      return menu.style.display = "none";
    }

    // Generate post menu
    var menuHTML = '';
    for (var i = 0; i < headings.length; i++) {
      var h = headings[i];
      menuHTML += (
        '<li class="h-' + h.tagName.toLowerCase() + '">'
        + '<a href="#h-' + h.getAttribute('id') + '">' + h.textContent + '</a></li>');
    }

    menuContent.innerHTML = '<ul>' + menuHTML + '</ul>';

    // The header element
    var header = document.querySelector('header.site-header');

    function doMenuCollapse(index, over_items) {
      var items = menuContent.firstChild.children;

      if (over_items == undefined) {
        over_items = 20;
      }

      if (items.length < over_items) {
        return;
      }

      var activeItem = items[index];
      var beginItem = activeItem
      var endItem = activeItem
      var beginIndex = index;
      var endIndex = index + 1;
      while (beginIndex >= 0
        && !items[beginIndex].classList.contains('h-h2')) {
        beginIndex -= 1;
      }
      while (endIndex < items.length
        && !items[endIndex].classList.contains('h-h2')) {
        endIndex += 1;
      }
      for (var i = 0; i < beginIndex; i++) {
        item = items[i]
        if (!item.classList.contains('h-h2')) {
          item.style.display = 'none';
        }
      }
      for (var i = beginIndex + 1; i < endIndex; i++) {
        item = items[i]
        // if (!item.classList.contains('h-h2')) {
          item.style.display = '';
        // }
      }
      for (var i = endIndex; i < items.length; i++) {
        item = items[i]
        if (!item.classList.contains('h-h2')) {
          item.style.display = 'none';
        }
      }
    }

    // Init menu collapsed
    doMenuCollapse(-1);

    // Active the menu item
    window.addEventListener('scroll', function (event) {
      var lastActive = menuContent.querySelector('.active');
      var changed = true;
      var activeIndex = -1;
      for (var i = headings.length - 1; i >= 0; i--) {
        var h = headings[i];
        var headingRect = h.getBoundingClientRect();
        var headerRect = header.getBoundingClientRect();
        var headerTop = Math.floor(headerRect.top);
        var headerHeight = Math.floor(headerRect.height);
        var headerHeight = headerTop + headerHeight + 20;
        if (headingRect.top <= headerHeight) {
          var id = 'h-' + h.getAttribute('id');
          var a = menuContent.querySelector('a[href="#' + id  + '"]');
          var curActive = a.parentNode;
          if (curActive) {
            curActive.classList.add('active');
            activeIndex = i;
          }
          if (lastActive == curActive) {
            changed = false;
          }
          break;
        }
      }
      if (changed) {
        if (lastActive) {
          lastActive.classList.remove('active');
        }
        doMenuCollapse(activeIndex);
      }
      event.preventDefault();
    });
  }
  generateContent();
</script>
</section>
</div>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/paper_notes/"></data>

  <div class="wrapper">
    <div class="site-footer-inner">
<div>Copyright © 2023-current AkihikoWATANABE. The header images and any thumbnail images for the posts were generated by ChatGPT's DALL-E3.</div>
      <div>Powered by <a title="Jekyll is a simple, blog-aware, static site
      generator." href="https://jekyllrb.com/">Jekyll</a> &amp; <a title="Yat, yet
      another theme." href="https://github.com/jeffreytse/jekyll-theme-yat">Yat Theme</a>.</div>
      <div class="footer-col rss-subscribe">Subscribe <a href="/paper_notes/feed.xml">via RSS</a>
</div>
    </div>
  </div>
</footer>
</body>
  </html>
